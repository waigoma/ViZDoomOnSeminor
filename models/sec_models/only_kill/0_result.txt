D:\Programming\School\Hosei\ViZDoomOnSeminor\venv\Scripts\python.exe D:\Programming\School\Hosei\ViZDoomOnSeminor\examples\my_learning_deathmatch.py
GPU available
Initializing doom...
Doom initialized.
Initializing new model
  0%|          | 0/800 [00:00<?, ?it/s]
Epoch #1
Saving the network weights to: ../models/sec_models/only_kill/model-0.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 0.65 minutes

Epoch #2
  0%|          | 2/800 [01:16<8:29:00, 38.27s/it]Saving the network weights to: ../models/sec_models/only_kill/model-1.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 3.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 1.28 minutes

Epoch #3
Saving the network weights to: ../models/sec_models/only_kill/model-2.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 4.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 1.93 minutes

Epoch #4
  0%|          | 4/800 [02:34<8:31:20, 38.54s/it]Saving the network weights to: ../models/sec_models/only_kill/model-3.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 6.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 2.57 minutes

Epoch #5
Saving the network weights to: ../models/sec_models/only_kill/model-4.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 8.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 3.21 minutes

Epoch #6
  1%|          | 6/800 [03:51<8:29:52, 38.53s/it]Saving the network weights to: ../models/sec_models/only_kill/model-5.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 9.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 3.85 minutes

Epoch #7
Saving the network weights to: ../models/sec_models/only_kill/model-6.pth
  1%|          | 7/800 [04:29<8:27:26, 38.39s/it]Results:
  total_reward: 6.0, step_mean: 0.003873466752743706
  total_deaths: 12.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 4.49 minutes

Epoch #8
Saving the network weights to: ../models/sec_models/only_kill/model-7.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 14.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 5.13 minutes

Epoch #9
  1%|          | 9/800 [05:47<8:30:54, 38.75s/it]Saving the network weights to: ../models/sec_models/only_kill/model-8.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 15.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 5.79 minutes

Epoch #10
Saving the network weights to: ../models/sec_models/only_kill/model-9.pth
Results:
  total_reward: 9.0, step_mean: 0.005776636713735558
  total_deaths: 17.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 6.44 minutes
  1%|▏         | 10/800 [06:26<8:31:43, 38.87s/it]
Epoch #11
Saving the network weights to: ../models/sec_models/only_kill/model-10.pth
Results:
  total_reward: 5.0, step_mean: 0.0032113037893384713
  total_deaths: 19.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 7.10 minutes

Epoch #12
  2%|▏         | 12/800 [07:43<8:27:10, 38.62s/it]Saving the network weights to: ../models/sec_models/only_kill/model-11.pth
Results:
  total_reward: 2.0, step_mean: 0.0012828736369467607
  total_deaths: 21.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 7.72 minutes

Epoch #13
Saving the network weights to: ../models/sec_models/only_kill/model-12.pth
Results:
  total_reward: 7.0, step_mean: 0.004467134652201659
  total_deaths: 22.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 8.37 minutes

Epoch #14
  2%|▏         | 14/800 [08:59<8:20:41, 38.22s/it]Saving the network weights to: ../models/sec_models/only_kill/model-13.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 24.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 8.99 minutes

Epoch #15
Saving the network weights to: ../models/sec_models/only_kill/model-14.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 26.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 9.61 minutes

Epoch #16
  2%|▏         | 16/800 [10:15<8:17:09, 38.05s/it]Saving the network weights to: ../models/sec_models/only_kill/model-15.pth
Results:
  total_reward: 8.0, step_mean: 0.005138086062941554
  total_deaths: 28.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 10.25 minutes

Epoch #17
  2%|▏         | 17/800 [10:54<8:20:50, 38.38s/it]Saving the network weights to: ../models/sec_models/only_kill/model-16.pth
Results:
  total_reward: 16.0, step_mean: 0.010269576379974325
  total_deaths: 30.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 10.90 minutes

Epoch #18
Saving the network weights to: ../models/sec_models/only_kill/model-17.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 32.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 11.56 minutes

Epoch #19
  2%|▏         | 19/800 [12:13<8:29:05, 39.11s/it]Saving the network weights to: ../models/sec_models/only_kill/model-18.pth
Results:
  total_reward: 16.0, step_mean: 0.010329244673983214
  total_deaths: 35.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 12.23 minutes

Epoch #20
Saving the network weights to: ../models/sec_models/only_kill/model-19.pth
Results:
  total_reward: 5.0, step_mean: 0.003190810465858328
  total_deaths: 36.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 12.90 minutes

Epoch #21
  3%|▎         | 21/800 [13:33<8:34:18, 39.61s/it]Saving the network weights to: ../models/sec_models/only_kill/model-20.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 37.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 13.57 minutes

Epoch #22
Saving the network weights to: ../models/sec_models/only_kill/model-21.pth
Results:
  total_reward: 2.0, step_mean: 0.0012903225806451613
  total_deaths: 40.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 14.24 minutes

Epoch #23
  3%|▎         | 23/800 [14:55<8:40:30, 40.19s/it]Saving the network weights to: ../models/sec_models/only_kill/model-22.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 41.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 14.92 minutes

Epoch #24
Saving the network weights to: ../models/sec_models/only_kill/model-23.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 42.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 15.61 minutes

Epoch #25
  3%|▎         | 25/800 [16:17<8:43:26, 40.53s/it]Saving the network weights to: ../models/sec_models/only_kill/model-24.pth
Results:
  total_reward: 2.0, step_mean: 0.0012903225806451613
  total_deaths: 45.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 16.29 minutes

Epoch #26
  3%|▎         | 26/800 [16:58<8:45:12, 40.71s/it]Saving the network weights to: ../models/sec_models/only_kill/model-25.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 47.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 16.97 minutes

Epoch #27
Saving the network weights to: ../models/sec_models/only_kill/model-26.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 49.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 17.66 minutes

Epoch #28
  4%|▎         | 28/800 [18:19<8:44:11, 40.74s/it]Saving the network weights to: ../models/sec_models/only_kill/model-27.pth
Results:
  total_reward: 4.0, step_mean: 0.0025974025974025974
  total_deaths: 53.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 18.33 minutes

Epoch #29
Saving the network weights to: ../models/sec_models/only_kill/model-28.pth
Results:
  total_reward: 4.0, step_mean: 0.0025806451612903226
  total_deaths: 56.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 19.01 minutes

Epoch #30
  4%|▍         | 30/800 [19:41<8:44:08, 40.84s/it]Saving the network weights to: ../models/sec_models/only_kill/model-29.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 57.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 19.69 minutes

Epoch #31
  4%|▍         | 31/800 [20:22<8:43:08, 40.82s/it]Saving the network weights to: ../models/sec_models/only_kill/model-30.pth
Results:
  total_reward: 9.0, step_mean: 0.005776636713735558
  total_deaths: 59.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 20.37 minutes

Epoch #32
Saving the network weights to: ../models/sec_models/only_kill/model-31.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 61.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 21.06 minutes

Epoch #33
  4%|▍         | 33/800 [21:44<8:43:11, 40.93s/it]Saving the network weights to: ../models/sec_models/only_kill/model-32.pth
Results:
  total_reward: 1.0, step_mean: 0.0006414368184733803
  total_deaths: 63.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 21.74 minutes

Epoch #34
Saving the network weights to: ../models/sec_models/only_kill/model-33.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 65.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 22.43 minutes

Epoch #35
  4%|▍         | 35/800 [23:07<8:47:38, 41.38s/it]Saving the network weights to: ../models/sec_models/only_kill/model-34.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 66.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 23.13 minutes

Epoch #36
Saving the network weights to: ../models/sec_models/only_kill/model-35.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 68.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 23.83 minutes

Epoch #37
  5%|▍         | 37/800 [24:31<8:50:30, 41.72s/it]Saving the network weights to: ../models/sec_models/only_kill/model-36.pth
Results:
  total_reward: 4.0, step_mean: 0.0025823111684958036
  total_deaths: 71.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 24.53 minutes

Epoch #38
Saving the network weights to: ../models/sec_models/only_kill/model-37.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 72.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 25.22 minutes

Epoch #39
  5%|▍         | 39/800 [25:55<8:48:26, 41.66s/it]Saving the network weights to: ../models/sec_models/only_kill/model-38.pth
Results:
  total_reward: 5.0, step_mean: 0.0032113037893384713
  total_deaths: 74.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 25.92 minutes

Epoch #40
Saving the network weights to: ../models/sec_models/only_kill/model-39.pth
Results:
  total_reward: 3.0, step_mean: 0.001924310455420141
  total_deaths: 76.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 26.62 minutes

Epoch #41
  5%|▌         | 41/800 [27:20<8:55:08, 42.30s/it]Saving the network weights to: ../models/sec_models/only_kill/model-40.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 78.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 27.35 minutes

Epoch #42
  5%|▌         | 42/800 [28:04<8:58:50, 42.65s/it]Saving the network weights to: ../models/sec_models/only_kill/model-41.pth
Results:
  total_reward: 7.0, step_mean: 0.0044444444444444444
  total_deaths: 78.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 28.07 minutes

Epoch #43
Saving the network weights to: ../models/sec_models/only_kill/model-42.pth
Results:
  total_reward: 6.0, step_mean: 0.003870967741935484
  total_deaths: 81.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 28.78 minutes

Epoch #44
  6%|▌         | 44/800 [29:28<8:54:03, 42.39s/it]Saving the network weights to: ../models/sec_models/only_kill/model-43.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 82.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 29.48 minutes

Epoch #45
  6%|▌         | 45/800 [30:11<8:54:51, 42.51s/it]Saving the network weights to: ../models/sec_models/only_kill/model-44.pth
Results:
  total_reward: 4.0, step_mean: 0.0025396825396825397
  total_deaths: 82.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 30.19 minutes

Epoch #46
Saving the network weights to: ../models/sec_models/only_kill/model-45.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 83.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 30.89 minutes

Epoch #47
  6%|▌         | 47/800 [31:35<8:49:43, 42.21s/it]Saving the network weights to: ../models/sec_models/only_kill/model-46.pth
Results:
  total_reward: 3.0, step_mean: 0.0019169329073482429
  total_deaths: 85.0
  frag: 0.0
  death: 2.0
  global_step: 1565
Total elapsed time: 31.59 minutes

Epoch #48
Saving the network weights to: ../models/sec_models/only_kill/model-47.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 86.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 32.29 minutes

Epoch #49
  6%|▌         | 49/800 [32:59<8:46:44, 42.08s/it]Saving the network weights to: ../models/sec_models/only_kill/model-48.pth
Results:
  total_reward: 5.0, step_mean: 0.003190810465858328
  total_deaths: 87.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 32.99 minutes

Epoch #50
Saving the network weights to: ../models/sec_models/only_kill/model-49.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 89.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 33.68 minutes

Epoch #51
  6%|▋         | 51/800 [34:22<8:42:22, 41.85s/it]Saving the network weights to: ../models/sec_models/only_kill/model-50.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 90.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 34.37 minutes

Epoch #52
Saving the network weights to: ../models/sec_models/only_kill/model-51.pth
Results:
  total_reward: 5.0, step_mean: 0.0031928480204342275
  total_deaths: 91.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 35.06 minutes

Epoch #53
  7%|▋         | 53/800 [35:45<8:37:42, 41.58s/it]Saving the network weights to: ../models/sec_models/only_kill/model-52.pth
Results:
  total_reward: 3.0, step_mean: 0.001936733376371853
  total_deaths: 94.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 35.75 minutes

Epoch #54
Saving the network weights to: ../models/sec_models/only_kill/model-53.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 95.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 36.46 minutes

Epoch #55
  7%|▋         | 55/800 [37:08<8:34:31, 41.44s/it]Saving the network weights to: ../models/sec_models/only_kill/model-54.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 97.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 37.13 minutes

Epoch #56
Saving the network weights to: ../models/sec_models/only_kill/model-55.pth
  7%|▋         | 56/800 [37:48<8:32:02, 41.29s/it]Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 99.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 37.82 minutes

Epoch #57
Saving the network weights to: ../models/sec_models/only_kill/model-56.pth
Results:
  total_reward: 9.0, step_mean: 0.00574345883854499
  total_deaths: 100.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 38.58 minutes

Epoch #58
  7%|▋         | 58/800 [39:16<8:45:09, 42.47s/it]Saving the network weights to: ../models/sec_models/only_kill/model-57.pth
Results:
  total_reward: 7.0, step_mean: 0.004467134652201659
  total_deaths: 101.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 39.28 minutes

Epoch #59
Saving the network weights to: ../models/sec_models/only_kill/model-58.pth
Results:
  total_reward: 3.0, step_mean: 0.001936733376371853
  total_deaths: 104.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 39.98 minutes

Epoch #60
  8%|▊         | 60/800 [40:40<8:40:47, 42.23s/it]Saving the network weights to: ../models/sec_models/only_kill/model-59.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 105.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 40.68 minutes

Epoch #61
Saving the network weights to: ../models/sec_models/only_kill/model-60.pth
Results:
  total_reward: 8.0, step_mean: 0.005131494547787043
  total_deaths: 107.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 41.38 minutes

Epoch #62
  8%|▊         | 62/800 [42:05<8:40:41, 42.33s/it]Saving the network weights to: ../models/sec_models/only_kill/model-61.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 109.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 42.09 minutes

Epoch #63
Saving the network weights to: ../models/sec_models/only_kill/model-62.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 111.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 42.80 minutes

Epoch #64
  8%|▊         | 64/800 [43:30<8:39:27, 42.35s/it]Saving the network weights to: ../models/sec_models/only_kill/model-63.pth
Results:
  total_reward: 1.0, step_mean: 0.0006455777921239509
  total_deaths: 114.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 43.50 minutes

Epoch #65
Saving the network weights to: ../models/sec_models/only_kill/model-64.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 116.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 44.21 minutes

Epoch #66
  8%|▊         | 66/800 [44:54<8:36:22, 42.21s/it]Saving the network weights to: ../models/sec_models/only_kill/model-65.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 119.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 44.91 minutes

Epoch #67
Saving the network weights to: ../models/sec_models/only_kill/model-66.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 120.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 45.62 minutes

Epoch #68
  8%|▊         | 68/800 [46:18<8:33:58, 42.13s/it]Saving the network weights to: ../models/sec_models/only_kill/model-67.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 121.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 46.31 minutes

Epoch #69
  9%|▊         | 69/800 [47:00<8:31:52, 42.01s/it]Saving the network weights to: ../models/sec_models/only_kill/model-68.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 124.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 47.01 minutes

Epoch #70
Saving the network weights to: ../models/sec_models/only_kill/model-69.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 126.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 47.78 minutes

Epoch #71
  9%|▉         | 71/800 [48:33<8:59:22, 44.39s/it]Saving the network weights to: ../models/sec_models/only_kill/model-70.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 127.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 48.56 minutes

Epoch #72
Saving the network weights to: ../models/sec_models/only_kill/model-71.pth
Results:
  total_reward: 3.0, step_mean: 0.0019267822736030828
  total_deaths: 129.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 49.41 minutes

Epoch #73
  9%|▉         | 73/800 [50:13<9:30:07, 47.05s/it]Saving the network weights to: ../models/sec_models/only_kill/model-72.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 129.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 50.22 minutes

Epoch #74
Saving the network weights to: ../models/sec_models/only_kill/model-73.pth
  9%|▉         | 74/800 [51:02<9:37:09, 47.70s/it]Results:
  total_reward: 6.0, step_mean: 0.0038314176245210726
  total_deaths: 130.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 51.04 minutes

Epoch #75
Saving the network weights to: ../models/sec_models/only_kill/model-74.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 131.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 51.90 minutes

Epoch #76
 10%|▉         | 76/800 [52:44<9:56:19, 49.42s/it]Saving the network weights to: ../models/sec_models/only_kill/model-75.pth
Results:
  total_reward: 6.0, step_mean: 0.003873466752743706
  total_deaths: 134.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 52.75 minutes

Epoch #77
Saving the network weights to: ../models/sec_models/only_kill/model-76.pth
 10%|▉         | 77/800 [53:33<9:52:08, 49.14s/it]Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 136.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 53.56 minutes

Epoch #78
Saving the network weights to: ../models/sec_models/only_kill/model-77.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 138.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 54.37 minutes

Epoch #79
 10%|▉         | 79/800 [55:12<9:52:25, 49.30s/it]Saving the network weights to: ../models/sec_models/only_kill/model-78.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 140.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 55.20 minutes

Epoch #80
Saving the network weights to: ../models/sec_models/only_kill/model-79.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 142.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 56.03 minutes

Epoch #81
 10%|█         | 81/800 [56:53<9:59:03, 49.99s/it]Saving the network weights to: ../models/sec_models/only_kill/model-80.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 143.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 56.89 minutes

Epoch #82
Saving the network weights to: ../models/sec_models/only_kill/model-81.pth
Results:
  total_reward: 2.0, step_mean: 0.0012903225806451613
  total_deaths: 146.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 57.73 minutes

Epoch #83
 10%|█         | 83/800 [58:35<10:04:31, 50.59s/it]Saving the network weights to: ../models/sec_models/only_kill/model-82.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 147.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 58.59 minutes

Epoch #84
 10%|█         | 84/800 [59:18<9:37:21, 48.38s/it] Saving the network weights to: ../models/sec_models/only_kill/model-83.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 148.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 59.31 minutes

Epoch #85
Saving the network weights to: ../models/sec_models/only_kill/model-84.pth
Results:
  total_reward: 3.0, step_mean: 0.001924310455420141
  total_deaths: 150.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 60.03 minutes

Epoch #86
 11%|█         | 86/800 [1:00:44<9:03:29, 45.67s/it]Saving the network weights to: ../models/sec_models/only_kill/model-85.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 151.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 60.75 minutes

Epoch #87
Saving the network weights to: ../models/sec_models/only_kill/model-86.pth
Results:
  total_reward: 7.0, step_mean: 0.004469987228607918
  total_deaths: 152.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 61.57 minutes

Epoch #88
 11%|█         | 88/800 [1:02:26<9:35:25, 48.49s/it]Saving the network weights to: ../models/sec_models/only_kill/model-87.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 153.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 62.44 minutes

Epoch #89
Saving the network weights to: ../models/sec_models/only_kill/model-88.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 155.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 63.31 minutes

Epoch #90
 11%|█▏        | 90/800 [1:04:07<9:44:28, 49.39s/it]Saving the network weights to: ../models/sec_models/only_kill/model-89.pth
Results:
  total_reward: 16.0, step_mean: 0.010269576379974325
  total_deaths: 157.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 64.13 minutes

Epoch #91
Saving the network weights to: ../models/sec_models/only_kill/model-90.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 159.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 64.93 minutes

Epoch #92
 12%|█▏        | 92/800 [1:05:38<9:15:45, 47.10s/it]Saving the network weights to: ../models/sec_models/only_kill/model-91.pth
Results:
  total_reward: 14.0, step_mean: 0.008985879332477536
  total_deaths: 161.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 65.64 minutes

Epoch #93
Saving the network weights to: ../models/sec_models/only_kill/model-92.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 162.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 66.36 minutes

Epoch #94
 12%|█▏        | 94/800 [1:07:03<8:45:34, 44.67s/it]Saving the network weights to: ../models/sec_models/only_kill/model-93.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 164.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 67.06 minutes

Epoch #95
Saving the network weights to: ../models/sec_models/only_kill/model-94.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 166.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 67.75 minutes

Epoch #96
 12%|█▏        | 96/800 [1:08:25<8:23:49, 42.94s/it]Saving the network weights to: ../models/sec_models/only_kill/model-95.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 168.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 68.43 minutes

Epoch #97
Saving the network weights to: ../models/sec_models/only_kill/model-96.pth
Results:
  total_reward: 2.0, step_mean: 0.0012987012987012987
  total_deaths: 172.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 69.10 minutes

Epoch #98
 12%|█▏        | 98/800 [1:09:48<8:13:43, 42.20s/it]Saving the network weights to: ../models/sec_models/only_kill/model-97.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 173.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 69.81 minutes

Epoch #99
 12%|█▏        | 99/800 [1:10:31<8:14:42, 42.34s/it]Saving the network weights to: ../models/sec_models/only_kill/model-98.pth
Results:
  total_reward: 11.0, step_mean: 0.007064868336544637
  total_deaths: 175.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 70.52 minutes

Epoch #100
Saving the network weights to: ../models/sec_models/only_kill/model-99.pth
Results:
  total_reward: 21.0, step_mean: 0.01348747591522158
  total_deaths: 177.0
  frag: 1.0
  death: 2.0
  global_step: 1557
Total elapsed time: 71.20 minutes

Epoch #101
 13%|█▎        | 101/800 [1:11:53<8:06:14, 41.74s/it]Saving the network weights to: ../models/sec_models/only_kill/model-100.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 179.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 71.89 minutes

Epoch #102
Saving the network weights to: ../models/sec_models/only_kill/model-101.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 181.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 72.58 minutes

Epoch #103
 13%|█▎        | 103/800 [1:13:15<7:59:47, 41.30s/it]Saving the network weights to: ../models/sec_models/only_kill/model-102.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 182.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 73.26 minutes

Epoch #104
Saving the network weights to: ../models/sec_models/only_kill/model-103.pth
Results:
  total_reward: 2.0, step_mean: 0.0012845215157353885
  total_deaths: 184.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 73.94 minutes

Epoch #105
 13%|█▎        | 105/800 [1:14:37<7:57:30, 41.22s/it]Saving the network weights to: ../models/sec_models/only_kill/model-104.pth
Results:
  total_reward: 4.0, step_mean: 0.0025396825396825397
  total_deaths: 184.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 74.63 minutes

Epoch #106
 13%|█▎        | 106/800 [1:15:18<7:55:57, 41.15s/it]Saving the network weights to: ../models/sec_models/only_kill/model-105.pth
Results:
  total_reward: 6.0, step_mean: 0.0038314176245210726
  total_deaths: 185.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 75.31 minutes

Epoch #107
Saving the network weights to: ../models/sec_models/only_kill/model-106.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 186.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 75.99 minutes

Epoch #108
 14%|█▎        | 108/800 [1:16:41<7:57:19, 41.39s/it]Saving the network weights to: ../models/sec_models/only_kill/model-107.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 187.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 76.69 minutes

Epoch #109
Saving the network weights to: ../models/sec_models/only_kill/model-108.pth
Results:
  total_reward: 1.0, step_mean: 0.0006455777921239509
  total_deaths: 190.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 77.41 minutes

Epoch #110
 14%|█▍        | 110/800 [1:18:08<8:09:53, 42.60s/it]Saving the network weights to: ../models/sec_models/only_kill/model-109.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 191.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 78.15 minutes

Epoch #111
Saving the network weights to: ../models/sec_models/only_kill/model-110.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 193.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 78.86 minutes

Epoch #112
 14%|█▍        | 112/800 [1:19:34<8:10:51, 42.81s/it]Saving the network weights to: ../models/sec_models/only_kill/model-111.pth
Results:
  total_reward: 13.0, step_mean: 0.00834403080872914
  total_deaths: 195.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 79.58 minutes

Epoch #113
Saving the network weights to: ../models/sec_models/only_kill/model-112.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 197.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 80.31 minutes

Epoch #114
 14%|█▍        | 114/800 [1:21:01<8:10:46, 42.92s/it]Saving the network weights to: ../models/sec_models/only_kill/model-113.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 198.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 81.02 minutes

Epoch #115
Saving the network weights to: ../models/sec_models/only_kill/model-114.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 199.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 81.70 minutes

Epoch #116
 14%|█▍        | 116/800 [1:22:23<7:57:45, 41.91s/it]Saving the network weights to: ../models/sec_models/only_kill/model-115.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 201.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 82.38 minutes

Epoch #117
Saving the network weights to: ../models/sec_models/only_kill/model-116.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 202.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 83.09 minutes

Epoch #118
 15%|█▍        | 118/800 [1:23:47<7:57:16, 41.99s/it]Saving the network weights to: ../models/sec_models/only_kill/model-117.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 204.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 83.79 minutes

Epoch #119
Saving the network weights to: ../models/sec_models/only_kill/model-118.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 205.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 84.50 minutes

Epoch #120
 15%|█▌        | 120/800 [1:25:09<7:48:20, 41.32s/it]Saving the network weights to: ../models/sec_models/only_kill/model-119.pth
Results:
  total_reward: 5.0, step_mean: 0.0032258064516129032
  total_deaths: 208.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 85.15 minutes

Epoch #121
 15%|█▌        | 121/800 [1:25:49<7:43:11, 40.93s/it]Saving the network weights to: ../models/sec_models/only_kill/model-120.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 209.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 85.82 minutes

Epoch #122
Saving the network weights to: ../models/sec_models/only_kill/model-121.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 210.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 86.51 minutes

Epoch #123
 15%|█▌        | 123/800 [1:27:11<7:43:22, 41.07s/it]Saving the network weights to: ../models/sec_models/only_kill/model-122.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 212.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 87.19 minutes

Epoch #124
 16%|█▌        | 124/800 [1:27:52<7:42:32, 41.05s/it]Saving the network weights to: ../models/sec_models/only_kill/model-123.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 214.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 87.88 minutes

Epoch #125
Saving the network weights to: ../models/sec_models/only_kill/model-124.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 216.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 88.56 minutes

Epoch #126
 16%|█▌        | 126/800 [1:29:14<7:39:58, 40.95s/it]Saving the network weights to: ../models/sec_models/only_kill/model-125.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 218.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 89.24 minutes

Epoch #127
 16%|█▌        | 127/800 [1:29:55<7:40:56, 41.09s/it]Saving the network weights to: ../models/sec_models/only_kill/model-126.pth
Results:
  total_reward: 1.0, step_mean: 0.0006451612903225806
  total_deaths: 221.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 89.93 minutes

Epoch #128
Saving the network weights to: ../models/sec_models/only_kill/model-127.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 223.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 90.61 minutes

Epoch #129
 16%|█▌        | 129/800 [1:31:18<7:41:09, 41.24s/it]Saving the network weights to: ../models/sec_models/only_kill/model-128.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 226.0
  frag: 0.0
  death: 3.0
  global_step: 1558
Total elapsed time: 91.31 minutes

Epoch #130
Saving the network weights to: ../models/sec_models/only_kill/model-129.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 228.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 92.01 minutes

Epoch #131
 16%|█▋        | 131/800 [1:32:42<7:45:45, 41.77s/it]Saving the network weights to: ../models/sec_models/only_kill/model-130.pth
Results:
  total_reward: 1.0, step_mean: 0.0006414368184733803
  total_deaths: 230.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 92.71 minutes

Epoch #132
Saving the network weights to: ../models/sec_models/only_kill/model-131.pth
Results:
  total_reward: 22.0, step_mean: 0.014120667522464698
  total_deaths: 232.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 93.41 minutes

Epoch #133
 17%|█▋        | 133/800 [1:34:07<7:46:59, 42.01s/it]Saving the network weights to: ../models/sec_models/only_kill/model-132.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 233.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 94.12 minutes

Epoch #134
Saving the network weights to: ../models/sec_models/only_kill/model-133.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 234.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 94.83 minutes

Epoch #135
 17%|█▋        | 135/800 [1:35:31<7:46:55, 42.13s/it]Saving the network weights to: ../models/sec_models/only_kill/model-134.pth
Results:
  total_reward: 9.0, step_mean: 0.005776636713735558
  total_deaths: 236.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 95.53 minutes

Epoch #136
Saving the network weights to: ../models/sec_models/only_kill/model-135.pth
 17%|█▋        | 136/800 [1:36:14<7:48:44, 42.36s/it]Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 237.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 96.25 minutes

Epoch #137
Saving the network weights to: ../models/sec_models/only_kill/model-136.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 238.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 96.94 minutes

Epoch #138
 17%|█▋        | 138/800 [1:37:38<7:44:03, 42.06s/it]Saving the network weights to: ../models/sec_models/only_kill/model-137.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 240.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 97.64 minutes

Epoch #139
Saving the network weights to: ../models/sec_models/only_kill/model-138.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 242.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 98.32 minutes

Epoch #140
 18%|█▊        | 140/800 [1:39:00<7:37:25, 41.58s/it]Saving the network weights to: ../models/sec_models/only_kill/model-139.pth
Results:
  total_reward: 5.0, step_mean: 0.0031928480204342275
  total_deaths: 243.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 99.01 minutes

Epoch #141
 18%|█▊        | 141/800 [1:39:41<7:34:25, 41.37s/it]Saving the network weights to: ../models/sec_models/only_kill/model-140.pth
Results:
  total_reward: 1.0, step_mean: 0.0006414368184733803
  total_deaths: 245.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 99.69 minutes

Epoch #142
Saving the network weights to: ../models/sec_models/only_kill/model-141.pth
Results:
  total_reward: 13.0, step_mean: 0.008301404853128991
  total_deaths: 246.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 100.38 minutes

Epoch #143
 18%|█▊        | 143/800 [1:41:04<7:33:28, 41.41s/it]Saving the network weights to: ../models/sec_models/only_kill/model-142.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 248.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 101.07 minutes

Epoch #144
Saving the network weights to: ../models/sec_models/only_kill/model-143.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 249.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 101.78 minutes

Epoch #145
 18%|█▊        | 145/800 [1:42:28<7:35:19, 41.71s/it]Saving the network weights to: ../models/sec_models/only_kill/model-144.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 251.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 102.47 minutes

Epoch #146
Saving the network weights to: ../models/sec_models/only_kill/model-145.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 253.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 103.15 minutes

Epoch #147
 18%|█▊        | 147/800 [1:43:49<7:28:28, 41.21s/it]Saving the network weights to: ../models/sec_models/only_kill/model-146.pth
Results:
  total_reward: 1.0, step_mean: 0.0006422607578676942
  total_deaths: 255.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 103.83 minutes

Epoch #148
 18%|█▊        | 148/800 [1:44:30<7:27:39, 41.19s/it]Saving the network weights to: ../models/sec_models/only_kill/model-147.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 257.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 104.52 minutes

Epoch #149
Saving the network weights to: ../models/sec_models/only_kill/model-148.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 258.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 105.19 minutes

Epoch #150
 19%|█▉        | 150/800 [1:45:51<7:21:20, 40.74s/it]Saving the network weights to: ../models/sec_models/only_kill/model-149.pth
Results:
  total_reward: 1.0, step_mean: 0.0006455777921239509
  total_deaths: 261.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 105.86 minutes

Epoch #151
Saving the network weights to: ../models/sec_models/only_kill/model-150.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 263.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 106.53 minutes

Epoch #152
 19%|█▉        | 152/800 [1:47:12<7:16:55, 40.46s/it]Saving the network weights to: ../models/sec_models/only_kill/model-151.pth
Results:
  total_reward: 2.0, step_mean: 0.0012845215157353885
  total_deaths: 265.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 107.20 minutes

Epoch #153
Saving the network weights to: ../models/sec_models/only_kill/model-152.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 266.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 107.87 minutes

Epoch #154
 19%|█▉        | 154/800 [1:48:32<7:15:26, 40.44s/it]Saving the network weights to: ../models/sec_models/only_kill/model-153.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 267.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 108.55 minutes

Epoch #155
Saving the network weights to: ../models/sec_models/only_kill/model-154.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 268.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 109.23 minutes

Epoch #156
 20%|█▉        | 156/800 [1:49:54<7:15:55, 40.61s/it]Saving the network weights to: ../models/sec_models/only_kill/model-155.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 270.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 109.91 minutes

Epoch #157
Saving the network weights to: ../models/sec_models/only_kill/model-156.pth
Results:
  total_reward: 2.0, step_mean: 0.0012698412698412698
  total_deaths: 270.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 110.60 minutes

Epoch #158
 20%|█▉        | 158/800 [1:51:16<7:17:12, 40.86s/it]Saving the network weights to: ../models/sec_models/only_kill/model-157.pth
Results:
  total_reward: 1.0, step_mean: 0.0006406149903907751
  total_deaths: 272.0
  frag: 0.0
  death: 2.0
  global_step: 1561
Total elapsed time: 111.28 minutes

Epoch #159
Saving the network weights to: ../models/sec_models/only_kill/model-158.pth
Results:
  total_reward: 4.0, step_mean: 0.0025806451612903226
  total_deaths: 275.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 111.95 minutes

Epoch #160
 20%|██        | 160/800 [1:52:37<7:13:17, 40.62s/it]Saving the network weights to: ../models/sec_models/only_kill/model-159.pth
Results:
  total_reward: 9.0, step_mean: 0.005772931366260423
  total_deaths: 277.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 112.63 minutes

Epoch #161
Saving the network weights to: ../models/sec_models/only_kill/model-160.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 278.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 113.30 minutes

Epoch #162
 20%|██        | 162/800 [1:53:58<7:10:22, 40.47s/it]Saving the network weights to: ../models/sec_models/only_kill/model-161.pth
Results:
  total_reward: 1.0, step_mean: 0.0006451612903225806
  total_deaths: 281.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 113.97 minutes

Epoch #163
Saving the network weights to: ../models/sec_models/only_kill/model-162.pth
Results:
  total_reward: 1.0, step_mean: 0.0006451612903225806
  total_deaths: 284.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 114.64 minutes

Epoch #164
 20%|██        | 164/800 [1:55:18<7:06:29, 40.23s/it]Saving the network weights to: ../models/sec_models/only_kill/model-163.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 285.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 115.30 minutes

Epoch #165
Saving the network weights to: ../models/sec_models/only_kill/model-164.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 287.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 115.98 minutes

Epoch #166
 21%|██        | 166/800 [1:56:39<7:06:23, 40.35s/it]Saving the network weights to: ../models/sec_models/only_kill/model-165.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 290.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 116.65 minutes

Epoch #167
Saving the network weights to: ../models/sec_models/only_kill/model-166.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 292.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 117.34 minutes

Epoch #168
 21%|██        | 168/800 [1:58:01<7:08:18, 40.66s/it]Saving the network weights to: ../models/sec_models/only_kill/model-167.pth
Results:
  total_reward: 4.0, step_mean: 0.002569043031470777
  total_deaths: 294.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 118.02 minutes

Epoch #169
 21%|██        | 169/800 [1:58:41<7:07:43, 40.67s/it]Saving the network weights to: ../models/sec_models/only_kill/model-168.pth
Results:
  total_reward: 5.0, step_mean: 0.003244646333549643
  total_deaths: 298.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 118.70 minutes

Epoch #170
Saving the network weights to: ../models/sec_models/only_kill/model-169.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 300.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 119.37 minutes

Epoch #171
 21%|██▏       | 171/800 [2:00:02<7:05:51, 40.62s/it]Saving the network weights to: ../models/sec_models/only_kill/model-170.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 301.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 120.05 minutes

Epoch #172
 22%|██▏       | 172/800 [2:00:43<7:04:05, 40.52s/it]Saving the network weights to: ../models/sec_models/only_kill/model-171.pth
Results:
  total_reward: 1.0, step_mean: 0.0006414368184733803
  total_deaths: 303.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 120.72 minutes

Epoch #173
Saving the network weights to: ../models/sec_models/only_kill/model-172.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 304.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 121.39 minutes

Epoch #174
 22%|██▏       | 174/800 [2:02:04<7:03:10, 40.56s/it]Saving the network weights to: ../models/sec_models/only_kill/model-173.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 305.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 122.07 minutes

Epoch #175
 22%|██▏       | 175/800 [2:02:44<7:02:27, 40.56s/it]Saving the network weights to: ../models/sec_models/only_kill/model-174.pth
Results:
  total_reward: 5.0, step_mean: 0.0031928480204342275
  total_deaths: 306.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 122.75 minutes

Epoch #176
Saving the network weights to: ../models/sec_models/only_kill/model-175.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 307.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 123.42 minutes

Epoch #177
 22%|██▏       | 177/800 [2:04:05<7:00:30, 40.50s/it]Saving the network weights to: ../models/sec_models/only_kill/model-176.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 308.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 124.10 minutes

Epoch #178
 22%|██▏       | 178/800 [2:04:45<6:58:54, 40.41s/it]Saving the network weights to: ../models/sec_models/only_kill/model-177.pth
Results:
  total_reward: 4.0, step_mean: 0.002569043031470777
  total_deaths: 310.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 124.76 minutes

Epoch #179
Saving the network weights to: ../models/sec_models/only_kill/model-178.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 311.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 125.47 minutes

Epoch #180
 22%|██▎       | 180/800 [2:06:09<7:05:12, 41.15s/it]Saving the network weights to: ../models/sec_models/only_kill/model-179.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 313.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 126.16 minutes

Epoch #181
 23%|██▎       | 181/800 [2:06:50<7:02:38, 40.97s/it]Saving the network weights to: ../models/sec_models/only_kill/model-180.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 315.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 126.84 minutes

Epoch #182
 23%|██▎       | 182/800 [2:07:31<7:01:23, 40.91s/it]Saving the network weights to: ../models/sec_models/only_kill/model-181.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 316.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 127.52 minutes

Epoch #183
 23%|██▎       | 183/800 [2:08:11<6:58:36, 40.71s/it]Saving the network weights to: ../models/sec_models/only_kill/model-182.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 319.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 128.19 minutes

Epoch #184
Saving the network weights to: ../models/sec_models/only_kill/model-183.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 319.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 128.88 minutes

Epoch #185
 23%|██▎       | 185/800 [2:09:34<7:00:35, 41.03s/it]Saving the network weights to: ../models/sec_models/only_kill/model-184.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 322.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 129.57 minutes

Epoch #186
Saving the network weights to: ../models/sec_models/only_kill/model-185.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 324.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 130.25 minutes

Epoch #187
 23%|██▎       | 187/800 [2:10:56<6:59:44, 41.08s/it]Saving the network weights to: ../models/sec_models/only_kill/model-186.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 326.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 130.94 minutes

Epoch #188
Saving the network weights to: ../models/sec_models/only_kill/model-187.pth
Results:
  total_reward: 2.0, step_mean: 0.0012911555842479018
  total_deaths: 329.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 131.62 minutes

Epoch #189
 24%|██▎       | 189/800 [2:12:18<6:57:44, 41.02s/it]Saving the network weights to: ../models/sec_models/only_kill/model-188.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 331.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 132.30 minutes

Epoch #190
Saving the network weights to: ../models/sec_models/only_kill/model-189.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 333.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 132.97 minutes

Epoch #191
 24%|██▍       | 191/800 [2:13:39<6:54:10, 40.81s/it]Saving the network weights to: ../models/sec_models/only_kill/model-190.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 334.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 133.65 minutes

Epoch #192
Saving the network weights to: ../models/sec_models/only_kill/model-191.pth
Results:
  total_reward: 9.0, step_mean: 0.00574345883854499
  total_deaths: 335.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 134.33 minutes

Epoch #193
 24%|██▍       | 193/800 [2:15:00<6:51:16, 40.65s/it]Saving the network weights to: ../models/sec_models/only_kill/model-192.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 337.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 135.01 minutes

Epoch #194
Saving the network weights to: ../models/sec_models/only_kill/model-193.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 338.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 135.69 minutes

Epoch #195
 24%|██▍       | 195/800 [2:16:22<6:51:15, 40.79s/it]Saving the network weights to: ../models/sec_models/only_kill/model-194.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 340.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 136.37 minutes

Epoch #196
Saving the network weights to: ../models/sec_models/only_kill/model-195.pth
Results:
  total_reward: 7.0, step_mean: 0.004469987228607918
  total_deaths: 341.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 137.05 minutes

Epoch #197
 25%|██▍       | 197/800 [2:17:45<6:54:16, 41.22s/it]Saving the network weights to: ../models/sec_models/only_kill/model-196.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 343.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 137.76 minutes

Epoch #198
Saving the network weights to: ../models/sec_models/only_kill/model-197.pth
Results:
  total_reward: 5.0, step_mean: 0.003190810465858328
  total_deaths: 344.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 138.51 minutes

Epoch #199
 25%|██▍       | 199/800 [2:19:15<7:10:57, 43.02s/it]Saving the network weights to: ../models/sec_models/only_kill/model-198.pth
Results:
  total_reward: 8.0, step_mean: 0.005134788189987163
  total_deaths: 346.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 139.25 minutes

Epoch #200
Saving the network weights to: ../models/sec_models/only_kill/model-199.pth
Results:
  total_reward: 8.0, step_mean: 0.005138086062941554
  total_deaths: 348.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 139.99 minutes

Epoch #201
 25%|██▌       | 201/800 [2:20:40<7:07:22, 42.81s/it]Saving the network weights to: ../models/sec_models/only_kill/model-200.pth
Results:
  total_reward: 6.0, step_mean: 0.003870967741935484
  total_deaths: 351.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 140.68 minutes

Epoch #202
Saving the network weights to: ../models/sec_models/only_kill/model-201.pth
Results:
  total_reward: 4.0, step_mean: 0.0025396825396825397
  total_deaths: 351.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 141.39 minutes

Epoch #203
 25%|██▌       | 203/800 [2:22:05<7:02:03, 42.42s/it]Saving the network weights to: ../models/sec_models/only_kill/model-202.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 352.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 142.08 minutes

Epoch #204
Saving the network weights to: ../models/sec_models/only_kill/model-203.pth
Results:
  total_reward: 2.0, step_mean: 0.0012911555842479018
  total_deaths: 355.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 142.77 minutes

Epoch #205
 26%|██▌       | 205/800 [2:23:27<6:55:41, 41.92s/it]Saving the network weights to: ../models/sec_models/only_kill/model-204.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 356.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 143.46 minutes

Epoch #206
Saving the network weights to: ../models/sec_models/only_kill/model-205.pth
Results:
  total_reward: 1.0, step_mean: 0.0006451612903225806
  total_deaths: 359.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 144.19 minutes

Epoch #207
 26%|██▌       | 207/800 [2:24:56<7:06:39, 43.17s/it]Saving the network weights to: ../models/sec_models/only_kill/model-206.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 360.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 144.94 minutes

Epoch #208
Saving the network weights to: ../models/sec_models/only_kill/model-207.pth
Results:
  total_reward: 4.0, step_mean: 0.0025957170668397143
  total_deaths: 364.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 145.77 minutes

Epoch #209
 26%|██▌       | 209/800 [2:26:41<7:54:01, 48.12s/it]Saving the network weights to: ../models/sec_models/only_kill/model-208.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 365.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 146.69 minutes

Epoch #210
Saving the network weights to: ../models/sec_models/only_kill/model-209.pth
Results:
  total_reward: 2.0, step_mean: 0.0012845215157353885
  total_deaths: 367.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 147.62 minutes

Epoch #211
 26%|██▋       | 211/800 [2:28:25<8:09:40, 49.88s/it]Saving the network weights to: ../models/sec_models/only_kill/model-210.pth
Results:
  total_reward: 6.0, step_mean: 0.0038535645472061657
  total_deaths: 369.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 148.43 minutes

Epoch #212
Saving the network weights to: ../models/sec_models/only_kill/model-211.pth
Results:
  total_reward: 4.0, step_mean: 0.002569043031470777
  total_deaths: 371.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 149.15 minutes

Epoch #213
 27%|██▋       | 213/800 [2:29:51<7:34:29, 46.46s/it]Saving the network weights to: ../models/sec_models/only_kill/model-212.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 373.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 149.87 minutes

Epoch #214
Saving the network weights to: ../models/sec_models/only_kill/model-213.pth
Results:
  total_reward: 2.0, step_mean: 0.0012903225806451613
  total_deaths: 376.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 150.57 minutes

Epoch #215
 27%|██▋       | 215/800 [2:31:15<7:08:27, 43.95s/it]Saving the network weights to: ../models/sec_models/only_kill/model-214.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 377.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 151.25 minutes

Epoch #216
Saving the network weights to: ../models/sec_models/only_kill/model-215.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 380.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 151.95 minutes

Epoch #217
 27%|██▋       | 217/800 [2:32:38<6:56:30, 42.86s/it]Saving the network weights to: ../models/sec_models/only_kill/model-216.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 382.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 152.65 minutes

Epoch #218
Saving the network weights to: ../models/sec_models/only_kill/model-217.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 383.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 153.36 minutes

Epoch #219
 27%|██▋       | 219/800 [2:34:02<6:49:20, 42.27s/it]Saving the network weights to: ../models/sec_models/only_kill/model-218.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 384.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 154.04 minutes

Epoch #220
Saving the network weights to: ../models/sec_models/only_kill/model-219.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 385.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 154.74 minutes

Epoch #221
 28%|██▊       | 221/800 [2:35:26<6:47:48, 42.26s/it]Saving the network weights to: ../models/sec_models/only_kill/model-220.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 386.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 155.45 minutes

Epoch #222
Saving the network weights to: ../models/sec_models/only_kill/model-221.pth
Results:
  total_reward: 7.0, step_mean: 0.00449582530507386
  total_deaths: 388.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 156.13 minutes

Epoch #223
 28%|██▊       | 223/800 [2:36:48<6:39:08, 41.50s/it]Saving the network weights to: ../models/sec_models/only_kill/model-222.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 390.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 156.81 minutes

Epoch #224
 28%|██▊       | 224/800 [2:37:30<6:40:22, 41.71s/it]Saving the network weights to: ../models/sec_models/only_kill/model-223.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 392.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 157.51 minutes

Epoch #225
Saving the network weights to: ../models/sec_models/only_kill/model-224.pth
Results:
  total_reward: 4.0, step_mean: 0.002569043031470777
  total_deaths: 394.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 158.20 minutes

Epoch #226
 28%|██▊       | 226/800 [2:38:52<6:34:42, 41.26s/it]Saving the network weights to: ../models/sec_models/only_kill/model-225.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 396.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 158.87 minutes

Epoch #227
Saving the network weights to: ../models/sec_models/only_kill/model-226.pth
 28%|██▊       | 227/800 [2:39:33<6:32:42, 41.12s/it]Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 397.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 159.55 minutes

Epoch #228
Saving the network weights to: ../models/sec_models/only_kill/model-227.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 397.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 160.24 minutes

Epoch #229
 29%|██▊       | 229/800 [2:40:55<6:30:59, 41.08s/it]Saving the network weights to: ../models/sec_models/only_kill/model-228.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 398.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 160.92 minutes

Epoch #230
 29%|██▉       | 230/800 [2:41:36<6:29:35, 41.01s/it]Saving the network weights to: ../models/sec_models/only_kill/model-229.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 400.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 161.60 minutes

Epoch #231
 29%|██▉       | 231/800 [2:42:17<6:28:25, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill/model-230.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 402.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 162.28 minutes

Epoch #232
Saving the network weights to: ../models/sec_models/only_kill/model-231.pth
Results:
  total_reward: 3.0, step_mean: 0.001924310455420141
  total_deaths: 404.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 162.96 minutes

Epoch #233
 29%|██▉       | 233/800 [2:43:38<6:25:36, 40.80s/it]Saving the network weights to: ../models/sec_models/only_kill/model-232.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 405.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 163.64 minutes

Epoch #234
 29%|██▉       | 234/800 [2:44:19<6:24:47, 40.79s/it]Saving the network weights to: ../models/sec_models/only_kill/model-233.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 406.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 164.32 minutes

Epoch #235
Saving the network weights to: ../models/sec_models/only_kill/model-234.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 407.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 165.00 minutes

Epoch #236
 30%|██▉       | 236/800 [2:45:40<6:23:48, 40.83s/it]Saving the network weights to: ../models/sec_models/only_kill/model-235.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 408.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 165.68 minutes

Epoch #237
Saving the network weights to: ../models/sec_models/only_kill/model-236.pth
 30%|██▉       | 237/800 [2:46:21<6:22:50, 40.80s/it]Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 410.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 166.36 minutes

Epoch #238
 30%|██▉       | 238/800 [2:47:01<6:21:03, 40.68s/it]Saving the network weights to: ../models/sec_models/only_kill/model-237.pth
Results:
  total_reward: 5.0, step_mean: 0.0032278889606197547
  total_deaths: 413.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 167.03 minutes

Epoch #239
Saving the network weights to: ../models/sec_models/only_kill/model-238.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 414.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 167.73 minutes

Epoch #240
 30%|███       | 240/800 [2:48:25<6:24:49, 41.23s/it]Saving the network weights to: ../models/sec_models/only_kill/model-239.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 416.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 168.42 minutes

Epoch #241
Saving the network weights to: ../models/sec_models/only_kill/model-240.pth
Results:
  total_reward: 7.0, step_mean: 0.004469987228607918
  total_deaths: 417.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 169.12 minutes

Epoch #242
 30%|███       | 242/800 [2:49:48<6:23:33, 41.24s/it]Saving the network weights to: ../models/sec_models/only_kill/model-241.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 419.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 169.80 minutes

Epoch #243
 30%|███       | 243/800 [2:50:29<6:22:26, 41.20s/it]Saving the network weights to: ../models/sec_models/only_kill/model-242.pth
Results:
  total_reward: 8.0, step_mean: 0.005105296745373325
  total_deaths: 420.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 170.49 minutes

Epoch #244
Saving the network weights to: ../models/sec_models/only_kill/model-243.pth
Results:
  total_reward: 3.0, step_mean: 0.001936733376371853
  total_deaths: 423.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 171.21 minutes

Epoch #245
 31%|███       | 245/800 [2:51:54<6:28:34, 42.01s/it]Saving the network weights to: ../models/sec_models/only_kill/model-244.pth
Results:
  total_reward: 1.0, step_mean: 0.0006455777921239509
  total_deaths: 426.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 171.92 minutes

Epoch #246
 31%|███       | 246/800 [2:52:37<6:29:00, 42.13s/it]Saving the network weights to: ../models/sec_models/only_kill/model-245.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 428.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 172.62 minutes

Epoch #247
 31%|███       | 247/800 [2:53:19<6:27:47, 42.08s/it]Saving the network weights to: ../models/sec_models/only_kill/model-246.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 430.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 173.32 minutes

Epoch #248
Saving the network weights to: ../models/sec_models/only_kill/model-247.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 433.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 174.00 minutes

Epoch #249
 31%|███       | 249/800 [2:54:40<6:20:45, 41.46s/it]Saving the network weights to: ../models/sec_models/only_kill/model-248.pth
Results:
  total_reward: 2.0, step_mean: 0.0012828736369467607
  total_deaths: 435.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 174.68 minutes

Epoch #250
Saving the network weights to: ../models/sec_models/only_kill/model-249.pth
Results:
  total_reward: 4.0, step_mean: 0.0025806451612903226
  total_deaths: 438.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 175.37 minutes

Epoch #251
 31%|███▏      | 251/800 [2:56:03<6:17:34, 41.26s/it]Saving the network weights to: ../models/sec_models/only_kill/model-250.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 440.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 176.05 minutes

Epoch #252
 32%|███▏      | 252/800 [2:56:43<6:15:22, 41.10s/it]Saving the network weights to: ../models/sec_models/only_kill/model-251.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 442.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 176.73 minutes

Epoch #253
Saving the network weights to: ../models/sec_models/only_kill/model-252.pth
Results:
  total_reward: 5.0, step_mean: 0.0032258064516129032
  total_deaths: 445.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 177.41 minutes

Epoch #254
 32%|███▏      | 254/800 [2:58:05<6:11:40, 40.84s/it]Saving the network weights to: ../models/sec_models/only_kill/model-253.pth
Results:
  total_reward: 6.0, step_mean: 0.0038314176245210726
  total_deaths: 446.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 178.08 minutes

Epoch #255
Saving the network weights to: ../models/sec_models/only_kill/model-254.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 447.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 178.99 minutes

Epoch #256
 32%|███▏      | 256/800 [2:59:42<6:40:56, 44.22s/it]Saving the network weights to: ../models/sec_models/only_kill/model-255.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 449.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 179.70 minutes

Epoch #257
Saving the network weights to: ../models/sec_models/only_kill/model-256.pth
Results:
  total_reward: 14.0, step_mean: 0.008934269304403318
  total_deaths: 450.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 180.48 minutes

Epoch #258
 32%|███▏      | 258/800 [3:01:16<6:53:05, 45.73s/it]Saving the network weights to: ../models/sec_models/only_kill/model-257.pth
Results:
  total_reward: 8.0, step_mean: 0.005134788189987163
  total_deaths: 452.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 181.27 minutes

Epoch #259
Saving the network weights to: ../models/sec_models/only_kill/model-258.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 453.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 181.99 minutes

Epoch #260
 32%|███▎      | 260/800 [3:02:47<6:53:24, 45.93s/it]Saving the network weights to: ../models/sec_models/only_kill/model-259.pth
Results:
  total_reward: 5.0, step_mean: 0.003190810465858328
  total_deaths: 454.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 182.79 minutes

Epoch #261
Saving the network weights to: ../models/sec_models/only_kill/model-260.pth
Results:
  total_reward: 10.0, step_mean: 0.006381620931716656
  total_deaths: 455.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 183.59 minutes

Epoch #262
 33%|███▎      | 262/800 [3:04:20<6:53:43, 46.14s/it]Saving the network weights to: ../models/sec_models/only_kill/model-261.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 457.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 184.35 minutes

Epoch #263
 33%|███▎      | 263/800 [3:05:05<6:49:34, 45.76s/it]Saving the network weights to: ../models/sec_models/only_kill/model-262.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 459.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 185.09 minutes

Epoch #264
 33%|███▎      | 264/800 [3:05:48<6:42:03, 45.01s/it]Saving the network weights to: ../models/sec_models/only_kill/model-263.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 461.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 185.81 minutes

Epoch #265
 33%|███▎      | 265/800 [3:06:32<6:36:46, 44.50s/it]Saving the network weights to: ../models/sec_models/only_kill/model-264.pth
Results:
  total_reward: 6.0, step_mean: 0.003848620910840282
  total_deaths: 463.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 186.54 minutes

Epoch #266
Saving the network weights to: ../models/sec_models/only_kill/model-265.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 465.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 187.27 minutes

Epoch #267
 33%|███▎      | 267/800 [3:07:57<6:25:06, 43.35s/it]Saving the network weights to: ../models/sec_models/only_kill/model-266.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 467.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 187.96 minutes

Epoch #268
 34%|███▎      | 268/800 [3:08:38<6:17:38, 42.59s/it]Saving the network weights to: ../models/sec_models/only_kill/model-267.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 468.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 188.64 minutes

Epoch #269
Saving the network weights to: ../models/sec_models/only_kill/model-268.pth
Results:
  total_reward: 1.0, step_mean: 0.0006485084306095979
  total_deaths: 472.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 189.32 minutes

Epoch #270
 34%|███▍      | 270/800 [3:10:01<6:11:32, 42.06s/it]Saving the network weights to: ../models/sec_models/only_kill/model-269.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 474.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 190.02 minutes

Epoch #271
Saving the network weights to: ../models/sec_models/only_kill/model-270.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 475.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 190.71 minutes

Epoch #272
 34%|███▍      | 272/800 [3:11:24<6:08:24, 41.86s/it]Saving the network weights to: ../models/sec_models/only_kill/model-271.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 476.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 191.41 minutes

Epoch #273
 34%|███▍      | 273/800 [3:12:06<6:09:06, 42.02s/it]Saving the network weights to: ../models/sec_models/only_kill/model-272.pth
Results:
  total_reward: 1.0, step_mean: 0.0006349206349206349
  total_deaths: 476.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 192.11 minutes

Epoch #274
Saving the network weights to: ../models/sec_models/only_kill/model-273.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 478.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 192.80 minutes

Epoch #275
 34%|███▍      | 275/800 [3:13:30<6:06:26, 41.88s/it]Saving the network weights to: ../models/sec_models/only_kill/model-274.pth
Results:
  total_reward: 8.0, step_mean: 0.005108556832694764
  total_deaths: 479.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 193.50 minutes

Epoch #276
 34%|███▍      | 276/800 [3:14:11<6:04:11, 41.70s/it]Saving the network weights to: ../models/sec_models/only_kill/model-275.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 480.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 194.19 minutes

Epoch #277
Saving the network weights to: ../models/sec_models/only_kill/model-276.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 481.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 194.90 minutes

Epoch #278
 35%|███▍      | 278/800 [3:15:35<6:04:49, 41.93s/it]Saving the network weights to: ../models/sec_models/only_kill/model-277.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 482.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 195.60 minutes

Epoch #279
 35%|███▍      | 279/800 [3:16:17<6:04:27, 41.97s/it]Saving the network weights to: ../models/sec_models/only_kill/model-278.pth
Results:
  total_reward: 8.0, step_mean: 0.005105296745373325
  total_deaths: 483.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 196.30 minutes

Epoch #280
Saving the network weights to: ../models/sec_models/only_kill/model-279.pth
Results:
  total_reward: 4.0, step_mean: 0.0025823111684958036
  total_deaths: 486.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 196.99 minutes

Epoch #281
 35%|███▌      | 281/800 [3:17:40<6:00:52, 41.72s/it]Saving the network weights to: ../models/sec_models/only_kill/model-280.pth
Results:
  total_reward: 4.0, step_mean: 0.0025756600128783
  total_deaths: 489.0
  frag: 0.0
  death: 3.0
  global_step: 1553
Total elapsed time: 197.68 minutes

Epoch #282
Saving the network weights to: ../models/sec_models/only_kill/model-281.pth
Results:
  total_reward: 6.0, step_mean: 0.003870967741935484
  total_deaths: 492.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 198.38 minutes

Epoch #283
 35%|███▌      | 283/800 [3:19:05<6:02:47, 42.10s/it]Saving the network weights to: ../models/sec_models/only_kill/model-282.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 493.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 199.09 minutes

Epoch #284
Saving the network weights to: ../models/sec_models/only_kill/model-283.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 496.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 199.76 minutes

Epoch #285
 36%|███▌      | 285/800 [3:20:25<5:52:05, 41.02s/it]Saving the network weights to: ../models/sec_models/only_kill/model-284.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 499.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 200.43 minutes

Epoch #286
 36%|███▌      | 286/800 [3:21:05<5:48:36, 40.69s/it]Saving the network weights to: ../models/sec_models/only_kill/model-285.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 500.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 201.09 minutes

Epoch #287
 36%|███▌      | 287/800 [3:21:45<5:46:25, 40.52s/it]Saving the network weights to: ../models/sec_models/only_kill/model-286.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 501.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 201.76 minutes

Epoch #288
 36%|███▌      | 288/800 [3:22:25<5:44:21, 40.36s/it]Saving the network weights to: ../models/sec_models/only_kill/model-287.pth
Results:
  total_reward: 18.0, step_mean: 0.01148691767708998
  total_deaths: 502.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 202.43 minutes

Epoch #289
Saving the network weights to: ../models/sec_models/only_kill/model-288.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 503.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 203.10 minutes

Epoch #290
 36%|███▋      | 290/800 [3:23:45<5:42:08, 40.25s/it]Saving the network weights to: ../models/sec_models/only_kill/model-289.pth
Results:
  total_reward: 7.0, step_mean: 0.004469987228607918
  total_deaths: 504.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 203.77 minutes

Epoch #291
Saving the network weights to: ../models/sec_models/only_kill/model-290.pth
Results:
  total_reward: 16.0, step_mean: 0.010217113665389528
  total_deaths: 505.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 204.43 minutes

Epoch #292
 36%|███▋      | 292/800 [3:25:06<5:41:12, 40.30s/it]Saving the network weights to: ../models/sec_models/only_kill/model-291.pth
Results:
  total_reward: 3.0, step_mean: 0.001936733376371853
  total_deaths: 508.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 205.11 minutes

Epoch #293
Saving the network weights to: ../models/sec_models/only_kill/model-292.pth
Results:
  total_reward: 13.0, step_mean: 0.008392511297611363
  total_deaths: 511.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 205.77 minutes

Epoch #294
 37%|███▋      | 294/800 [3:26:26<5:38:16, 40.11s/it]Saving the network weights to: ../models/sec_models/only_kill/model-293.pth
Results:
  total_reward: 17.0, step_mean: 0.010939510939510939
  total_deaths: 514.0
  frag: 1.0
  death: 3.0
  global_step: 1554
Total elapsed time: 206.44 minutes

Epoch #295
 37%|███▋      | 295/800 [3:27:06<5:37:13, 40.07s/it]Saving the network weights to: ../models/sec_models/only_kill/model-294.pth
Results:
  total_reward: 8.0, step_mean: 0.005134788189987163
  total_deaths: 516.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 207.10 minutes

Epoch #296
Saving the network weights to: ../models/sec_models/only_kill/model-295.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 518.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 207.77 minutes

Epoch #297
 37%|███▋      | 297/800 [3:28:26<5:36:22, 40.12s/it]Saving the network weights to: ../models/sec_models/only_kill/model-296.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 519.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 208.44 minutes

Epoch #298
 37%|███▋      | 298/800 [3:29:06<5:36:07, 40.17s/it]Saving the network weights to: ../models/sec_models/only_kill/model-297.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 521.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 209.11 minutes

Epoch #299
Saving the network weights to: ../models/sec_models/only_kill/model-298.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 522.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 209.81 minutes

Epoch #300
 38%|███▊      | 300/800 [3:30:28<5:36:41, 40.40s/it]Saving the network weights to: ../models/sec_models/only_kill/model-299.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 525.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 210.48 minutes

Epoch #301
 38%|███▊      | 301/800 [3:31:08<5:35:28, 40.34s/it]Saving the network weights to: ../models/sec_models/only_kill/model-300.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 526.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 211.15 minutes

Epoch #302
Saving the network weights to: ../models/sec_models/only_kill/model-301.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 528.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 211.81 minutes

Epoch #303
 38%|███▊      | 303/800 [3:32:29<5:34:20, 40.36s/it]Saving the network weights to: ../models/sec_models/only_kill/model-302.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 529.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 212.49 minutes

Epoch #304
 38%|███▊      | 304/800 [3:33:10<5:34:30, 40.46s/it]Saving the network weights to: ../models/sec_models/only_kill/model-303.pth
Results:
  total_reward: 5.0, step_mean: 0.003207184092366902
  total_deaths: 531.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 213.17 minutes

Epoch #305
Saving the network weights to: ../models/sec_models/only_kill/model-304.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 533.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 213.83 minutes

Epoch #306
 38%|███▊      | 306/800 [3:34:29<5:29:31, 40.02s/it]Saving the network weights to: ../models/sec_models/only_kill/model-305.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 535.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 214.49 minutes

Epoch #307
 38%|███▊      | 307/800 [3:35:08<5:26:59, 39.80s/it]Saving the network weights to: ../models/sec_models/only_kill/model-306.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 537.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 215.14 minutes

Epoch #308
 38%|███▊      | 308/800 [3:35:49<5:29:13, 40.15s/it]Saving the network weights to: ../models/sec_models/only_kill/model-307.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 538.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 215.83 minutes

Epoch #309
Saving the network weights to: ../models/sec_models/only_kill/model-308.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 540.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 216.49 minutes

Epoch #310
 39%|███▉      | 310/800 [3:37:09<5:26:01, 39.92s/it]Saving the network weights to: ../models/sec_models/only_kill/model-309.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 541.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 217.15 minutes

Epoch #311
Saving the network weights to: ../models/sec_models/only_kill/model-310.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 542.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 217.82 minutes

Epoch #312
 39%|███▉      | 312/800 [3:38:29<5:24:55, 39.95s/it]Saving the network weights to: ../models/sec_models/only_kill/model-311.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 543.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 218.48 minutes

Epoch #313
Saving the network weights to: ../models/sec_models/only_kill/model-312.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 544.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 219.15 minutes

Epoch #314
 39%|███▉      | 314/800 [3:39:48<5:22:46, 39.85s/it]Saving the network weights to: ../models/sec_models/only_kill/model-313.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 546.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 219.81 minutes

Epoch #315
 39%|███▉      | 315/800 [3:40:28<5:21:30, 39.77s/it]Saving the network weights to: ../models/sec_models/only_kill/model-314.pth
Results:
  total_reward: 2.0, step_mean: 0.0012828736369467607
  total_deaths: 548.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 220.47 minutes

Epoch #316
Saving the network weights to: ../models/sec_models/only_kill/model-315.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 550.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 221.13 minutes

Epoch #317
 40%|███▉      | 317/800 [3:41:47<5:19:44, 39.72s/it]Saving the network weights to: ../models/sec_models/only_kill/model-316.pth
Results:
  total_reward: 2.0, step_mean: 0.001288659793814433
  total_deaths: 553.0
  frag: 0.0
  death: 3.0
  global_step: 1552
Total elapsed time: 221.79 minutes

Epoch #318
Saving the network weights to: ../models/sec_models/only_kill/model-317.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 555.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 222.45 minutes

Epoch #319
 40%|███▉      | 319/800 [3:43:06<5:17:17, 39.58s/it]Saving the network weights to: ../models/sec_models/only_kill/model-318.pth
Results:
  total_reward: 8.0, step_mean: 0.005105296745373325
  total_deaths: 556.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 223.11 minutes

Epoch #320
Saving the network weights to: ../models/sec_models/only_kill/model-319.pth
Results:
  total_reward: 4.0, step_mean: 0.0025396825396825397
  total_deaths: 556.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 223.78 minutes

Epoch #321
 40%|████      | 321/800 [3:44:26<5:17:38, 39.79s/it]Saving the network weights to: ../models/sec_models/only_kill/model-320.pth
Results:
  total_reward: 17.0, step_mean: 0.010848755583918315
  total_deaths: 557.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 224.44 minutes

Epoch #322
Saving the network weights to: ../models/sec_models/only_kill/model-321.pth
Results:
  total_reward: 6.0, step_mean: 0.0038289725590299937
  total_deaths: 558.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 225.11 minutes

Epoch #323
 40%|████      | 323/800 [3:45:46<5:16:45, 39.84s/it]Saving the network weights to: ../models/sec_models/only_kill/model-322.pth
Results:
  total_reward: 6.0, step_mean: 0.003848620910840282
  total_deaths: 560.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 225.77 minutes

Epoch #324
 40%|████      | 324/800 [3:46:25<5:15:24, 39.76s/it]Saving the network weights to: ../models/sec_models/only_kill/model-323.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 562.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 226.43 minutes

Epoch #325
 41%|████      | 325/800 [3:47:05<5:14:15, 39.69s/it]Saving the network weights to: ../models/sec_models/only_kill/model-324.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 564.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 227.09 minutes

Epoch #326
Saving the network weights to: ../models/sec_models/only_kill/model-325.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 566.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 227.76 minutes

Epoch #327
 41%|████      | 327/800 [3:48:25<5:14:48, 39.93s/it]Saving the network weights to: ../models/sec_models/only_kill/model-326.pth
Results:
  total_reward: 6.0, step_mean: 0.003873466752743706
  total_deaths: 569.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 228.43 minutes

Epoch #328
 41%|████      | 328/800 [3:49:05<5:13:31, 39.85s/it]Saving the network weights to: ../models/sec_models/only_kill/model-327.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 571.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 229.09 minutes

Epoch #329
 41%|████      | 329/800 [3:49:45<5:13:35, 39.95s/it]Saving the network weights to: ../models/sec_models/only_kill/model-328.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 572.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 229.76 minutes

Epoch #330
Saving the network weights to: ../models/sec_models/only_kill/model-329.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 573.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 230.43 minutes

Epoch #331
 41%|████▏     | 331/800 [3:51:05<5:11:29, 39.85s/it]Saving the network weights to: ../models/sec_models/only_kill/model-330.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 574.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 231.09 minutes

Epoch #332
 42%|████▏     | 332/800 [3:51:44<5:08:54, 39.60s/it]Saving the network weights to: ../models/sec_models/only_kill/model-331.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 577.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 231.74 minutes

Epoch #333
Saving the network weights to: ../models/sec_models/only_kill/model-332.pth
Results:
  total_reward: 2.0, step_mean: 0.0012911555842479018
  total_deaths: 580.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 232.40 minutes

Epoch #334
 42%|████▏     | 334/800 [3:53:04<5:10:19, 39.96s/it]Saving the network weights to: ../models/sec_models/only_kill/model-333.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 582.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 233.08 minutes

Epoch #335
Saving the network weights to: ../models/sec_models/only_kill/model-334.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 584.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 233.74 minutes

Epoch #336
 42%|████▏     | 336/800 [3:54:24<5:08:49, 39.93s/it]Saving the network weights to: ../models/sec_models/only_kill/model-335.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 585.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 234.41 minutes

Epoch #337
Saving the network weights to: ../models/sec_models/only_kill/model-336.pth
Results:
  total_reward: 2.0, step_mean: 0.0012828736369467607
  total_deaths: 587.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 235.06 minutes

Epoch #338
 42%|████▏     | 338/800 [3:55:42<5:04:28, 39.54s/it]Saving the network weights to: ../models/sec_models/only_kill/model-337.pth
Results:
  total_reward: 4.0, step_mean: 0.0025940337224383916
  total_deaths: 591.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 235.71 minutes

Epoch #339
Saving the network weights to: ../models/sec_models/only_kill/model-338.pth
Results:
  total_reward: 5.0, step_mean: 0.003244646333549643
  total_deaths: 595.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 236.37 minutes

Epoch #340
 42%|████▎     | 340/800 [3:57:02<5:04:50, 39.76s/it]Saving the network weights to: ../models/sec_models/only_kill/model-339.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 596.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 237.04 minutes

Epoch #341
Saving the network weights to: ../models/sec_models/only_kill/model-340.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 598.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 237.72 minutes

Epoch #342
 43%|████▎     | 342/800 [3:58:22<5:05:08, 39.97s/it]Saving the network weights to: ../models/sec_models/only_kill/model-341.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 600.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 238.38 minutes

Epoch #343
 43%|████▎     | 343/800 [3:59:02<5:04:17, 39.95s/it]Saving the network weights to: ../models/sec_models/only_kill/model-342.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 602.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 239.05 minutes

Epoch #344
 43%|████▎     | 344/800 [3:59:42<5:03:07, 39.88s/it]Saving the network weights to: ../models/sec_models/only_kill/model-343.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 605.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 239.71 minutes

Epoch #345
Saving the network weights to: ../models/sec_models/only_kill/model-344.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 607.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 240.39 minutes

Epoch #346
 43%|████▎     | 346/800 [4:01:03<5:03:43, 40.14s/it]Saving the network weights to: ../models/sec_models/only_kill/model-345.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 608.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 241.06 minutes

Epoch #347
 43%|████▎     | 347/800 [4:01:43<5:03:29, 40.20s/it]Saving the network weights to: ../models/sec_models/only_kill/model-346.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 610.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 241.73 minutes

Epoch #348
Saving the network weights to: ../models/sec_models/only_kill/model-347.pth
Results:
  total_reward: 1.0, step_mean: 0.0006422607578676942
  total_deaths: 612.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 242.41 minutes

Epoch #349
 44%|████▎     | 349/800 [4:03:05<5:04:46, 40.55s/it]Saving the network weights to: ../models/sec_models/only_kill/model-348.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 615.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 243.09 minutes

Epoch #350
Saving the network weights to: ../models/sec_models/only_kill/model-349.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 617.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 243.77 minutes

Epoch #351
 44%|████▍     | 351/800 [4:04:26<5:04:07, 40.64s/it]Saving the network weights to: ../models/sec_models/only_kill/model-350.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 618.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 244.45 minutes

Epoch #352
 44%|████▍     | 352/800 [4:05:08<5:05:04, 40.86s/it]Saving the network weights to: ../models/sec_models/only_kill/model-351.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 619.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 245.14 minutes

Epoch #353
Saving the network weights to: ../models/sec_models/only_kill/model-352.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 620.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 245.82 minutes

Epoch #354
 44%|████▍     | 354/800 [4:06:30<5:03:50, 40.88s/it]Saving the network weights to: ../models/sec_models/only_kill/model-353.pth
Results:
  total_reward: 2.0, step_mean: 0.0012853470437017994
  total_deaths: 623.0
  frag: 0.0
  death: 3.0
  global_step: 1556
Total elapsed time: 246.50 minutes

Epoch #355
Saving the network weights to: ../models/sec_models/only_kill/model-354.pth
Results:
  total_reward: 2.0, step_mean: 0.0012911555842479018
  total_deaths: 626.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 247.17 minutes

Epoch #356
 44%|████▍     | 356/800 [4:07:51<5:01:19, 40.72s/it]Saving the network weights to: ../models/sec_models/only_kill/model-355.pth
Results:
  total_reward: 4.0, step_mean: 0.0025806451612903226
  total_deaths: 629.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 247.85 minutes

Epoch #357
Saving the network weights to: ../models/sec_models/only_kill/model-356.pth
Results:
  total_reward: 7.0, step_mean: 0.0044728434504792336
  total_deaths: 631.0
  frag: 0.0
  death: 2.0
  global_step: 1565
Total elapsed time: 248.53 minutes

Epoch #358
 45%|████▍     | 358/800 [4:09:13<5:01:08, 40.88s/it]Saving the network weights to: ../models/sec_models/only_kill/model-357.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 632.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 249.22 minutes

Epoch #359
Saving the network weights to: ../models/sec_models/only_kill/model-358.pth
Results:
  total_reward: 2.0, step_mean: 0.0012698412698412698
  total_deaths: 632.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 249.90 minutes

Epoch #360
 45%|████▌     | 360/800 [4:10:35<5:02:00, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill/model-359.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 633.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 250.60 minutes

Epoch #361
Saving the network weights to: ../models/sec_models/only_kill/model-360.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 634.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 251.27 minutes

Epoch #362
 45%|████▌     | 362/800 [4:11:55<4:55:09, 40.43s/it]Saving the network weights to: ../models/sec_models/only_kill/model-361.pth
Results:
  total_reward: 7.0, step_mean: 0.00449582530507386
  total_deaths: 636.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 251.92 minutes

Epoch #363
 45%|████▌     | 363/800 [4:12:34<4:51:21, 40.00s/it]Saving the network weights to: ../models/sec_models/only_kill/model-362.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 638.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 252.57 minutes

Epoch #364
Saving the network weights to: ../models/sec_models/only_kill/model-363.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 640.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 253.22 minutes

Epoch #365
 46%|████▌     | 365/800 [4:13:52<4:46:51, 39.57s/it]Saving the network weights to: ../models/sec_models/only_kill/model-364.pth
Results:
  total_reward: 21.0, step_mean: 0.013409961685823755
  total_deaths: 641.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 253.88 minutes

Epoch #366
Saving the network weights to: ../models/sec_models/only_kill/model-365.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 641.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 254.54 minutes

Epoch #367
 46%|████▌     | 367/800 [4:15:11<4:44:56, 39.48s/it]Saving the network weights to: ../models/sec_models/only_kill/model-366.pth
Results:
  total_reward: 5.0, step_mean: 0.0032258064516129032
  total_deaths: 644.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 255.19 minutes

Epoch #368
 46%|████▌     | 368/800 [4:15:52<4:46:58, 39.86s/it]Saving the network weights to: ../models/sec_models/only_kill/model-367.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 645.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 255.87 minutes

Epoch #369
Saving the network weights to: ../models/sec_models/only_kill/model-368.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 647.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 256.54 minutes

Epoch #370
 46%|████▋     | 370/800 [4:17:13<4:48:42, 40.29s/it]Saving the network weights to: ../models/sec_models/only_kill/model-369.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 649.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 257.23 minutes

Epoch #371
 46%|████▋     | 371/800 [4:17:54<4:50:28, 40.63s/it]Saving the network weights to: ../models/sec_models/only_kill/model-370.pth
Results:
  total_reward: 6.0, step_mean: 0.003873466752743706
  total_deaths: 652.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 257.92 minutes

Epoch #372
 46%|████▋     | 372/800 [4:18:35<4:50:27, 40.72s/it]Saving the network weights to: ../models/sec_models/only_kill/model-371.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 655.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 258.60 minutes

Epoch #373
 47%|████▋     | 373/800 [4:19:17<4:51:53, 41.02s/it]Saving the network weights to: ../models/sec_models/only_kill/model-372.pth
Results:
  total_reward: 1.0, step_mean: 0.0006414368184733803
  total_deaths: 657.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 259.29 minutes

Epoch #374
Saving the network weights to: ../models/sec_models/only_kill/model-373.pth
Results:
  total_reward: 6.0, step_mean: 0.0038535645472061657
  total_deaths: 659.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 259.97 minutes

Epoch #375
 47%|████▋     | 375/800 [4:20:38<4:49:12, 40.83s/it]Saving the network weights to: ../models/sec_models/only_kill/model-374.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 660.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 260.65 minutes

Epoch #376
Saving the network weights to: ../models/sec_models/only_kill/model-375.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 661.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 261.33 minutes

Epoch #377
 47%|████▋     | 377/800 [4:22:00<4:48:17, 40.89s/it]Saving the network weights to: ../models/sec_models/only_kill/model-376.pth
Results:
  total_reward: 1.0, step_mean: 0.0006451612903225806
  total_deaths: 664.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 262.01 minutes

Epoch #378
 47%|████▋     | 378/800 [4:22:42<4:48:57, 41.08s/it]Saving the network weights to: ../models/sec_models/only_kill/model-377.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 665.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 262.71 minutes

Epoch #379
Saving the network weights to: ../models/sec_models/only_kill/model-378.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 667.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 263.38 minutes

Epoch #380
 48%|████▊     | 380/800 [4:24:03<4:44:58, 40.71s/it]Saving the network weights to: ../models/sec_models/only_kill/model-379.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 669.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 264.05 minutes

Epoch #381
Saving the network weights to: ../models/sec_models/only_kill/model-380.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 670.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 264.73 minutes

Epoch #382
 48%|████▊     | 382/800 [4:25:23<4:41:33, 40.42s/it]Saving the network weights to: ../models/sec_models/only_kill/model-381.pth
Results:
  total_reward: 5.0, step_mean: 0.003207184092366902
  total_deaths: 672.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 265.39 minutes

Epoch #383
 48%|████▊     | 383/800 [4:26:03<4:40:35, 40.37s/it]Saving the network weights to: ../models/sec_models/only_kill/model-382.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 674.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 266.06 minutes

Epoch #384
Saving the network weights to: ../models/sec_models/only_kill/model-383.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 675.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 266.71 minutes

Epoch #385
 48%|████▊     | 385/800 [4:27:21<4:33:02, 39.48s/it]Saving the network weights to: ../models/sec_models/only_kill/model-384.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 677.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 267.35 minutes

Epoch #386
Saving the network weights to: ../models/sec_models/only_kill/model-385.pth
Results:
  total_reward: 6.0, step_mean: 0.0038535645472061657
  total_deaths: 680.0
  frag: 0.0
  death: 3.0
  global_step: 1557
Total elapsed time: 267.99 minutes

Epoch #387
 48%|████▊     | 387/800 [4:28:38<4:29:16, 39.12s/it]Saving the network weights to: ../models/sec_models/only_kill/model-386.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 682.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 268.64 minutes

Epoch #388
 48%|████▊     | 388/800 [4:29:17<4:28:14, 39.06s/it]Saving the network weights to: ../models/sec_models/only_kill/model-387.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 683.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 269.29 minutes

Epoch #389
Saving the network weights to: ../models/sec_models/only_kill/model-388.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 684.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 269.95 minutes

Epoch #390
 49%|████▉     | 390/800 [4:30:35<4:26:25, 38.99s/it]Saving the network weights to: ../models/sec_models/only_kill/model-389.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 686.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 270.59 minutes

Epoch #391
Saving the network weights to: ../models/sec_models/only_kill/model-390.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 687.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 271.24 minutes

Epoch #392
 49%|████▉     | 392/800 [4:31:53<4:24:36, 38.91s/it]Saving the network weights to: ../models/sec_models/only_kill/model-391.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 689.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 271.88 minutes

Epoch #393
Saving the network weights to: ../models/sec_models/only_kill/model-392.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 690.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 272.54 minutes

Epoch #394
 49%|████▉     | 394/800 [4:33:12<4:26:00, 39.31s/it]Saving the network weights to: ../models/sec_models/only_kill/model-393.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 691.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 273.21 minutes

Epoch #395
Saving the network weights to: ../models/sec_models/only_kill/model-394.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 693.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 273.87 minutes

Epoch #396
 50%|████▉     | 396/800 [4:34:31<4:25:42, 39.46s/it]Saving the network weights to: ../models/sec_models/only_kill/model-395.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 695.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 274.53 minutes

Epoch #397
Saving the network weights to: ../models/sec_models/only_kill/model-396.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 697.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 275.19 minutes

Epoch #398
 50%|████▉     | 398/800 [4:35:51<4:26:10, 39.73s/it]Saving the network weights to: ../models/sec_models/only_kill/model-397.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 698.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 275.86 minutes

Epoch #399
Saving the network weights to: ../models/sec_models/only_kill/model-398.pth
Results:
  total_reward: 7.0, step_mean: 0.004490057729313663
  total_deaths: 700.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 276.52 minutes

Epoch #400
 50%|█████     | 400/800 [4:37:11<4:25:12, 39.78s/it]Saving the network weights to: ../models/sec_models/only_kill/model-399.pth
Results:
  total_reward: 6.0, step_mean: 0.003873466752743706
  total_deaths: 703.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 277.19 minutes

Epoch #401
Saving the network weights to: ../models/sec_models/only_kill/model-400.pth
Results:
  total_reward: 1.0, step_mean: 0.0006422607578676942
  total_deaths: 705.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 277.87 minutes

Epoch #402
 50%|█████     | 402/800 [4:38:32<4:26:45, 40.21s/it]Saving the network weights to: ../models/sec_models/only_kill/model-401.pth
Results:
  total_reward: 16.0, step_mean: 0.01021059349074665
  total_deaths: 706.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 278.54 minutes

Epoch #403
Saving the network weights to: ../models/sec_models/only_kill/model-402.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 707.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 279.21 minutes

Epoch #404
 50%|█████     | 404/800 [4:39:52<4:25:36, 40.24s/it]Saving the network weights to: ../models/sec_models/only_kill/model-403.pth
Results:
  total_reward: 4.0, step_mean: 0.0025396825396825397
  total_deaths: 707.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 279.88 minutes

Epoch #405
Saving the network weights to: ../models/sec_models/only_kill/model-404.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 710.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 280.59 minutes

Epoch #406
 51%|█████     | 406/800 [4:41:17<4:30:17, 41.16s/it]Saving the network weights to: ../models/sec_models/only_kill/model-405.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 711.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 281.29 minutes

Epoch #407
 51%|█████     | 407/800 [4:41:58<4:29:51, 41.20s/it]Saving the network weights to: ../models/sec_models/only_kill/model-406.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 712.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 281.98 minutes

Epoch #408
Saving the network weights to: ../models/sec_models/only_kill/model-407.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 713.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 282.66 minutes

Epoch #409
 51%|█████     | 409/800 [4:43:20<4:26:59, 40.97s/it]Saving the network weights to: ../models/sec_models/only_kill/model-408.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 715.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 283.34 minutes

Epoch #410
Saving the network weights to: ../models/sec_models/only_kill/model-409.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 717.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 284.02 minutes

Epoch #411
 51%|█████▏    | 411/800 [4:44:41<4:25:24, 40.94s/it]Saving the network weights to: ../models/sec_models/only_kill/model-410.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 718.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 284.70 minutes

Epoch #412
Saving the network weights to: ../models/sec_models/only_kill/model-411.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 720.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 285.38 minutes

Epoch #413
 52%|█████▏    | 413/800 [4:46:04<4:25:58, 41.24s/it]Saving the network weights to: ../models/sec_models/only_kill/model-412.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 722.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 286.08 minutes

Epoch #414
 52%|█████▏    | 414/800 [4:46:46<4:25:43, 41.30s/it]Saving the network weights to: ../models/sec_models/only_kill/model-413.pth
Results:
  total_reward: 8.0, step_mean: 0.005191434133679429
  total_deaths: 726.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 286.77 minutes

Epoch #415
 52%|█████▏    | 415/800 [4:47:27<4:25:38, 41.40s/it]Saving the network weights to: ../models/sec_models/only_kill/model-414.pth
Results:
  total_reward: 20.0, step_mean: 0.012836970474967908
  total_deaths: 728.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 287.46 minutes

Epoch #416
Saving the network weights to: ../models/sec_models/only_kill/model-415.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 730.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 288.17 minutes

Epoch #417
 52%|█████▏    | 417/800 [4:48:51<4:25:14, 41.55s/it]Saving the network weights to: ../models/sec_models/only_kill/model-416.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 732.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 288.86 minutes

Epoch #418
Saving the network weights to: ../models/sec_models/only_kill/model-417.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 733.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 289.55 minutes

Epoch #419
 52%|█████▏    | 419/800 [4:50:15<4:24:55, 41.72s/it]Saving the network weights to: ../models/sec_models/only_kill/model-418.pth
Results:
  total_reward: 5.0, step_mean: 0.003207184092366902
  total_deaths: 735.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 290.25 minutes

Epoch #420
Saving the network weights to: ../models/sec_models/only_kill/model-419.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 737.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 290.94 minutes

Epoch #421
 53%|█████▎    | 421/800 [4:51:38<4:22:45, 41.60s/it]Saving the network weights to: ../models/sec_models/only_kill/model-420.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 739.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 291.63 minutes

Epoch #422
Saving the network weights to: ../models/sec_models/only_kill/model-421.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 741.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 292.33 minutes

Epoch #423
 53%|█████▎    | 423/800 [4:53:01<4:22:19, 41.75s/it]Saving the network weights to: ../models/sec_models/only_kill/model-422.pth
Results:
  total_reward: 6.0, step_mean: 0.0038289725590299937
  total_deaths: 742.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 293.03 minutes

Epoch #424
 53%|█████▎    | 424/800 [4:53:43<4:21:28, 41.73s/it]Saving the network weights to: ../models/sec_models/only_kill/model-423.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 743.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 293.72 minutes

Epoch #425
Saving the network weights to: ../models/sec_models/only_kill/model-424.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 745.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 294.42 minutes

Epoch #426
 53%|█████▎    | 426/800 [4:55:08<4:22:23, 42.10s/it]Saving the network weights to: ../models/sec_models/only_kill/model-425.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 746.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 295.14 minutes

Epoch #427
Saving the network weights to: ../models/sec_models/only_kill/model-426.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 747.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 295.82 minutes

Epoch #428
 54%|█████▎    | 428/800 [4:56:29<4:16:04, 41.30s/it]Saving the network weights to: ../models/sec_models/only_kill/model-427.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 748.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 296.49 minutes

Epoch #429
Saving the network weights to: ../models/sec_models/only_kill/model-428.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 749.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 297.17 minutes

Epoch #430
 54%|█████▍    | 430/800 [4:57:50<4:12:58, 41.02s/it]Saving the network weights to: ../models/sec_models/only_kill/model-429.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 750.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 297.85 minutes

Epoch #431
Saving the network weights to: ../models/sec_models/only_kill/model-430.pth
Results:
  total_reward: 2.0, step_mean: 0.0012903225806451613
  total_deaths: 753.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 298.52 minutes

Epoch #432
 54%|█████▍    | 432/800 [4:59:11<4:09:02, 40.61s/it]Saving the network weights to: ../models/sec_models/only_kill/model-431.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 754.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 299.19 minutes

Epoch #433
 54%|█████▍    | 433/800 [4:59:51<4:08:01, 40.55s/it]Saving the network weights to: ../models/sec_models/only_kill/model-432.pth
Results:
  total_reward: 9.0, step_mean: 0.005772931366260423
  total_deaths: 756.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 299.86 minutes

Epoch #434
Saving the network weights to: ../models/sec_models/only_kill/model-433.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 757.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 300.54 minutes

Epoch #435
 54%|█████▍    | 435/800 [5:01:13<4:07:12, 40.64s/it]Saving the network weights to: ../models/sec_models/only_kill/model-434.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 758.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 301.22 minutes

Epoch #436
Saving the network weights to: ../models/sec_models/only_kill/model-435.pth
Results:
  total_reward: 2.0, step_mean: 0.0012698412698412698
  total_deaths: 758.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 301.95 minutes

Epoch #437
 55%|█████▍    | 437/800 [5:02:38<4:11:51, 41.63s/it]Saving the network weights to: ../models/sec_models/only_kill/model-436.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 760.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 302.64 minutes

Epoch #438
 55%|█████▍    | 438/800 [5:03:20<4:11:40, 41.72s/it]Saving the network weights to: ../models/sec_models/only_kill/model-437.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 761.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 303.34 minutes

Epoch #439
Saving the network weights to: ../models/sec_models/only_kill/model-438.pth
Results:
  total_reward: 1.0, step_mean: 0.0006451612903225806
  total_deaths: 764.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 304.04 minutes

Epoch #440
 55%|█████▌    | 440/800 [5:04:44<4:10:55, 41.82s/it]Saving the network weights to: ../models/sec_models/only_kill/model-439.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 765.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 304.74 minutes

Epoch #441
Saving the network weights to: ../models/sec_models/only_kill/model-440.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 767.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 305.41 minutes

Epoch #442
 55%|█████▌    | 442/800 [5:06:05<4:06:04, 41.24s/it]Saving the network weights to: ../models/sec_models/only_kill/model-441.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 769.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 306.09 minutes

Epoch #443
Saving the network weights to: ../models/sec_models/only_kill/model-442.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 773.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 306.76 minutes

Epoch #444
 56%|█████▌    | 444/800 [5:07:26<4:02:39, 40.90s/it]Saving the network weights to: ../models/sec_models/only_kill/model-443.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 775.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 307.44 minutes

Epoch #445
Saving the network weights to: ../models/sec_models/only_kill/model-444.pth
Results:
  total_reward: 9.0, step_mean: 0.00574345883854499
  total_deaths: 776.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 308.13 minutes

Epoch #446
 56%|█████▌    | 446/800 [5:08:49<4:02:59, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill/model-445.pth
Results:
  total_reward: 6.0, step_mean: 0.0038289725590299937
  total_deaths: 777.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 308.82 minutes

Epoch #447
 56%|█████▌    | 447/800 [5:09:31<4:03:03, 41.31s/it]Saving the network weights to: ../models/sec_models/only_kill/model-446.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 779.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 309.52 minutes

Epoch #448
Saving the network weights to: ../models/sec_models/only_kill/model-447.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 780.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 310.19 minutes

Epoch #449
 56%|█████▌    | 449/800 [5:10:51<3:58:56, 40.85s/it]Saving the network weights to: ../models/sec_models/only_kill/model-448.pth
Results:
  total_reward: 4.0, step_mean: 0.0025823111684958036
  total_deaths: 783.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 310.86 minutes

Epoch #450
Saving the network weights to: ../models/sec_models/only_kill/model-449.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 784.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 311.55 minutes

Epoch #451
 56%|█████▋    | 451/800 [5:12:13<3:57:12, 40.78s/it]Saving the network weights to: ../models/sec_models/only_kill/model-450.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 785.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 312.22 minutes

Epoch #452
Saving the network weights to: ../models/sec_models/only_kill/model-451.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 786.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 312.91 minutes

Epoch #453
 57%|█████▋    | 453/800 [5:13:35<3:56:37, 40.91s/it]Saving the network weights to: ../models/sec_models/only_kill/model-452.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 788.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 313.59 minutes

Epoch #454
 57%|█████▋    | 454/800 [5:14:16<3:55:46, 40.89s/it]Saving the network weights to: ../models/sec_models/only_kill/model-453.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 791.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 314.27 minutes

Epoch #455
Saving the network weights to: ../models/sec_models/only_kill/model-454.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 792.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 314.96 minutes

Epoch #456
 57%|█████▋    | 456/800 [5:15:37<3:53:25, 40.71s/it]Saving the network weights to: ../models/sec_models/only_kill/model-455.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 793.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 315.63 minutes

Epoch #457
Saving the network weights to: ../models/sec_models/only_kill/model-456.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 795.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 316.30 minutes

Epoch #458
 57%|█████▋    | 458/800 [5:16:57<3:49:36, 40.28s/it]Saving the network weights to: ../models/sec_models/only_kill/model-457.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 797.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 316.96 minutes

Epoch #459
 57%|█████▋    | 459/800 [5:17:37<3:48:22, 40.18s/it]Saving the network weights to: ../models/sec_models/only_kill/model-458.pth
Results:
  total_reward: 7.0, step_mean: 0.004467134652201659
  total_deaths: 798.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 317.62 minutes

Epoch #460
Saving the network weights to: ../models/sec_models/only_kill/model-459.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 800.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 318.29 minutes

Epoch #461
 58%|█████▊    | 461/800 [5:18:56<3:44:27, 39.73s/it]Saving the network weights to: ../models/sec_models/only_kill/model-460.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 802.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 318.94 minutes

Epoch #462
Saving the network weights to: ../models/sec_models/only_kill/model-461.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 805.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 319.58 minutes

Epoch #463
 58%|█████▊    | 463/800 [5:20:13<3:40:27, 39.25s/it]Saving the network weights to: ../models/sec_models/only_kill/model-462.pth
Results:
  total_reward: 5.0, step_mean: 0.0032278889606197547
  total_deaths: 808.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 320.23 minutes

Epoch #464
Saving the network weights to: ../models/sec_models/only_kill/model-463.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 809.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 320.88 minutes

Epoch #465
 58%|█████▊    | 465/800 [5:21:31<3:37:45, 39.00s/it]Saving the network weights to: ../models/sec_models/only_kill/model-464.pth
Results:
  total_reward: 1.0, step_mean: 0.0006422607578676942
  total_deaths: 811.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 321.52 minutes

Epoch #466
Saving the network weights to: ../models/sec_models/only_kill/model-465.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 813.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 322.17 minutes

Epoch #467
 58%|█████▊    | 467/800 [5:22:48<3:35:51, 38.89s/it]Saving the network weights to: ../models/sec_models/only_kill/model-466.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 815.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 322.82 minutes

Epoch #468
Saving the network weights to: ../models/sec_models/only_kill/model-467.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 817.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 323.48 minutes

Epoch #469
 59%|█████▊    | 469/800 [5:24:08<3:36:28, 39.24s/it]Saving the network weights to: ../models/sec_models/only_kill/model-468.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 819.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 324.13 minutes

Epoch #470
Saving the network weights to: ../models/sec_models/only_kill/model-469.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 820.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 324.79 minutes

Epoch #471
 59%|█████▉    | 471/800 [5:25:26<3:35:13, 39.25s/it]Saving the network weights to: ../models/sec_models/only_kill/model-470.pth
Results:
  total_reward: 6.0, step_mean: 0.0038289725590299937
  total_deaths: 821.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 325.44 minutes

Epoch #472
 59%|█████▉    | 472/800 [5:26:06<3:35:26, 39.41s/it]Saving the network weights to: ../models/sec_models/only_kill/model-471.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 823.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 326.11 minutes

Epoch #473
Saving the network weights to: ../models/sec_models/only_kill/model-472.pth
 59%|█████▉    | 473/800 [5:26:46<3:35:20, 39.51s/it]Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 824.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 326.77 minutes

Epoch #474
 59%|█████▉    | 474/800 [5:27:26<3:35:33, 39.67s/it]Saving the network weights to: ../models/sec_models/only_kill/model-473.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 825.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 327.44 minutes

Epoch #475
Saving the network weights to: ../models/sec_models/only_kill/model-474.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 826.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 328.10 minutes

Epoch #476
 60%|█████▉    | 476/800 [5:28:46<3:35:50, 39.97s/it]Saving the network weights to: ../models/sec_models/only_kill/model-475.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 827.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 328.78 minutes

Epoch #477
 60%|█████▉    | 477/800 [5:29:28<3:38:25, 40.58s/it]Saving the network weights to: ../models/sec_models/only_kill/model-476.pth
Results:
  total_reward: 2.0, step_mean: 0.0012978585334198572
  total_deaths: 831.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 329.48 minutes

Epoch #478
Saving the network weights to: ../models/sec_models/only_kill/model-477.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 833.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 330.20 minutes

Epoch #479
 60%|█████▉    | 479/800 [5:30:53<3:42:22, 41.56s/it]Saving the network weights to: ../models/sec_models/only_kill/model-478.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 834.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 330.90 minutes

Epoch #480
Saving the network weights to: ../models/sec_models/only_kill/model-479.pth
Results:
  total_reward: 5.0, step_mean: 0.0031928480204342275
  total_deaths: 835.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 331.62 minutes

Epoch #481
 60%|██████    | 481/800 [5:32:19<3:44:35, 42.24s/it]Saving the network weights to: ../models/sec_models/only_kill/model-480.pth
Results:
  total_reward: 3.0, step_mean: 0.0019267822736030828
  total_deaths: 837.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 332.33 minutes

Epoch #482
 60%|██████    | 482/800 [5:33:02<3:44:28, 42.35s/it]Saving the network weights to: ../models/sec_models/only_kill/model-481.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 838.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 333.04 minutes

Epoch #483
Saving the network weights to: ../models/sec_models/only_kill/model-482.pth
Results:
  total_reward: 3.0, step_mean: 0.0019047619047619048
  total_deaths: 838.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 333.74 minutes

Epoch #484
 60%|██████    | 484/800 [5:34:25<3:41:35, 42.08s/it]Saving the network weights to: ../models/sec_models/only_kill/model-483.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 840.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 334.43 minutes

Epoch #485
 61%|██████    | 485/800 [5:35:07<3:40:44, 42.05s/it]Saving the network weights to: ../models/sec_models/only_kill/model-484.pth
Results:
  total_reward: 10.0, step_mean: 0.006381620931716656
  total_deaths: 841.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 335.13 minutes

Epoch #486
 61%|██████    | 486/800 [5:35:49<3:39:13, 41.89s/it]Saving the network weights to: ../models/sec_models/only_kill/model-485.pth
Results:
  total_reward: 1.0, step_mean: 0.0006455777921239509
  total_deaths: 844.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 335.82 minutes

Epoch #487
Saving the network weights to: ../models/sec_models/only_kill/model-486.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 846.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 336.52 minutes

Epoch #488
 61%|██████    | 488/800 [5:37:15<3:41:29, 42.59s/it]Saving the network weights to: ../models/sec_models/only_kill/model-487.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 847.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 337.26 minutes

Epoch #489
 61%|██████    | 489/800 [5:37:58<3:41:32, 42.74s/it]Saving the network weights to: ../models/sec_models/only_kill/model-488.pth
Results:
  total_reward: 14.0, step_mean: 0.008985879332477536
  total_deaths: 849.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 337.98 minutes

Epoch #490
 61%|██████▏   | 490/800 [5:38:40<3:39:40, 42.52s/it]Saving the network weights to: ../models/sec_models/only_kill/model-489.pth
Results:
  total_reward: 7.0, step_mean: 0.004467134652201659
  total_deaths: 850.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 338.68 minutes

Epoch #491
Saving the network weights to: ../models/sec_models/only_kill/model-490.pth
Results:
  total_reward: 19.0, step_mean: 0.012195121951219513
  total_deaths: 852.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 339.36 minutes

Epoch #492
 62%|██████▏   | 492/800 [5:40:03<3:34:56, 41.87s/it]Saving the network weights to: ../models/sec_models/only_kill/model-491.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 853.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 340.05 minutes

Epoch #493
Saving the network weights to: ../models/sec_models/only_kill/model-492.pth
Results:
  total_reward: 6.0, step_mean: 0.0038314176245210726
  total_deaths: 854.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 340.74 minutes

Epoch #494
 62%|██████▏   | 494/800 [5:41:26<3:32:28, 41.66s/it]Saving the network weights to: ../models/sec_models/only_kill/model-493.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 855.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 341.43 minutes

Epoch #495
 62%|██████▏   | 495/800 [5:42:08<3:32:19, 41.77s/it]Saving the network weights to: ../models/sec_models/only_kill/model-494.pth
Results:
  total_reward: 3.0, step_mean: 0.0019047619047619048
  total_deaths: 855.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 342.13 minutes

Epoch #496
 62%|██████▏   | 496/800 [5:42:49<3:31:23, 41.72s/it]Saving the network weights to: ../models/sec_models/only_kill/model-495.pth
Results:
  total_reward: 7.0, step_mean: 0.004469987228607918
  total_deaths: 856.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 342.83 minutes

Epoch #497
Saving the network weights to: ../models/sec_models/only_kill/model-496.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 857.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 343.52 minutes

Epoch #498
 62%|██████▏   | 498/800 [5:44:12<3:29:07, 41.55s/it]Saving the network weights to: ../models/sec_models/only_kill/model-497.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 858.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 344.21 minutes

Epoch #499
Saving the network weights to: ../models/sec_models/only_kill/model-498.pth
Results:
  total_reward: 5.0, step_mean: 0.0032113037893384713
  total_deaths: 860.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 344.90 minutes

Epoch #500
 62%|██████▎   | 500/800 [5:45:36<3:28:37, 41.73s/it]Saving the network weights to: ../models/sec_models/only_kill/model-499.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 860.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 345.60 minutes

Epoch #501
Saving the network weights to: ../models/sec_models/only_kill/model-500.pth
Results:
  total_reward: 1.0, step_mean: 0.0006451612903225806
  total_deaths: 863.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 346.29 minutes

Epoch #502
 63%|██████▎   | 502/800 [5:47:00<3:29:21, 42.15s/it]Saving the network weights to: ../models/sec_models/only_kill/model-501.pth
Results:
  total_reward: 15.0, step_mean: 0.009683666881859263
  total_deaths: 866.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 347.01 minutes

Epoch #503
Saving the network weights to: ../models/sec_models/only_kill/model-502.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 867.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 347.72 minutes

Epoch #504
 63%|██████▎   | 504/800 [5:48:25<3:28:42, 42.31s/it]Saving the network weights to: ../models/sec_models/only_kill/model-503.pth
Results:
  total_reward: 2.0, step_mean: 0.0012903225806451613
  total_deaths: 870.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 348.43 minutes

Epoch #505
 63%|██████▎   | 505/800 [5:49:09<3:29:58, 42.71s/it]Saving the network weights to: ../models/sec_models/only_kill/model-504.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 871.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 349.16 minutes

Epoch #506
 63%|██████▎   | 506/800 [5:49:53<3:31:25, 43.15s/it]Saving the network weights to: ../models/sec_models/only_kill/model-505.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 873.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 349.89 minutes

Epoch #507
Saving the network weights to: ../models/sec_models/only_kill/model-506.pth
Results:
  total_reward: 1.0, step_mean: 0.0006455777921239509
  total_deaths: 876.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 350.62 minutes

Epoch #508
 64%|██████▎   | 508/800 [5:51:22<3:33:36, 43.89s/it]Saving the network weights to: ../models/sec_models/only_kill/model-507.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 877.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 351.37 minutes

Epoch #509
Saving the network weights to: ../models/sec_models/only_kill/model-508.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 879.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 352.10 minutes

Epoch #510
 64%|██████▍   | 510/800 [5:52:50<3:33:18, 44.13s/it]Saving the network weights to: ../models/sec_models/only_kill/model-509.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 881.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 352.85 minutes

Epoch #511
Saving the network weights to: ../models/sec_models/only_kill/model-510.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 882.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 353.59 minutes

Epoch #512
 64%|██████▍   | 512/800 [5:54:18<3:30:29, 43.85s/it]Saving the network weights to: ../models/sec_models/only_kill/model-511.pth
Results:
  total_reward: 8.0, step_mean: 0.005105296745373325
  total_deaths: 883.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 354.31 minutes

Epoch #513
Saving the network weights to: ../models/sec_models/only_kill/model-512.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 885.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 355.02 minutes

Epoch #514
 64%|██████▍   | 514/800 [5:55:43<3:26:22, 43.30s/it]Saving the network weights to: ../models/sec_models/only_kill/model-513.pth
Results:
  total_reward: 7.0, step_mean: 0.004519044544867657
  total_deaths: 888.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 355.73 minutes

Epoch #515
Saving the network weights to: ../models/sec_models/only_kill/model-514.pth
Results:
  total_reward: 15.0, step_mean: 0.009578544061302681
  total_deaths: 889.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 356.45 minutes

Epoch #516
 64%|██████▍   | 516/800 [5:57:10<3:24:44, 43.26s/it]Saving the network weights to: ../models/sec_models/only_kill/model-515.pth
Results:
  total_reward: 18.0, step_mean: 0.011553273427471117
  total_deaths: 891.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 357.17 minutes

Epoch #517
 65%|██████▍   | 517/800 [5:57:52<3:23:13, 43.09s/it]Saving the network weights to: ../models/sec_models/only_kill/model-516.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 893.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 357.88 minutes

Epoch #518
Saving the network weights to: ../models/sec_models/only_kill/model-517.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 894.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 358.57 minutes

Epoch #519
 65%|██████▍   | 519/800 [5:59:16<3:18:09, 42.31s/it]Saving the network weights to: ../models/sec_models/only_kill/model-518.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 896.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 359.27 minutes

Epoch #520
Saving the network weights to: ../models/sec_models/only_kill/model-519.pth
Results:
  total_reward: 21.0, step_mean: 0.013478818998716302
  total_deaths: 898.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 359.96 minutes

Epoch #521
 65%|██████▌   | 521/800 [6:00:39<3:14:56, 41.92s/it]Saving the network weights to: ../models/sec_models/only_kill/model-520.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 899.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 360.65 minutes

Epoch #522
Saving the network weights to: ../models/sec_models/only_kill/model-521.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 900.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 361.36 minutes

Epoch #523
 65%|██████▌   | 523/800 [6:02:03<3:14:02, 42.03s/it]Saving the network weights to: ../models/sec_models/only_kill/model-522.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 901.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 362.06 minutes

Epoch #524
Saving the network weights to: ../models/sec_models/only_kill/model-523.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 902.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 362.77 minutes

Epoch #525
 66%|██████▌   | 525/800 [6:03:27<3:12:00, 41.89s/it]Saving the network weights to: ../models/sec_models/only_kill/model-524.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 904.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 363.46 minutes

Epoch #526
Saving the network weights to: ../models/sec_models/only_kill/model-525.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 906.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 364.13 minutes

Epoch #527
 66%|██████▌   | 527/800 [6:04:47<3:06:51, 41.07s/it]Saving the network weights to: ../models/sec_models/only_kill/model-526.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 907.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 364.80 minutes

Epoch #528
 66%|██████▌   | 528/800 [6:05:28<3:04:51, 40.78s/it]Saving the network weights to: ../models/sec_models/only_kill/model-527.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 909.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 365.47 minutes

Epoch #529
Saving the network weights to: ../models/sec_models/only_kill/model-528.pth
Results:
  total_reward: 2.0, step_mean: 0.0012903225806451613
  total_deaths: 912.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 366.14 minutes

Epoch #530
 66%|██████▋   | 530/800 [6:06:48<3:02:13, 40.49s/it]Saving the network weights to: ../models/sec_models/only_kill/model-529.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 914.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 366.81 minutes

Epoch #531
Saving the network weights to: ../models/sec_models/only_kill/model-530.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 916.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 367.48 minutes

Epoch #532
 66%|██████▋   | 532/800 [6:08:09<3:00:22, 40.38s/it]Saving the network weights to: ../models/sec_models/only_kill/model-531.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 917.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 368.15 minutes

Epoch #533
Saving the network weights to: ../models/sec_models/only_kill/model-532.pth
Results:
  total_reward: 21.0, step_mean: 0.013409961685823755
  total_deaths: 918.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 368.82 minutes

Epoch #534
 67%|██████▋   | 534/800 [6:09:29<2:58:19, 40.22s/it]Saving the network weights to: ../models/sec_models/only_kill/model-533.pth
Results:
  total_reward: 14.0, step_mean: 0.008985879332477536
  total_deaths: 920.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 369.49 minutes

Epoch #535
Saving the network weights to: ../models/sec_models/only_kill/model-534.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 922.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 370.15 minutes

Epoch #536
 67%|██████▋   | 536/800 [6:10:49<2:56:19, 40.08s/it]Saving the network weights to: ../models/sec_models/only_kill/model-535.pth
Results:
  total_reward: 20.0, step_mean: 0.012836970474967908
  total_deaths: 924.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 370.82 minutes

Epoch #537
Saving the network weights to: ../models/sec_models/only_kill/model-536.pth
Results:
  total_reward: 5.0, step_mean: 0.0031928480204342275
  total_deaths: 925.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 371.49 minutes

Epoch #538
 67%|██████▋   | 538/800 [6:12:10<2:55:54, 40.28s/it]Saving the network weights to: ../models/sec_models/only_kill/model-537.pth
Results:
  total_reward: 8.0, step_mean: 0.005161290322580645
  total_deaths: 928.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 372.17 minutes

Epoch #539
Saving the network weights to: ../models/sec_models/only_kill/model-538.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 930.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 372.83 minutes

Epoch #540
 68%|██████▊   | 540/800 [6:13:30<2:54:04, 40.17s/it]Saving the network weights to: ../models/sec_models/only_kill/model-539.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 931.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 373.50 minutes

Epoch #541
Saving the network weights to: ../models/sec_models/only_kill/model-540.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 932.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 374.18 minutes

Epoch #542
 68%|██████▊   | 542/800 [6:14:50<2:52:58, 40.23s/it]Saving the network weights to: ../models/sec_models/only_kill/model-541.pth
Results:
  total_reward: 9.0, step_mean: 0.005776636713735558
  total_deaths: 934.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 374.85 minutes

Epoch #543
Saving the network weights to: ../models/sec_models/only_kill/model-542.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 936.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 375.51 minutes

Epoch #544
 68%|██████▊   | 544/800 [6:16:11<2:51:51, 40.28s/it]Saving the network weights to: ../models/sec_models/only_kill/model-543.pth
Results:
  total_reward: 4.0, step_mean: 0.0025806451612903226
  total_deaths: 939.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 376.19 minutes

Epoch #545
Saving the network weights to: ../models/sec_models/only_kill/model-544.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 941.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 376.87 minutes

Epoch #546
 68%|██████▊   | 546/800 [6:17:33<2:52:43, 40.80s/it]Saving the network weights to: ../models/sec_models/only_kill/model-545.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 942.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 377.56 minutes

Epoch #547
Saving the network weights to: ../models/sec_models/only_kill/model-546.pth
 68%|██████▊   | 547/800 [6:18:13<2:50:35, 40.46s/it]Results:
  total_reward: 3.0, step_mean: 0.0019047619047619048
  total_deaths: 942.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 378.22 minutes

Epoch #548
Saving the network weights to: ../models/sec_models/only_kill/model-547.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 944.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 378.87 minutes

Epoch #549
 69%|██████▊   | 549/800 [6:19:30<2:45:37, 39.59s/it]Saving the network weights to: ../models/sec_models/only_kill/model-548.pth
Results:
  total_reward: 17.0, step_mean: 0.010911424903722721
  total_deaths: 946.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 379.52 minutes

Epoch #550
Saving the network weights to: ../models/sec_models/only_kill/model-549.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 948.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 380.16 minutes

Epoch #551
 69%|██████▉   | 551/800 [6:20:48<2:42:02, 39.05s/it]Saving the network weights to: ../models/sec_models/only_kill/model-550.pth
Results:
  total_reward: 14.0, step_mean: 0.00903225806451613
  total_deaths: 951.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 380.80 minutes

Epoch #552
Saving the network weights to: ../models/sec_models/only_kill/model-551.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 953.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 381.45 minutes

Epoch #553
 69%|██████▉   | 553/800 [6:22:05<2:39:49, 38.82s/it]Saving the network weights to: ../models/sec_models/only_kill/model-552.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 956.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 382.09 minutes

Epoch #554
 69%|██████▉   | 554/800 [6:22:44<2:39:09, 38.82s/it]Saving the network weights to: ../models/sec_models/only_kill/model-553.pth
Results:
  total_reward: 4.0, step_mean: 0.002569043031470777
  total_deaths: 958.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 382.74 minutes

Epoch #555
 69%|██████▉   | 555/800 [6:23:23<2:38:41, 38.86s/it]Saving the network weights to: ../models/sec_models/only_kill/model-554.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 959.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 383.39 minutes

Epoch #556
 70%|██████▉   | 556/800 [6:24:01<2:37:57, 38.84s/it]Saving the network weights to: ../models/sec_models/only_kill/model-555.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 961.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 384.03 minutes

Epoch #557
Saving the network weights to: ../models/sec_models/only_kill/model-556.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 962.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 384.68 minutes

Epoch #558
 70%|██████▉   | 558/800 [6:25:19<2:36:34, 38.82s/it]Saving the network weights to: ../models/sec_models/only_kill/model-557.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 964.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 385.33 minutes

Epoch #559
 70%|██████▉   | 559/800 [6:25:58<2:35:46, 38.78s/it]Saving the network weights to: ../models/sec_models/only_kill/model-558.pth
Results:
  total_reward: 19.0, step_mean: 0.012258064516129033
  total_deaths: 967.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 385.97 minutes

Epoch #560
Saving the network weights to: ../models/sec_models/only_kill/model-559.pth
Results:
  total_reward: 3.0, step_mean: 0.001936733376371853
  total_deaths: 970.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 386.62 minutes

Epoch #561
 70%|███████   | 561/800 [6:27:15<2:34:25, 38.77s/it]Saving the network weights to: ../models/sec_models/only_kill/model-560.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 972.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 387.26 minutes

Epoch #562
Saving the network weights to: ../models/sec_models/only_kill/model-561.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 973.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 387.91 minutes

Epoch #563
 70%|███████   | 563/800 [6:28:33<2:33:04, 38.75s/it]Saving the network weights to: ../models/sec_models/only_kill/model-562.pth
Results:
  total_reward: 1.0, step_mean: 0.0006414368184733803
  total_deaths: 975.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 388.55 minutes

Epoch #564
 70%|███████   | 564/800 [6:29:12<2:32:34, 38.79s/it]Saving the network weights to: ../models/sec_models/only_kill/model-563.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 976.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 389.20 minutes

Epoch #565
Saving the network weights to: ../models/sec_models/only_kill/model-564.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 978.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 389.85 minutes

Epoch #566
 71%|███████   | 566/800 [6:30:29<2:31:28, 38.84s/it]Saving the network weights to: ../models/sec_models/only_kill/model-565.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 981.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 390.50 minutes

Epoch #567
Saving the network weights to: ../models/sec_models/only_kill/model-566.pth
Results:
  total_reward: 3.0, step_mean: 0.001936733376371853
  total_deaths: 984.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 391.14 minutes

Epoch #568
 71%|███████   | 568/800 [6:31:47<2:29:48, 38.74s/it]Saving the network weights to: ../models/sec_models/only_kill/model-567.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 985.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 391.79 minutes

Epoch #569
Saving the network weights to: ../models/sec_models/only_kill/model-568.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 987.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 392.43 minutes

Epoch #570
 71%|███████▏  | 570/800 [6:33:04<2:28:44, 38.80s/it]Saving the network weights to: ../models/sec_models/only_kill/model-569.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 988.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 393.08 minutes

Epoch #571
 71%|███████▏  | 571/800 [6:33:44<2:28:54, 39.01s/it]Saving the network weights to: ../models/sec_models/only_kill/model-570.pth
Results:
  total_reward: 14.0, step_mean: 0.00903225806451613
  total_deaths: 991.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 393.74 minutes

Epoch #572
 72%|███████▏  | 572/800 [6:34:24<2:29:28, 39.34s/it]Saving the network weights to: ../models/sec_models/only_kill/model-571.pth
Results:
  total_reward: 16.0, step_mean: 0.010217113665389528
  total_deaths: 992.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 394.41 minutes

Epoch #573
Saving the network weights to: ../models/sec_models/only_kill/model-572.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 993.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 395.07 minutes

Epoch #574
 72%|███████▏  | 574/800 [6:35:43<2:28:54, 39.53s/it]Saving the network weights to: ../models/sec_models/only_kill/model-573.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 994.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 395.73 minutes

Epoch #575
Saving the network weights to: ../models/sec_models/only_kill/model-574.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 995.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 396.40 minutes

Epoch #576
 72%|███████▏  | 576/800 [6:37:02<2:26:54, 39.35s/it]Saving the network weights to: ../models/sec_models/only_kill/model-575.pth
Results:
  total_reward: 11.0, step_mean: 0.007060333761232349
  total_deaths: 997.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 397.04 minutes

Epoch #577
Saving the network weights to: ../models/sec_models/only_kill/model-576.pth
Results:
  total_reward: 10.0, step_mean: 0.006418485237483954
  total_deaths: 999.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 397.70 minutes

Epoch #578
 72%|███████▏  | 578/800 [6:38:21<2:26:22, 39.56s/it]Saving the network weights to: ../models/sec_models/only_kill/model-577.pth
Results:
  total_reward: 5.0, step_mean: 0.003207184092366902
  total_deaths: 1001.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 398.37 minutes

Epoch #579
Saving the network weights to: ../models/sec_models/only_kill/model-578.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 1003.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 399.03 minutes

Epoch #580
 72%|███████▎  | 580/800 [6:39:41<2:25:33, 39.70s/it]Saving the network weights to: ../models/sec_models/only_kill/model-579.pth
Results:
  total_reward: 12.0, step_mean: 0.007662835249042145
  total_deaths: 1004.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 399.69 minutes

Epoch #581
Saving the network weights to: ../models/sec_models/only_kill/model-580.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 1005.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 400.36 minutes

Epoch #582
 73%|███████▎  | 582/800 [6:41:00<2:23:48, 39.58s/it]Saving the network weights to: ../models/sec_models/only_kill/model-581.pth
Results:
  total_reward: 3.0, step_mean: 0.001936733376371853
  total_deaths: 1008.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 401.01 minutes

Epoch #583
 73%|███████▎  | 583/800 [6:41:40<2:23:23, 39.65s/it]Saving the network weights to: ../models/sec_models/only_kill/model-582.pth
Results:
  total_reward: 3.0, step_mean: 0.001924310455420141
  total_deaths: 1010.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 401.67 minutes

Epoch #584
Saving the network weights to: ../models/sec_models/only_kill/model-583.pth
Results:
  total_reward: 9.0, step_mean: 0.00574345883854499
  total_deaths: 1011.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 402.34 minutes

Epoch #585
 73%|███████▎  | 585/800 [6:42:59<2:21:20, 39.44s/it]Saving the network weights to: ../models/sec_models/only_kill/model-584.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 1014.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 402.98 minutes

Epoch #586
Saving the network weights to: ../models/sec_models/only_kill/model-585.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1016.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 403.64 minutes

Epoch #587
 73%|███████▎  | 587/800 [6:44:19<2:21:06, 39.75s/it]Saving the network weights to: ../models/sec_models/only_kill/model-586.pth
Results:
  total_reward: 4.0, step_mean: 0.0025396825396825397
  total_deaths: 1016.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 404.32 minutes

Epoch #588
Saving the network weights to: ../models/sec_models/only_kill/model-587.pth
Results:
  total_reward: 3.0, step_mean: 0.001946787800129786
  total_deaths: 1020.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 404.97 minutes

Epoch #589
 74%|███████▎  | 589/800 [6:45:37<2:18:56, 39.51s/it]Saving the network weights to: ../models/sec_models/only_kill/model-588.pth
Results:
  total_reward: 1.0, step_mean: 0.0006451612903225806
  total_deaths: 1023.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 405.63 minutes

Epoch #590
Saving the network weights to: ../models/sec_models/only_kill/model-589.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1025.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 406.33 minutes

Epoch #591
 74%|███████▍  | 591/800 [6:47:02<2:23:11, 41.11s/it]Saving the network weights to: ../models/sec_models/only_kill/model-590.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 1026.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 407.04 minutes

Epoch #592
Saving the network weights to: ../models/sec_models/only_kill/model-591.pth
Results:
  total_reward: 4.0, step_mean: 0.0025806451612903226
  total_deaths: 1029.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 407.74 minutes

Epoch #593
 74%|███████▍  | 593/800 [6:48:27<2:24:06, 41.77s/it]Saving the network weights to: ../models/sec_models/only_kill/model-592.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1031.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 408.46 minutes

Epoch #594
 74%|███████▍  | 594/800 [6:49:08<2:22:16, 41.44s/it]Saving the network weights to: ../models/sec_models/only_kill/model-593.pth
Results:
  total_reward: 6.0, step_mean: 0.003873466752743706
  total_deaths: 1034.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 409.13 minutes

Epoch #595
 74%|███████▍  | 595/800 [6:49:48<2:20:48, 41.21s/it]Saving the network weights to: ../models/sec_models/only_kill/model-594.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1037.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 409.81 minutes

Epoch #596
Saving the network weights to: ../models/sec_models/only_kill/model-595.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1038.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 410.50 minutes

Epoch #597
 75%|███████▍  | 597/800 [6:51:11<2:19:26, 41.21s/it]Saving the network weights to: ../models/sec_models/only_kill/model-596.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1040.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 411.19 minutes

Epoch #598
Saving the network weights to: ../models/sec_models/only_kill/model-597.pth
Results:
  total_reward: 5.0, step_mean: 0.003244646333549643
  total_deaths: 1044.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 411.91 minutes

Epoch #599
 75%|███████▍  | 599/800 [6:52:35<2:19:35, 41.67s/it]Saving the network weights to: ../models/sec_models/only_kill/model-598.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 1046.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 412.60 minutes

Epoch #600
Saving the network weights to: ../models/sec_models/only_kill/model-599.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 1048.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 413.27 minutes

Epoch #601
 75%|███████▌  | 601/800 [6:53:57<2:16:37, 41.19s/it]Saving the network weights to: ../models/sec_models/only_kill/model-600.pth
Results:
  total_reward: 14.0, step_mean: 0.008934269304403318
  total_deaths: 1049.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 413.95 minutes

Epoch #602
Saving the network weights to: ../models/sec_models/only_kill/model-601.pth
Results:
  total_reward: 21.0, step_mean: 0.013565891472868217
  total_deaths: 1052.0
  frag: 1.0
  death: 3.0
  global_step: 1548
Total elapsed time: 414.63 minutes

Epoch #603
 75%|███████▌  | 603/800 [6:55:18<2:14:15, 40.89s/it]Saving the network weights to: ../models/sec_models/only_kill/model-602.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1053.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 415.31 minutes

Epoch #604
Saving the network weights to: ../models/sec_models/only_kill/model-603.pth
Results:
  total_reward: 5.0, step_mean: 0.003190810465858328
  total_deaths: 1054.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 416.00 minutes

Epoch #605
 76%|███████▌  | 605/800 [6:56:42<2:14:50, 41.49s/it]Saving the network weights to: ../models/sec_models/only_kill/model-604.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 1056.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 416.71 minutes

Epoch #606
 76%|███████▌  | 606/800 [6:57:26<2:16:55, 42.35s/it]Saving the network weights to: ../models/sec_models/only_kill/model-605.pth
Results:
  total_reward: 5.0, step_mean: 0.0032278889606197547
  total_deaths: 1059.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 417.45 minutes

Epoch #607
Saving the network weights to: ../models/sec_models/only_kill/model-606.pth
Results:
  total_reward: 2.0, step_mean: 0.0012828736369467607
  total_deaths: 1061.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 418.15 minutes

Epoch #608
 76%|███████▌  | 608/800 [6:58:49<2:14:00, 41.88s/it]Saving the network weights to: ../models/sec_models/only_kill/model-607.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 1062.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 418.83 minutes

Epoch #609
 76%|███████▌  | 609/800 [6:59:30<2:12:18, 41.56s/it]Saving the network weights to: ../models/sec_models/only_kill/model-608.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 1063.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 419.51 minutes

Epoch #610
Saving the network weights to: ../models/sec_models/only_kill/model-609.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 1064.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 420.19 minutes

Epoch #611
 76%|███████▋  | 611/800 [7:00:51<2:08:57, 40.94s/it]Saving the network weights to: ../models/sec_models/only_kill/model-610.pth
Results:
  total_reward: 7.0, step_mean: 0.004516129032258065
  total_deaths: 1067.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 420.86 minutes

Epoch #612
Saving the network weights to: ../models/sec_models/only_kill/model-611.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 1068.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 421.54 minutes

Epoch #613
 77%|███████▋  | 613/800 [7:02:13<2:07:52, 41.03s/it]Saving the network weights to: ../models/sec_models/only_kill/model-612.pth
Results:
  total_reward: 5.0, step_mean: 0.0032278889606197547
  total_deaths: 1071.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 422.23 minutes

Epoch #614
Saving the network weights to: ../models/sec_models/only_kill/model-613.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 1072.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 422.93 minutes

Epoch #615
 77%|███████▋  | 615/800 [7:03:37<2:07:29, 41.35s/it]Saving the network weights to: ../models/sec_models/only_kill/model-614.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 1074.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 423.62 minutes

Epoch #616
Saving the network weights to: ../models/sec_models/only_kill/model-615.pth
Results:
  total_reward: 18.0, step_mean: 0.011553273427471117
  total_deaths: 1076.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 424.30 minutes

Epoch #617
 77%|███████▋  | 617/800 [7:04:59<2:05:45, 41.23s/it]Saving the network weights to: ../models/sec_models/only_kill/model-616.pth
Results:
  total_reward: 6.0, step_mean: 0.0038289725590299937
  total_deaths: 1077.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 424.99 minutes

Epoch #618
Saving the network weights to: ../models/sec_models/only_kill/model-617.pth
 77%|███████▋  | 618/800 [7:05:40<2:05:05, 41.24s/it]Results:
  total_reward: 7.0, step_mean: 0.004490057729313663
  total_deaths: 1079.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 425.68 minutes

Epoch #619
Saving the network weights to: ../models/sec_models/only_kill/model-618.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 1080.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 426.37 minutes

Epoch #620
 78%|███████▊  | 620/800 [7:07:03<2:04:04, 41.36s/it]Saving the network weights to: ../models/sec_models/only_kill/model-619.pth
Results:
  total_reward: 5.0, step_mean: 0.0031928480204342275
  total_deaths: 1081.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 427.06 minutes

Epoch #621
 78%|███████▊  | 621/800 [7:07:45<2:04:07, 41.61s/it]Saving the network weights to: ../models/sec_models/only_kill/model-620.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 1083.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 427.76 minutes

Epoch #622
Saving the network weights to: ../models/sec_models/only_kill/model-621.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 1084.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 428.45 minutes

Epoch #623
 78%|███████▊  | 623/800 [7:09:08<2:01:59, 41.35s/it]Saving the network weights to: ../models/sec_models/only_kill/model-622.pth
Results:
  total_reward: 7.0, step_mean: 0.004467134652201659
  total_deaths: 1085.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 429.13 minutes

Epoch #624
Saving the network weights to: ../models/sec_models/only_kill/model-623.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1086.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 429.81 minutes

Epoch #625
 78%|███████▊  | 625/800 [7:10:28<1:58:52, 40.76s/it]Saving the network weights to: ../models/sec_models/only_kill/model-624.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1087.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 430.48 minutes

Epoch #626
Saving the network weights to: ../models/sec_models/only_kill/model-625.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1089.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 431.14 minutes

Epoch #627
 78%|███████▊  | 627/800 [7:11:47<1:55:57, 40.22s/it]Saving the network weights to: ../models/sec_models/only_kill/model-626.pth
Results:
  total_reward: 1.0, step_mean: 0.0006455777921239509
  total_deaths: 1092.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 431.80 minutes

Epoch #628
 78%|███████▊  | 628/800 [7:12:27<1:55:07, 40.16s/it]Saving the network weights to: ../models/sec_models/only_kill/model-627.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1093.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 432.47 minutes

Epoch #629
 79%|███████▊  | 629/800 [7:13:07<1:54:10, 40.06s/it]Saving the network weights to: ../models/sec_models/only_kill/model-628.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1094.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 433.13 minutes

Epoch #630
Saving the network weights to: ../models/sec_models/only_kill/model-629.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 1095.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 433.82 minutes

Epoch #631
 79%|███████▉  | 631/800 [7:14:28<1:53:02, 40.13s/it]Saving the network weights to: ../models/sec_models/only_kill/model-630.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1098.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 434.48 minutes

Epoch #632
Saving the network weights to: ../models/sec_models/only_kill/model-631.pth
Results:
  total_reward: 5.0, step_mean: 0.003190810465858328
  total_deaths: 1099.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 435.14 minutes

Epoch #633
 79%|███████▉  | 633/800 [7:15:47<1:51:03, 39.90s/it]Saving the network weights to: ../models/sec_models/only_kill/model-632.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 1101.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 435.80 minutes

Epoch #634
 79%|███████▉  | 634/800 [7:16:28<1:50:34, 39.97s/it]Saving the network weights to: ../models/sec_models/only_kill/model-633.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 1102.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 436.47 minutes

Epoch #635
 79%|███████▉  | 635/800 [7:17:07<1:49:50, 39.94s/it]Saving the network weights to: ../models/sec_models/only_kill/model-634.pth
Results:
  total_reward: 5.0, step_mean: 0.003207184092366902
  total_deaths: 1104.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 437.13 minutes

Epoch #636
Saving the network weights to: ../models/sec_models/only_kill/model-635.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 1105.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 437.80 minutes

Epoch #637
 80%|███████▉  | 637/800 [7:18:30<1:50:34, 40.70s/it]Saving the network weights to: ../models/sec_models/only_kill/model-636.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1106.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 438.51 minutes

Epoch #638
Saving the network weights to: ../models/sec_models/only_kill/model-637.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 1107.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 439.18 minutes

Epoch #639
 80%|███████▉  | 639/800 [7:19:50<1:48:32, 40.45s/it]Saving the network weights to: ../models/sec_models/only_kill/model-638.pth
Results:
  total_reward: 3.0, step_mean: 0.0019267822736030828
  total_deaths: 1109.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 439.85 minutes

Epoch #640
Saving the network weights to: ../models/sec_models/only_kill/model-639.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1111.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 440.52 minutes

Epoch #641
 80%|████████  | 641/800 [7:21:10<1:46:37, 40.24s/it]Saving the network weights to: ../models/sec_models/only_kill/model-640.pth
Results:
  total_reward: 2.0, step_mean: 0.0012845215157353885
  total_deaths: 1113.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 441.18 minutes

Epoch #642
Saving the network weights to: ../models/sec_models/only_kill/model-641.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 1115.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 441.86 minutes

Epoch #643
 80%|████████  | 643/800 [7:22:31<1:45:04, 40.16s/it]Saving the network weights to: ../models/sec_models/only_kill/model-642.pth
Results:
  total_reward: 8.0, step_mean: 0.005134788189987163
  total_deaths: 1117.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 442.52 minutes

Epoch #644
 80%|████████  | 644/800 [7:23:11<1:44:19, 40.12s/it]Saving the network weights to: ../models/sec_models/only_kill/model-643.pth
Results:
  total_reward: 10.0, step_mean: 0.006422607578676943
  total_deaths: 1119.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 443.19 minutes

Epoch #645
Saving the network weights to: ../models/sec_models/only_kill/model-644.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 1121.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 443.88 minutes

Epoch #646
 81%|████████  | 646/800 [7:24:33<1:43:54, 40.48s/it]Saving the network weights to: ../models/sec_models/only_kill/model-645.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 1124.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 444.55 minutes

Epoch #647
 81%|████████  | 647/800 [7:25:13<1:43:24, 40.55s/it]Saving the network weights to: ../models/sec_models/only_kill/model-646.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1124.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 445.23 minutes

Epoch #648
 81%|████████  | 648/800 [7:25:55<1:43:19, 40.78s/it]Saving the network weights to: ../models/sec_models/only_kill/model-647.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 1125.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 445.92 minutes

Epoch #649
 81%|████████  | 649/800 [7:26:36<1:43:16, 41.04s/it]Saving the network weights to: ../models/sec_models/only_kill/model-648.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1126.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 446.61 minutes

Epoch #650
 81%|████████▏ | 650/800 [7:27:17<1:42:23, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill/model-649.pth
Results:
  total_reward: 15.0, step_mean: 0.009578544061302681
  total_deaths: 1127.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 447.29 minutes

Epoch #651
Saving the network weights to: ../models/sec_models/only_kill/model-650.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 1129.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 447.96 minutes

Epoch #652
 82%|████████▏ | 652/800 [7:28:38<1:40:22, 40.70s/it]Saving the network weights to: ../models/sec_models/only_kill/model-651.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 1130.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 448.64 minutes

Epoch #653
 82%|████████▏ | 653/800 [7:29:19<1:40:12, 40.90s/it]Saving the network weights to: ../models/sec_models/only_kill/model-652.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1132.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 449.33 minutes

Epoch #654
Saving the network weights to: ../models/sec_models/only_kill/model-653.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1134.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 449.99 minutes

Epoch #655
 82%|████████▏ | 655/800 [7:30:38<1:37:04, 40.17s/it]Saving the network weights to: ../models/sec_models/only_kill/model-654.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 1137.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 450.64 minutes

Epoch #656
Saving the network weights to: ../models/sec_models/only_kill/model-655.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1138.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 451.32 minutes

Epoch #657
 82%|████████▏ | 657/800 [7:32:00<1:36:31, 40.50s/it]Saving the network weights to: ../models/sec_models/only_kill/model-656.pth
Results:
  total_reward: 2.0, step_mean: 0.0012903225806451613
  total_deaths: 1141.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 452.00 minutes

Epoch #658
Saving the network weights to: ../models/sec_models/only_kill/model-657.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 1143.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 452.69 minutes

Epoch #659
 82%|████████▏ | 659/800 [7:33:22<1:36:01, 40.86s/it]Saving the network weights to: ../models/sec_models/only_kill/model-658.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1144.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 453.38 minutes

Epoch #660
 82%|████████▎ | 660/800 [7:34:03<1:35:17, 40.84s/it]Saving the network weights to: ../models/sec_models/only_kill/model-659.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 1145.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 454.06 minutes

Epoch #661
Saving the network weights to: ../models/sec_models/only_kill/model-660.pth
Results:
  total_reward: 2.0, step_mean: 0.0012698412698412698
  total_deaths: 1145.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 454.74 minutes

Epoch #662
 83%|████████▎ | 662/800 [7:35:26<1:34:33, 41.11s/it]Saving the network weights to: ../models/sec_models/only_kill/model-661.pth
Results:
  total_reward: 3.0, step_mean: 0.0019157088122605363
  total_deaths: 1146.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 455.44 minutes

Epoch #663
Saving the network weights to: ../models/sec_models/only_kill/model-662.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 1148.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 456.13 minutes

Epoch #664
 83%|████████▎ | 664/800 [7:36:47<1:32:19, 40.73s/it]Saving the network weights to: ../models/sec_models/only_kill/model-663.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1149.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 456.79 minutes

Epoch #665
Saving the network weights to: ../models/sec_models/only_kill/model-664.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1149.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 457.45 minutes

Epoch #666
 83%|████████▎ | 666/800 [7:38:06<1:29:47, 40.20s/it]Saving the network weights to: ../models/sec_models/only_kill/model-665.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 1152.0
  frag: 0.0
  death: 3.0
  global_step: 1558
Total elapsed time: 458.11 minutes

Epoch #667
Saving the network weights to: ../models/sec_models/only_kill/model-666.pth
Results:
  total_reward: 8.0, step_mean: 0.005161290322580645
  total_deaths: 1155.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 458.78 minutes

Epoch #668
 84%|████████▎ | 668/800 [7:39:26<1:28:03, 40.02s/it]Saving the network weights to: ../models/sec_models/only_kill/model-667.pth
Results:
  total_reward: 3.0, step_mean: 0.001924310455420141
  total_deaths: 1157.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 459.44 minutes

Epoch #669
 84%|████████▎ | 669/800 [7:40:06<1:27:30, 40.08s/it]Saving the network weights to: ../models/sec_models/only_kill/model-668.pth
Results:
  total_reward: 3.0, step_mean: 0.0019047619047619048
  total_deaths: 1157.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 460.11 minutes

Epoch #670
Saving the network weights to: ../models/sec_models/only_kill/model-669.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 1159.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 460.77 minutes

Epoch #671
 84%|████████▍ | 671/800 [7:41:25<1:25:06, 39.58s/it]Saving the network weights to: ../models/sec_models/only_kill/model-670.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1162.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 461.42 minutes

Epoch #672
Saving the network weights to: ../models/sec_models/only_kill/model-671.pth
Results:
  total_reward: 4.0, step_mean: 0.0025806451612903226
  total_deaths: 1165.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 462.06 minutes

Epoch #673
 84%|████████▍ | 673/800 [7:42:43<1:23:21, 39.38s/it]Saving the network weights to: ../models/sec_models/only_kill/model-672.pth
Results:
  total_reward: 3.0, step_mean: 0.0019047619047619048
  total_deaths: 1165.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 462.72 minutes

Epoch #674
 84%|████████▍ | 674/800 [7:43:23<1:23:06, 39.57s/it]Saving the network weights to: ../models/sec_models/only_kill/model-673.pth
Results:
  total_reward: 5.0, step_mean: 0.003190810465858328
  total_deaths: 1166.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 463.39 minutes

Epoch #675
Saving the network weights to: ../models/sec_models/only_kill/model-674.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1168.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 464.06 minutes

Epoch #676
 84%|████████▍ | 676/800 [7:44:43<1:22:07, 39.74s/it]Saving the network weights to: ../models/sec_models/only_kill/model-675.pth
Results:
  total_reward: 1.0, step_mean: 0.0006422607578676942
  total_deaths: 1170.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 464.72 minutes

Epoch #677
Saving the network weights to: ../models/sec_models/only_kill/model-676.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1172.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 465.39 minutes

Epoch #678
 85%|████████▍ | 678/800 [7:46:04<1:21:37, 40.15s/it]Saving the network weights to: ../models/sec_models/only_kill/model-677.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1173.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 466.07 minutes

Epoch #679
Saving the network weights to: ../models/sec_models/only_kill/model-678.pth
Results:
  total_reward: 6.0, step_mean: 0.0038510911424903724
  total_deaths: 1175.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 466.74 minutes

Epoch #680
 85%|████████▌ | 680/800 [7:47:25<1:20:34, 40.29s/it]Saving the network weights to: ../models/sec_models/only_kill/model-679.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 1176.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 467.42 minutes

Epoch #681
 85%|████████▌ | 681/800 [7:48:06<1:20:31, 40.60s/it]Saving the network weights to: ../models/sec_models/only_kill/model-680.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 1177.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 468.11 minutes

Epoch #682
Saving the network weights to: ../models/sec_models/only_kill/model-681.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 1178.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 468.78 minutes

Epoch #683
 85%|████████▌ | 683/800 [7:49:26<1:18:41, 40.35s/it]Saving the network weights to: ../models/sec_models/only_kill/model-682.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 1180.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 469.45 minutes

Epoch #684
 86%|████████▌ | 684/800 [7:50:06<1:17:37, 40.15s/it]Saving the network weights to: ../models/sec_models/only_kill/model-683.pth
Results:
  total_reward: 2.0, step_mean: 0.0012911555842479018
  total_deaths: 1183.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 470.11 minutes

Epoch #685
Saving the network weights to: ../models/sec_models/only_kill/model-684.pth
Results:
  total_reward: 7.0, step_mean: 0.004519044544867657
  total_deaths: 1186.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 470.76 minutes

Epoch #686
 86%|████████▌ | 686/800 [7:51:24<1:15:28, 39.73s/it]Saving the network weights to: ../models/sec_models/only_kill/model-685.pth
Results:
  total_reward: 11.0, step_mean: 0.006984126984126984
  total_deaths: 1186.0
  frag: 1.0
  death: 0.0
  global_step: 1575
Total elapsed time: 471.42 minutes

Epoch #687
 86%|████████▌ | 687/800 [7:52:04<1:14:36, 39.62s/it]Saving the network weights to: ../models/sec_models/only_kill/model-686.pth
Results:
  total_reward: 6.0, step_mean: 0.0038314176245210726
  total_deaths: 1187.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 472.07 minutes

Epoch #688
Saving the network weights to: ../models/sec_models/only_kill/model-687.pth
Results:
  total_reward: 10.0, step_mean: 0.0064516129032258064
  total_deaths: 1190.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 472.73 minutes

Epoch #689
 86%|████████▌ | 689/800 [7:53:22<1:12:59, 39.46s/it]Saving the network weights to: ../models/sec_models/only_kill/model-688.pth
Results:
  total_reward: 8.0, step_mean: 0.005134788189987163
  total_deaths: 1192.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 473.38 minutes

Epoch #690
Saving the network weights to: ../models/sec_models/only_kill/model-689.pth
Results:
  total_reward: 6.0, step_mean: 0.0038314176245210726
  total_deaths: 1193.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 474.04 minutes

Epoch #691
 86%|████████▋ | 691/800 [7:54:42<1:11:52, 39.56s/it]Saving the network weights to: ../models/sec_models/only_kill/model-690.pth
Results:
  total_reward: 5.0, step_mean: 0.003190810465858328
  total_deaths: 1194.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 474.70 minutes

Epoch #692
Saving the network weights to: ../models/sec_models/only_kill/model-691.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1196.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 475.40 minutes

Epoch #693
 87%|████████▋ | 693/800 [7:56:04<1:11:53, 40.31s/it]Saving the network weights to: ../models/sec_models/only_kill/model-692.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1198.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 476.07 minutes

Epoch #694
Saving the network weights to: ../models/sec_models/only_kill/model-693.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 1199.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 476.75 minutes

Epoch #695
 87%|████████▋ | 695/800 [7:57:25<1:10:37, 40.36s/it]Saving the network weights to: ../models/sec_models/only_kill/model-694.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 1201.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 477.42 minutes

Epoch #696
Saving the network weights to: ../models/sec_models/only_kill/model-695.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 1202.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 478.09 minutes

Epoch #697
 87%|████████▋ | 697/800 [7:58:45<1:09:09, 40.28s/it]Saving the network weights to: ../models/sec_models/only_kill/model-696.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 1203.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 478.76 minutes

Epoch #698
Saving the network weights to: ../models/sec_models/only_kill/model-697.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 1204.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 479.43 minutes

Epoch #699
 87%|████████▋ | 699/800 [8:00:05<1:07:31, 40.11s/it]Saving the network weights to: ../models/sec_models/only_kill/model-698.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1207.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 480.09 minutes

Epoch #700
Saving the network weights to: ../models/sec_models/only_kill/model-699.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 1209.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 480.75 minutes

Epoch #701
 88%|████████▊ | 701/800 [8:01:24<1:05:38, 39.79s/it]Saving the network weights to: ../models/sec_models/only_kill/model-700.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 1211.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 481.41 minutes

Epoch #702
 88%|████████▊ | 702/800 [8:02:04<1:04:53, 39.73s/it]Saving the network weights to: ../models/sec_models/only_kill/model-701.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 1212.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 482.07 minutes

Epoch #703
Saving the network weights to: ../models/sec_models/only_kill/model-702.pth
Results:
  total_reward: 4.0, step_mean: 0.0025974025974025974
  total_deaths: 1216.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 482.72 minutes

Epoch #704
 88%|████████▊ | 704/800 [8:03:22<1:03:23, 39.61s/it]Saving the network weights to: ../models/sec_models/only_kill/model-703.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1217.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 483.38 minutes

Epoch #705
Saving the network weights to: ../models/sec_models/only_kill/model-704.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1219.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 484.05 minutes

Epoch #706
 88%|████████▊ | 706/800 [8:04:42<1:02:19, 39.78s/it]Saving the network weights to: ../models/sec_models/only_kill/model-705.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1221.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 484.71 minutes

Epoch #707
Saving the network weights to: ../models/sec_models/only_kill/model-706.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 1223.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 485.38 minutes

Epoch #708
 88%|████████▊ | 708/800 [8:06:02<1:01:15, 39.95s/it]Saving the network weights to: ../models/sec_models/only_kill/model-707.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1224.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 486.05 minutes

Epoch #709
Saving the network weights to: ../models/sec_models/only_kill/model-708.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 1226.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 486.72 minutes

Epoch #710
 89%|████████▉ | 710/800 [8:07:24<1:00:33, 40.38s/it]Saving the network weights to: ../models/sec_models/only_kill/model-709.pth
Results:
  total_reward: 35.0, step_mean: 0.022464698331193838
  total_deaths: 1228.0
  frag: 2.0
  death: 2.0
  global_step: 1558
Total elapsed time: 487.40 minutes

Epoch #711
Saving the network weights to: ../models/sec_models/only_kill/model-710.pth
Results:
  total_reward: 9.0, step_mean: 0.005776636713735558
  total_deaths: 1230.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 488.10 minutes

Epoch #712
 89%|████████▉ | 712/800 [8:08:45<59:22, 40.48s/it]  Saving the network weights to: ../models/sec_models/only_kill/model-711.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1233.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 488.76 minutes

Epoch #713
 89%|████████▉ | 713/800 [8:09:26<58:55, 40.64s/it]Saving the network weights to: ../models/sec_models/only_kill/model-712.pth
Results:
  total_reward: 3.0, step_mean: 0.0019047619047619048
  total_deaths: 1233.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 489.45 minutes

Epoch #714
 89%|████████▉ | 714/800 [8:10:07<58:16, 40.66s/it]Saving the network weights to: ../models/sec_models/only_kill/model-713.pth
Results:
  total_reward: 3.0, step_mean: 0.001924310455420141
  total_deaths: 1235.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 490.13 minutes

Epoch #715
Saving the network weights to: ../models/sec_models/only_kill/model-714.pth
Results:
  total_reward: 17.0, step_mean: 0.010911424903722721
  total_deaths: 1237.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 490.82 minutes

Epoch #716
 90%|████████▉ | 716/800 [8:11:29<56:58, 40.69s/it]Saving the network weights to: ../models/sec_models/only_kill/model-715.pth
Results:
  total_reward: 4.0, step_mean: 0.0025823111684958036
  total_deaths: 1240.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 491.49 minutes

Epoch #717
Saving the network weights to: ../models/sec_models/only_kill/model-716.pth
Results:
  total_reward: 17.0, step_mean: 0.010848755583918315
  total_deaths: 1241.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 492.17 minutes

Epoch #718
 90%|████████▉ | 718/800 [8:12:51<55:59, 40.97s/it]Saving the network weights to: ../models/sec_models/only_kill/model-717.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 1242.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 492.86 minutes

Epoch #719
 90%|████████▉ | 719/800 [8:13:32<55:06, 40.82s/it]Saving the network weights to: ../models/sec_models/only_kill/model-718.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 1244.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 493.54 minutes

Epoch #720
 90%|█████████ | 720/800 [8:14:12<54:23, 40.80s/it]Saving the network weights to: ../models/sec_models/only_kill/model-719.pth
Results:
  total_reward: 5.0, step_mean: 0.0032113037893384713
  total_deaths: 1246.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 494.21 minutes

Epoch #721
Saving the network weights to: ../models/sec_models/only_kill/model-720.pth
Results:
  total_reward: 6.0, step_mean: 0.0038314176245210726
  total_deaths: 1247.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 494.89 minutes

Epoch #722
 90%|█████████ | 722/800 [8:15:32<52:30, 40.39s/it]Saving the network weights to: ../models/sec_models/only_kill/model-721.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 1249.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 495.55 minutes

Epoch #723
Saving the network weights to: ../models/sec_models/only_kill/model-722.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1251.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 496.22 minutes

Epoch #724
 90%|█████████ | 724/800 [8:16:53<51:10, 40.40s/it]Saving the network weights to: ../models/sec_models/only_kill/model-723.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1254.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 496.89 minutes

Epoch #725
Saving the network weights to: ../models/sec_models/only_kill/model-724.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 1255.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 497.58 minutes

Epoch #726
 91%|█████████ | 726/800 [8:18:15<50:16, 40.77s/it]Saving the network weights to: ../models/sec_models/only_kill/model-725.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1257.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 498.27 minutes

Epoch #727
Saving the network weights to: ../models/sec_models/only_kill/model-726.pth
 91%|█████████ | 727/800 [8:18:55<49:19, 40.54s/it]Results:
  total_reward: 14.0, step_mean: 0.008934269304403318
  total_deaths: 1258.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 498.93 minutes

Epoch #728
Saving the network weights to: ../models/sec_models/only_kill/model-727.pth
Results:
  total_reward: 7.0, step_mean: 0.004516129032258065
  total_deaths: 1261.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 499.60 minutes

Epoch #729
 91%|█████████ | 729/800 [8:20:17<48:03, 40.62s/it]Saving the network weights to: ../models/sec_models/only_kill/model-728.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 1263.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 500.29 minutes

Epoch #730
Saving the network weights to: ../models/sec_models/only_kill/model-729.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 1265.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 500.97 minutes

Epoch #731
 91%|█████████▏| 731/800 [8:21:39<46:57, 40.84s/it]Saving the network weights to: ../models/sec_models/only_kill/model-730.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 1266.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 501.66 minutes

Epoch #732
 92%|█████████▏| 732/800 [8:22:19<46:07, 40.70s/it]Saving the network weights to: ../models/sec_models/only_kill/model-731.pth
Results:
  total_reward: 4.0, step_mean: 0.0025823111684958036
  total_deaths: 1269.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 502.33 minutes

Epoch #733
 92%|█████████▏| 733/800 [8:23:00<45:33, 40.80s/it]Saving the network weights to: ../models/sec_models/only_kill/model-732.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 1271.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 503.01 minutes

Epoch #734
Saving the network weights to: ../models/sec_models/only_kill/model-733.pth
Results:
  total_reward: 17.0, step_mean: 0.010911424903722721
  total_deaths: 1273.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 503.70 minutes

Epoch #735
 92%|█████████▏| 735/800 [8:24:22<44:13, 40.82s/it]Saving the network weights to: ../models/sec_models/only_kill/model-734.pth
Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 1275.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 504.37 minutes

Epoch #736
Saving the network weights to: ../models/sec_models/only_kill/model-735.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1276.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 505.05 minutes

Epoch #737
 92%|█████████▏| 737/800 [8:25:44<43:05, 41.04s/it]Saving the network weights to: ../models/sec_models/only_kill/model-736.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 1278.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 505.75 minutes

Epoch #738
 92%|█████████▏| 738/800 [8:26:25<42:22, 41.01s/it]Saving the network weights to: ../models/sec_models/only_kill/model-737.pth
Results:
  total_reward: 10.0, step_mean: 0.0064516129032258064
  total_deaths: 1281.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 506.43 minutes

Epoch #739
Saving the network weights to: ../models/sec_models/only_kill/model-738.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1282.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 507.11 minutes

Epoch #740
 92%|█████████▎| 740/800 [8:27:48<41:21, 41.35s/it]Saving the network weights to: ../models/sec_models/only_kill/model-739.pth
Results:
  total_reward: 4.0, step_mean: 0.002569043031470777
  total_deaths: 1284.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 507.81 minutes

Epoch #741
Saving the network weights to: ../models/sec_models/only_kill/model-740.pth
Results:
  total_reward: 7.0, step_mean: 0.004467134652201659
  total_deaths: 1285.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 508.51 minutes

Epoch #742
 93%|█████████▎| 742/800 [8:29:13<40:31, 41.92s/it]Saving the network weights to: ../models/sec_models/only_kill/model-741.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1286.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 509.22 minutes

Epoch #743
Saving the network weights to: ../models/sec_models/only_kill/model-742.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 1287.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 509.92 minutes

Epoch #744
 93%|█████████▎| 744/800 [8:30:36<38:49, 41.60s/it]Saving the network weights to: ../models/sec_models/only_kill/model-743.pth
Results:
  total_reward: 9.0, step_mean: 0.005810200129115558
  total_deaths: 1290.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 510.60 minutes

Epoch #745
 93%|█████████▎| 745/800 [8:31:17<37:57, 41.41s/it]Saving the network weights to: ../models/sec_models/only_kill/model-744.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 1291.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 511.29 minutes

Epoch #746
Saving the network weights to: ../models/sec_models/only_kill/model-745.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 1292.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 511.98 minutes

Epoch #747
 93%|█████████▎| 747/800 [8:32:40<36:40, 41.51s/it]Saving the network weights to: ../models/sec_models/only_kill/model-746.pth
Results:
  total_reward: 6.0, step_mean: 0.0038289725590299937
  total_deaths: 1293.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 512.67 minutes

Epoch #748
Saving the network weights to: ../models/sec_models/only_kill/model-747.pth
Results:
  total_reward: 2.0, step_mean: 0.0012763241863433313
  total_deaths: 1294.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 513.36 minutes

Epoch #749
 94%|█████████▎| 749/800 [8:34:03<35:15, 41.48s/it]Saving the network weights to: ../models/sec_models/only_kill/model-748.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1296.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 514.05 minutes

Epoch #750
Saving the network weights to: ../models/sec_models/only_kill/model-749.pth
 94%|█████████▍| 750/800 [8:34:44<34:35, 41.51s/it]Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1298.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 514.75 minutes

Epoch #751
Saving the network weights to: ../models/sec_models/only_kill/model-750.pth
Results:
  total_reward: 2.0, step_mean: 0.001277139208173691
  total_deaths: 1299.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 515.43 minutes

Epoch #752
 94%|█████████▍| 752/800 [8:36:07<33:04, 41.34s/it]Saving the network weights to: ../models/sec_models/only_kill/model-751.pth
Results:
  total_reward: 14.0, step_mean: 0.008934269304403318
  total_deaths: 1300.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 516.12 minutes

Epoch #753
 94%|█████████▍| 753/800 [8:36:47<32:16, 41.20s/it]Saving the network weights to: ../models/sec_models/only_kill/model-752.pth
Results:
  total_reward: 13.0, step_mean: 0.008301404853128991
  total_deaths: 1301.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 516.80 minutes

Epoch #754
Saving the network weights to: ../models/sec_models/only_kill/model-753.pth
Results:
  total_reward: 16.0, step_mean: 0.01032258064516129
  total_deaths: 1304.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 517.47 minutes

Epoch #755
 94%|█████████▍| 755/800 [8:38:09<30:42, 40.95s/it]Saving the network weights to: ../models/sec_models/only_kill/model-754.pth
Results:
  total_reward: 14.0, step_mean: 0.00899165061014772
  total_deaths: 1306.0
  frag: 1.0
  death: 2.0
  global_step: 1557
Total elapsed time: 518.16 minutes

Epoch #756
Saving the network weights to: ../models/sec_models/only_kill/model-755.pth
Results:
  total_reward: 5.0, step_mean: 0.003190810465858328
  total_deaths: 1307.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 518.86 minutes

Epoch #757
 95%|█████████▍| 757/800 [8:39:32<29:30, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill/model-756.pth
Results:
  total_reward: 8.0, step_mean: 0.005108556832694764
  total_deaths: 1308.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 519.54 minutes

Epoch #758
Saving the network weights to: ../models/sec_models/only_kill/model-757.pth
Results:
  total_reward: 9.0, step_mean: 0.005776636713735558
  total_deaths: 1310.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 520.21 minutes

Epoch #759
 95%|█████████▍| 759/800 [8:40:52<27:50, 40.73s/it]Saving the network weights to: ../models/sec_models/only_kill/model-758.pth
Results:
  total_reward: 3.0, step_mean: 0.001935483870967742
  total_deaths: 1313.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 520.88 minutes

Epoch #760
 95%|█████████▌| 760/800 [8:41:34<27:17, 40.93s/it]Saving the network weights to: ../models/sec_models/only_kill/model-759.pth
Results:
  total_reward: 8.0, step_mean: 0.005134788189987163
  total_deaths: 1315.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 521.57 minutes

Epoch #761
Saving the network weights to: ../models/sec_models/only_kill/model-760.pth
Results:
  total_reward: 16.0, step_mean: 0.01032258064516129
  total_deaths: 1318.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 522.26 minutes

Epoch #762
 95%|█████████▌| 762/800 [8:42:55<25:49, 40.77s/it]Saving the network weights to: ../models/sec_models/only_kill/model-761.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1319.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 522.93 minutes

Epoch #763
 95%|█████████▌| 763/800 [8:43:36<25:06, 40.73s/it]Saving the network weights to: ../models/sec_models/only_kill/model-762.pth
Results:
  total_reward: 1.0, step_mean: 0.0006455777921239509
  total_deaths: 1322.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 523.61 minutes

Epoch #764
Saving the network weights to: ../models/sec_models/only_kill/model-763.pth
 96%|█████████▌| 764/800 [8:44:17<24:30, 40.85s/it]Results:
  total_reward: 3.0, step_mean: 0.0019255455712451862
  total_deaths: 1324.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 524.29 minutes

Epoch #765
Saving the network weights to: ../models/sec_models/only_kill/model-764.pth
Results:
  total_reward: 14.0, step_mean: 0.008934269304403318
  total_deaths: 1325.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 524.98 minutes

Epoch #766
 96%|█████████▌| 766/800 [8:45:39<23:07, 40.81s/it]Saving the network weights to: ../models/sec_models/only_kill/model-765.pth
Results:
  total_reward: 6.0, step_mean: 0.0038289725590299937
  total_deaths: 1326.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 525.65 minutes

Epoch #767
Saving the network weights to: ../models/sec_models/only_kill/model-766.pth
Results:
  total_reward: 17.0, step_mean: 0.010855683269476373
  total_deaths: 1327.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 526.35 minutes

Epoch #768
 96%|█████████▌| 768/800 [8:47:02<22:00, 41.25s/it]Saving the network weights to: ../models/sec_models/only_kill/model-767.pth
Results:
  total_reward: 16.0, step_mean: 0.01032258064516129
  total_deaths: 1330.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 527.04 minutes

Epoch #769
Saving the network weights to: ../models/sec_models/only_kill/model-768.pth
Results:
  total_reward: 16.0, step_mean: 0.01032258064516129
  total_deaths: 1333.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 527.74 minutes

Epoch #770
 96%|█████████▋| 770/800 [8:48:25<20:39, 41.33s/it]Saving the network weights to: ../models/sec_models/only_kill/model-769.pth
Results:
  total_reward: 16.0, step_mean: 0.01021059349074665
  total_deaths: 1334.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 528.43 minutes

Epoch #771
Saving the network weights to: ../models/sec_models/only_kill/model-770.pth
Results:
  total_reward: 6.0, step_mean: 0.003873466752743706
  total_deaths: 1337.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 529.08 minutes

Epoch #772
 96%|█████████▋| 772/800 [8:49:44<18:53, 40.46s/it]Saving the network weights to: ../models/sec_models/only_kill/model-771.pth
Results:
  total_reward: 9.0, step_mean: 0.005776636713735558
  total_deaths: 1339.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 529.75 minutes

Epoch #773
Saving the network weights to: ../models/sec_models/only_kill/model-772.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 1341.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 530.41 minutes

Epoch #774
 97%|█████████▋| 774/800 [8:51:04<17:25, 40.20s/it]Saving the network weights to: ../models/sec_models/only_kill/model-773.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 1343.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 531.08 minutes

Epoch #775
Saving the network weights to: ../models/sec_models/only_kill/model-774.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1347.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 531.73 minutes

Epoch #776
 97%|█████████▋| 776/800 [8:52:23<15:58, 39.94s/it]Saving the network weights to: ../models/sec_models/only_kill/model-775.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 1348.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 532.40 minutes

Epoch #777
Saving the network weights to: ../models/sec_models/only_kill/model-776.pth
Results:
  total_reward: 1.0, step_mean: 0.0006381620931716656
  total_deaths: 1349.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 533.06 minutes

Epoch #778
 97%|█████████▋| 778/800 [8:53:43<14:36, 39.85s/it]Saving the network weights to: ../models/sec_models/only_kill/model-777.pth
Results:
  total_reward: 5.0, step_mean: 0.003209242618741977
  total_deaths: 1351.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 533.72 minutes

Epoch #779
Saving the network weights to: ../models/sec_models/only_kill/model-778.pth
Results:
  total_reward: 4.0, step_mean: 0.002554278416347382
  total_deaths: 1352.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 534.39 minutes

Epoch #780
 98%|█████████▊| 780/800 [8:55:03<13:16, 39.81s/it]Saving the network weights to: ../models/sec_models/only_kill/model-779.pth
Results:
  total_reward: 15.0, step_mean: 0.009633911368015413
  total_deaths: 1354.0
  frag: 1.0
  death: 2.0
  global_step: 1557
Total elapsed time: 535.05 minutes

Epoch #781
 98%|█████████▊| 781/800 [8:55:43<12:39, 39.96s/it]Saving the network weights to: ../models/sec_models/only_kill/model-780.pth
Results:
  total_reward: 2.0, step_mean: 0.0012698412698412698
  total_deaths: 1354.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 535.72 minutes

Epoch #782
Saving the network weights to: ../models/sec_models/only_kill/model-781.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 1356.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 536.39 minutes

Epoch #783
 98%|█████████▊| 783/800 [8:57:02<11:15, 39.74s/it]Saving the network weights to: ../models/sec_models/only_kill/model-782.pth
Results:
  total_reward: 3.0, step_mean: 0.001946787800129786
  total_deaths: 1360.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 537.04 minutes

Epoch #784
 98%|█████████▊| 784/800 [8:57:43<10:42, 40.17s/it]Saving the network weights to: ../models/sec_models/only_kill/model-783.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1361.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 537.73 minutes

Epoch #785
Saving the network weights to: ../models/sec_models/only_kill/model-784.pth
Results:
  total_reward: 12.0, step_mean: 0.007746933505487412
  total_deaths: 1364.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 538.42 minutes

Epoch #786
 98%|█████████▊| 786/800 [8:59:06<09:29, 40.70s/it]Saving the network weights to: ../models/sec_models/only_kill/model-785.pth
Results:
  total_reward: 1.0, step_mean: 0.0006385696040868455
  total_deaths: 1365.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 539.11 minutes

Epoch #787
 98%|█████████▊| 787/800 [8:59:47<08:51, 40.89s/it]Saving the network weights to: ../models/sec_models/only_kill/model-786.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1366.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 539.79 minutes

Epoch #788
Saving the network weights to: ../models/sec_models/only_kill/model-787.pth
Results:
  total_reward: 8.0, step_mean: 0.005134788189987163
  total_deaths: 1368.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 540.47 minutes

Epoch #789
 99%|█████████▊| 789/800 [9:01:08<07:26, 40.56s/it]Saving the network weights to: ../models/sec_models/only_kill/model-788.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 1370.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 541.14 minutes

Epoch #790
Saving the network weights to: ../models/sec_models/only_kill/model-789.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 1372.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 541.81 minutes

Epoch #791
 99%|█████████▉| 791/800 [9:02:29<06:04, 40.54s/it]Saving the network weights to: ../models/sec_models/only_kill/model-790.pth
Results:
  total_reward: 12.0, step_mean: 0.007662835249042145
  total_deaths: 1373.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 542.49 minutes

Epoch #792
Saving the network weights to: ../models/sec_models/only_kill/model-791.pth
Results:
  total_reward: 2.0, step_mean: 0.0012836970474967907
  total_deaths: 1375.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 543.17 minutes

Epoch #793
 99%|█████████▉| 793/800 [9:03:50<04:44, 40.60s/it]Saving the network weights to: ../models/sec_models/only_kill/model-792.pth
Results:
  total_reward: 6.0, step_mean: 0.0038289725590299937
  total_deaths: 1376.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 543.84 minutes

Epoch #794
Saving the network weights to: ../models/sec_models/only_kill/model-793.pth
Results:
  total_reward: 1.0, step_mean: 0.0006418485237483953
  total_deaths: 1378.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 544.49 minutes

Epoch #795
 99%|█████████▉| 795/800 [9:05:08<03:19, 39.83s/it]Saving the network weights to: ../models/sec_models/only_kill/model-794.pth
Results:
  total_reward: 7.0, step_mean: 0.004492939666238768
  total_deaths: 1380.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 545.15 minutes

Epoch #796
100%|█████████▉| 796/800 [9:05:47<02:38, 39.60s/it]Saving the network weights to: ../models/sec_models/only_kill/model-795.pth
Results:
  total_reward: 6.0, step_mean: 0.0038314176245210726
  total_deaths: 1381.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 545.80 minutes

Epoch #797
Saving the network weights to: ../models/sec_models/only_kill/model-796.pth
Results:
  total_reward: 4.0, step_mean: 0.0025673940949935813
  total_deaths: 1383.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 546.45 minutes

Epoch #798
100%|█████████▉| 798/800 [9:07:05<01:18, 39.29s/it]Saving the network weights to: ../models/sec_models/only_kill/model-797.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 1384.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 547.10 minutes

Epoch #799
100%|█████████▉| 799/800 [9:07:46<00:39, 39.56s/it]Saving the network weights to: ../models/sec_models/only_kill/model-798.pth
Results:
  total_reward: 3.0, step_mean: 0.0019144862795149968
  total_deaths: 1385.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 547.77 minutes

Epoch #800
Saving the network weights to: ../models/sec_models/only_kill/model-799.pth
Results:
  total_reward: 4.0, step_mean: 0.0025806451612903226
  total_deaths: 1388.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 548.42 minutes
Saving the network weights to: ../models/model-only_kill.pth
======================================
Training finished. It's time to watch!
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.003873466752743706, total: 6.0, steps: 1549
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.005776636713735558, total: 9.0, steps: 1558
mean: 0.0032113037893384713, total: 5.0, steps: 1557
mean: 0.0012828736369467607, total: 2.0, steps: 1559
mean: 0.004467134652201659, total: 7.0, steps: 1567
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.005138086062941554, total: 8.0, steps: 1557
mean: 0.010269576379974325, total: 16.0, steps: 1558
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.010329244673983214, total: 16.0, steps: 1549
mean: 0.003190810465858328, total: 5.0, steps: 1567
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0012903225806451613, total: 2.0, steps: 1550
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0012903225806451613, total: 2.0, steps: 1550
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0025974025974025974, total: 4.0, steps: 1540
mean: 0.0025806451612903226, total: 4.0, steps: 1550
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.005776636713735558, total: 9.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0006414368184733803, total: 1.0, steps: 1559
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0025823111684958036, total: 4.0, steps: 1549
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0032113037893384713, total: 5.0, steps: 1557
mean: 0.001924310455420141, total: 3.0, steps: 1559
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0044444444444444444, total: 7.0, steps: 1575
mean: 0.003870967741935484, total: 6.0, steps: 1550
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0025396825396825397, total: 4.0, steps: 1575
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0019169329073482429, total: 3.0, steps: 1565
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.003190810465858328, total: 5.0, steps: 1567
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0031928480204342275, total: 5.0, steps: 1566
mean: 0.001936733376371853, total: 3.0, steps: 1549
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.00574345883854499, total: 9.0, steps: 1567
mean: 0.004467134652201659, total: 7.0, steps: 1567
mean: 0.001936733376371853, total: 3.0, steps: 1549
mean: 0.0, total: 0.0, steps: 1566
mean: 0.005131494547787043, total: 8.0, steps: 1559
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0006455777921239509, total: 1.0, steps: 1549
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0019267822736030828, total: 3.0, steps: 1557
mean: 0.0, total: 0.0, steps: 1575
mean: 0.0038314176245210726, total: 6.0, steps: 1566
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.003873466752743706, total: 6.0, steps: 1549
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0012903225806451613, total: 2.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1567
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.001924310455420141, total: 3.0, steps: 1559
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.004469987228607918, total: 7.0, steps: 1566
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.010269576379974325, total: 16.0, steps: 1558
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.008985879332477536, total: 14.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0012987012987012987, total: 2.0, steps: 1540
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.007064868336544637, total: 11.0, steps: 1557
mean: 0.01348747591522158, total: 21.0, steps: 1557
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0012845215157353885, total: 2.0, steps: 1557
mean: 0.0025396825396825397, total: 4.0, steps: 1575
mean: 0.0038314176245210726, total: 6.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1567
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0006455777921239509, total: 1.0, steps: 1549
mean: 0.0, total: 0.0, steps: 1566
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.00834403080872914, total: 13.0, steps: 1558
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0032258064516129032, total: 5.0, steps: 1550
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1559
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0006451612903225806, total: 1.0, steps: 1550
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1557
mean: 0.0006414368184733803, total: 1.0, steps: 1559
mean: 0.014120667522464698, total: 22.0, steps: 1558
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.005776636713735558, total: 9.0, steps: 1558
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0031928480204342275, total: 5.0, steps: 1566
mean: 0.0006414368184733803, total: 1.0, steps: 1559
mean: 0.008301404853128991, total: 13.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1557
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0006422607578676942, total: 1.0, steps: 1557
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0006455777921239509, total: 1.0, steps: 1549
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0012845215157353885, total: 2.0, steps: 1557
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0012698412698412698, total: 2.0, steps: 1575
mean: 0.0006406149903907751, total: 1.0, steps: 1561
mean: 0.0025806451612903226, total: 4.0, steps: 1550
mean: 0.005772931366260423, total: 9.0, steps: 1559
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0006451612903225806, total: 1.0, steps: 1550
mean: 0.0006451612903225806, total: 1.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1559
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1559
mean: 0.002569043031470777, total: 4.0, steps: 1557
mean: 0.003244646333549643, total: 5.0, steps: 1541
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0006414368184733803, total: 1.0, steps: 1559
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0031928480204342275, total: 5.0, steps: 1566
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.002569043031470777, total: 4.0, steps: 1557
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1549
mean: 0.0, total: 0.0, steps: 1575
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0012911555842479018, total: 2.0, steps: 1549
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.00574345883854499, total: 9.0, steps: 1567
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.004469987228607918, total: 7.0, steps: 1566
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.003190810465858328, total: 5.0, steps: 1567
mean: 0.005134788189987163, total: 8.0, steps: 1558
mean: 0.005138086062941554, total: 8.0, steps: 1557
mean: 0.003870967741935484, total: 6.0, steps: 1550
mean: 0.0025396825396825397, total: 4.0, steps: 1575
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0012911555842479018, total: 2.0, steps: 1549
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0006451612903225806, total: 1.0, steps: 1550
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0025957170668397143, total: 4.0, steps: 1541
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0012845215157353885, total: 2.0, steps: 1557
mean: 0.0038535645472061657, total: 6.0, steps: 1557
mean: 0.002569043031470777, total: 4.0, steps: 1557
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.0012903225806451613, total: 2.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1566
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1567
mean: 0.00449582530507386, total: 7.0, steps: 1557
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.002569043031470777, total: 4.0, steps: 1557
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1575
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.001924310455420141, total: 3.0, steps: 1559
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0032278889606197547, total: 5.0, steps: 1549
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.004469987228607918, total: 7.0, steps: 1566
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.005105296745373325, total: 8.0, steps: 1567
mean: 0.001936733376371853, total: 3.0, steps: 1549
mean: 0.0006455777921239509, total: 1.0, steps: 1549
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0012828736369467607, total: 2.0, steps: 1559
mean: 0.0025806451612903226, total: 4.0, steps: 1550
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0032258064516129032, total: 5.0, steps: 1550
mean: 0.0038314176245210726, total: 6.0, steps: 1566
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.008934269304403318, total: 14.0, steps: 1567
mean: 0.005134788189987163, total: 8.0, steps: 1558
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.003190810465858328, total: 5.0, steps: 1567
mean: 0.006381620931716656, total: 10.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1557
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.003848620910840282, total: 6.0, steps: 1559
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0006485084306095979, total: 1.0, steps: 1542
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0006349206349206349, total: 1.0, steps: 1575
mean: 0.0, total: 0.0, steps: 1558
mean: 0.005108556832694764, total: 8.0, steps: 1566
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.005105296745373325, total: 8.0, steps: 1567
mean: 0.0025823111684958036, total: 4.0, steps: 1549
mean: 0.0025756600128783, total: 4.0, steps: 1553
mean: 0.003870967741935484, total: 6.0, steps: 1550
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.01148691767708998, total: 18.0, steps: 1567
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.004469987228607918, total: 7.0, steps: 1566
mean: 0.010217113665389528, total: 16.0, steps: 1566
mean: 0.001936733376371853, total: 3.0, steps: 1549
mean: 0.008392511297611363, total: 13.0, steps: 1549
mean: 0.010939510939510939, total: 17.0, steps: 1554
mean: 0.005134788189987163, total: 8.0, steps: 1558
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1557
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.003207184092366902, total: 5.0, steps: 1559
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0012828736369467607, total: 2.0, steps: 1559
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.001288659793814433, total: 2.0, steps: 1552
mean: 0.0, total: 0.0, steps: 1558
mean: 0.005105296745373325, total: 8.0, steps: 1567
mean: 0.0025396825396825397, total: 4.0, steps: 1575
mean: 0.010848755583918315, total: 17.0, steps: 1567
mean: 0.0038289725590299937, total: 6.0, steps: 1567
mean: 0.003848620910840282, total: 6.0, steps: 1559
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.003873466752743706, total: 6.0, steps: 1549
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1549
mean: 0.0012911555842479018, total: 2.0, steps: 1549
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0012828736369467607, total: 2.0, steps: 1559
mean: 0.0025940337224383916, total: 4.0, steps: 1542
mean: 0.003244646333549643, total: 5.0, steps: 1541
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0006422607578676942, total: 1.0, steps: 1557
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0012853470437017994, total: 2.0, steps: 1556
mean: 0.0012911555842479018, total: 2.0, steps: 1549
mean: 0.0025806451612903226, total: 4.0, steps: 1550
mean: 0.0044728434504792336, total: 7.0, steps: 1565
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0012698412698412698, total: 2.0, steps: 1575
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.00449582530507386, total: 7.0, steps: 1557
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.013409961685823755, total: 21.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1575
mean: 0.0032258064516129032, total: 5.0, steps: 1550
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1557
mean: 0.003873466752743706, total: 6.0, steps: 1549
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0006414368184733803, total: 1.0, steps: 1559
mean: 0.0038535645472061657, total: 6.0, steps: 1557
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0006451612903225806, total: 1.0, steps: 1550
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.003207184092366902, total: 5.0, steps: 1559
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0038535645472061657, total: 6.0, steps: 1557
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1557
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.004490057729313663, total: 7.0, steps: 1559
mean: 0.003873466752743706, total: 6.0, steps: 1549
mean: 0.0006422607578676942, total: 1.0, steps: 1557
mean: 0.01021059349074665, total: 16.0, steps: 1567
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0025396825396825397, total: 4.0, steps: 1575
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.005191434133679429, total: 8.0, steps: 1541
mean: 0.012836970474967908, total: 20.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.003207184092366902, total: 5.0, steps: 1559
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0038289725590299937, total: 6.0, steps: 1567
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1566
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0012903225806451613, total: 2.0, steps: 1550
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.005772931366260423, total: 9.0, steps: 1559
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0012698412698412698, total: 2.0, steps: 1575
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0006451612903225806, total: 1.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1542
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.00574345883854499, total: 9.0, steps: 1567
mean: 0.0038289725590299937, total: 6.0, steps: 1567
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0025823111684958036, total: 4.0, steps: 1549
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.004467134652201659, total: 7.0, steps: 1567
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.0032278889606197547, total: 5.0, steps: 1549
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0006422607578676942, total: 1.0, steps: 1557
mean: 0.0, total: 0.0, steps: 1557
mean: 0.0, total: 0.0, steps: 1558
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0038289725590299937, total: 6.0, steps: 1567
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0012978585334198572, total: 2.0, steps: 1541
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0031928480204342275, total: 5.0, steps: 1566
mean: 0.0019267822736030828, total: 3.0, steps: 1557
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0019047619047619048, total: 3.0, steps: 1575
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.006381620931716656, total: 10.0, steps: 1567
mean: 0.0006455777921239509, total: 1.0, steps: 1549
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.008985879332477536, total: 14.0, steps: 1558
mean: 0.004467134652201659, total: 7.0, steps: 1567
mean: 0.012195121951219513, total: 19.0, steps: 1558
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0038314176245210726, total: 6.0, steps: 1566
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0019047619047619048, total: 3.0, steps: 1575
mean: 0.004469987228607918, total: 7.0, steps: 1566
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0032113037893384713, total: 5.0, steps: 1557
mean: 0.0, total: 0.0, steps: 1575
mean: 0.0006451612903225806, total: 1.0, steps: 1550
mean: 0.009683666881859263, total: 15.0, steps: 1549
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0012903225806451613, total: 2.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1567
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.0006455777921239509, total: 1.0, steps: 1549
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.005105296745373325, total: 8.0, steps: 1567
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.004519044544867657, total: 7.0, steps: 1549
mean: 0.009578544061302681, total: 15.0, steps: 1566
mean: 0.011553273427471117, total: 18.0, steps: 1558
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.013478818998716302, total: 21.0, steps: 1558
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0012903225806451613, total: 2.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1567
mean: 0.013409961685823755, total: 21.0, steps: 1566
mean: 0.008985879332477536, total: 14.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.012836970474967908, total: 20.0, steps: 1558
mean: 0.0031928480204342275, total: 5.0, steps: 1566
mean: 0.005161290322580645, total: 8.0, steps: 1550
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.005776636713735558, total: 9.0, steps: 1558
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0025806451612903226, total: 4.0, steps: 1550
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0019047619047619048, total: 3.0, steps: 1575
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.010911424903722721, total: 17.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.00903225806451613, total: 14.0, steps: 1550
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1550
mean: 0.002569043031470777, total: 4.0, steps: 1557
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.012258064516129033, total: 19.0, steps: 1550
mean: 0.001936733376371853, total: 3.0, steps: 1549
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0006414368184733803, total: 1.0, steps: 1559
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.001936733376371853, total: 3.0, steps: 1549
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.00903225806451613, total: 14.0, steps: 1550
mean: 0.010217113665389528, total: 16.0, steps: 1566
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.007060333761232349, total: 11.0, steps: 1558
mean: 0.006418485237483954, total: 10.0, steps: 1558
mean: 0.003207184092366902, total: 5.0, steps: 1559
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.007662835249042145, total: 12.0, steps: 1566
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.001936733376371853, total: 3.0, steps: 1549
mean: 0.001924310455420141, total: 3.0, steps: 1559
mean: 0.00574345883854499, total: 9.0, steps: 1567
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1559
mean: 0.0025396825396825397, total: 4.0, steps: 1575
mean: 0.001946787800129786, total: 3.0, steps: 1541
mean: 0.0006451612903225806, total: 1.0, steps: 1550
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0025806451612903226, total: 4.0, steps: 1550
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.003873466752743706, total: 6.0, steps: 1549
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.003244646333549643, total: 5.0, steps: 1541
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.008934269304403318, total: 14.0, steps: 1567
mean: 0.013565891472868217, total: 21.0, steps: 1548
mean: 0.0, total: 0.0, steps: 1567
mean: 0.003190810465858328, total: 5.0, steps: 1567
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0032278889606197547, total: 5.0, steps: 1549
mean: 0.0012828736369467607, total: 2.0, steps: 1559
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.004516129032258065, total: 7.0, steps: 1550
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0032278889606197547, total: 5.0, steps: 1549
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.011553273427471117, total: 18.0, steps: 1558
mean: 0.0038289725590299937, total: 6.0, steps: 1567
mean: 0.004490057729313663, total: 7.0, steps: 1559
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0031928480204342275, total: 5.0, steps: 1566
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.004467134652201659, total: 7.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0006455777921239509, total: 1.0, steps: 1549
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1549
mean: 0.003190810465858328, total: 5.0, steps: 1567
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.003207184092366902, total: 5.0, steps: 1559
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1566
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0019267822736030828, total: 3.0, steps: 1557
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0012845215157353885, total: 2.0, steps: 1557
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.005134788189987163, total: 8.0, steps: 1558
mean: 0.006422607578676943, total: 10.0, steps: 1557
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1575
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1566
mean: 0.009578544061302681, total: 15.0, steps: 1566
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0012903225806451613, total: 2.0, steps: 1550
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0012698412698412698, total: 2.0, steps: 1575
mean: 0.0019157088122605363, total: 3.0, steps: 1566
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1575
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.005161290322580645, total: 8.0, steps: 1550
mean: 0.001924310455420141, total: 3.0, steps: 1559
mean: 0.0019047619047619048, total: 3.0, steps: 1575
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0025806451612903226, total: 4.0, steps: 1550
mean: 0.0019047619047619048, total: 3.0, steps: 1575
mean: 0.003190810465858328, total: 5.0, steps: 1567
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0006422607578676942, total: 1.0, steps: 1557
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0038510911424903724, total: 6.0, steps: 1558
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0012911555842479018, total: 2.0, steps: 1549
mean: 0.004519044544867657, total: 7.0, steps: 1549
mean: 0.006984126984126984, total: 11.0, steps: 1575
mean: 0.0038314176245210726, total: 6.0, steps: 1566
mean: 0.0064516129032258064, total: 10.0, steps: 1550
mean: 0.005134788189987163, total: 8.0, steps: 1558
mean: 0.0038314176245210726, total: 6.0, steps: 1566
mean: 0.003190810465858328, total: 5.0, steps: 1567
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1550
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0025974025974025974, total: 4.0, steps: 1540
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.022464698331193838, total: 35.0, steps: 1558
mean: 0.005776636713735558, total: 9.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1549
mean: 0.0019047619047619048, total: 3.0, steps: 1575
mean: 0.001924310455420141, total: 3.0, steps: 1559
mean: 0.010911424903722721, total: 17.0, steps: 1558
mean: 0.0025823111684958036, total: 4.0, steps: 1549
mean: 0.010848755583918315, total: 17.0, steps: 1567
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0032113037893384713, total: 5.0, steps: 1557
mean: 0.0038314176245210726, total: 6.0, steps: 1566
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1549
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1558
mean: 0.008934269304403318, total: 14.0, steps: 1567
mean: 0.004516129032258065, total: 7.0, steps: 1550
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.0025823111684958036, total: 4.0, steps: 1549
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.010911424903722721, total: 17.0, steps: 1558
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1567
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0064516129032258064, total: 10.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1566
mean: 0.002569043031470777, total: 4.0, steps: 1557
mean: 0.004467134652201659, total: 7.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.005810200129115558, total: 9.0, steps: 1549
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0038289725590299937, total: 6.0, steps: 1567
mean: 0.0012763241863433313, total: 2.0, steps: 1567
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1558
mean: 0.001277139208173691, total: 2.0, steps: 1566
mean: 0.008934269304403318, total: 14.0, steps: 1567
mean: 0.008301404853128991, total: 13.0, steps: 1566
mean: 0.01032258064516129, total: 16.0, steps: 1550
mean: 0.00899165061014772, total: 14.0, steps: 1557
mean: 0.003190810465858328, total: 5.0, steps: 1567
mean: 0.005108556832694764, total: 8.0, steps: 1566
mean: 0.005776636713735558, total: 9.0, steps: 1558
mean: 0.001935483870967742, total: 3.0, steps: 1550
mean: 0.005134788189987163, total: 8.0, steps: 1558
mean: 0.01032258064516129, total: 16.0, steps: 1550
mean: 0.0, total: 0.0, steps: 1566
mean: 0.0006455777921239509, total: 1.0, steps: 1549
mean: 0.0019255455712451862, total: 3.0, steps: 1558
mean: 0.008934269304403318, total: 14.0, steps: 1567
mean: 0.0038289725590299937, total: 6.0, steps: 1567
mean: 0.010855683269476373, total: 17.0, steps: 1566
mean: 0.01032258064516129, total: 16.0, steps: 1550
mean: 0.01032258064516129, total: 16.0, steps: 1550
mean: 0.01021059349074665, total: 16.0, steps: 1567
mean: 0.003873466752743706, total: 6.0, steps: 1549
mean: 0.005776636713735558, total: 9.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0, total: 0.0, steps: 1541
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0006381620931716656, total: 1.0, steps: 1567
mean: 0.003209242618741977, total: 5.0, steps: 1558
mean: 0.002554278416347382, total: 4.0, steps: 1566
mean: 0.009633911368015413, total: 15.0, steps: 1557
mean: 0.0012698412698412698, total: 2.0, steps: 1575
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.001946787800129786, total: 3.0, steps: 1541
mean: 0.0, total: 0.0, steps: 1567
mean: 0.007746933505487412, total: 12.0, steps: 1549
mean: 0.0006385696040868455, total: 1.0, steps: 1566
mean: 0.0, total: 0.0, steps: 1566
mean: 0.005134788189987163, total: 8.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.007662835249042145, total: 12.0, steps: 1566
mean: 0.0012836970474967907, total: 2.0, steps: 1558
mean: 0.0038289725590299937, total: 6.0, steps: 1567
mean: 0.0006418485237483953, total: 1.0, steps: 1558
mean: 0.004492939666238768, total: 7.0, steps: 1558
mean: 0.0038314176245210726, total: 6.0, steps: 1566
mean: 0.0025673940949935813, total: 4.0, steps: 1558
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: 0.0019144862795149968, total: 3.0, steps: 1567
mean: 0.0025806451612903226, total: 4.0, steps: 1550
Player died.
Player died.
Player died.
Episode finished.
************************

kills: 0.0,
deaths: 3.0,
kill/death: 0.0
Results: (name: score)
AI: 0

Perfect: 3

Total score: 1.0
************************

Process finished with exit code 0
