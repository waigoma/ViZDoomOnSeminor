D:\Programming\School\Hosei\ViZDoomOnSeminor\venv\Scripts\python.exe D:\Programming\School\Hosei\ViZDoomOnSeminor\examples\my_learning_deathmatch2.py
GPU available
Initializing doom...
Doom initialized.
Initializing new model
  0%|          | 0/800 [00:00<?, ?it/s]
Epoch #1
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-0.pth
Results:
  total_reward: -192.5, step_mean: -0.1235558408215661
  total_deaths: 2.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 0.64 minutes

Epoch #2
  0%|          | 2/800 [01:15<8:24:32, 37.94s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-1.pth
Results:
  total_reward: -178.0, step_mean: -0.11424903722721438
  total_deaths: 4.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 1.27 minutes

Epoch #3
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-2.pth
Results:
  total_reward: -193.5, step_mean: -0.1241976893453145
  total_deaths: 6.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 1.91 minutes

Epoch #4
  0%|          | 4/800 [02:32<8:28:35, 38.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-3.pth
Results:
  total_reward: -179.0, step_mean: -0.11489088575096278
  total_deaths: 8.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 2.55 minutes

Epoch #5
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-4.pth
Results:
  total_reward: -180.0, step_mean: -0.11553273427471117
  total_deaths: 10.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 3.19 minutes

Epoch #6
  1%|          | 6/800 [03:48<8:24:12, 38.10s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-5.pth
Results:
  total_reward: -193.0, step_mean: -0.12524334847501623
  total_deaths: 14.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 3.82 minutes

Epoch #7
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-6.pth
Results:
  total_reward: -154.0, step_mean: -0.09884467265725289
  total_deaths: 16.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 4.45 minutes

Epoch #8
  1%|          | 8/800 [05:06<8:27:47, 38.47s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-7.pth
Results:
  total_reward: -172.5, step_mean: -0.11008296107211232
  total_deaths: 17.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 5.11 minutes

Epoch #9
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-8.pth
Results:
  total_reward: -174.0, step_mean: -0.1111111111111111
  total_deaths: 18.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 5.76 minutes

Epoch #10
  1%|▏         | 10/800 [06:24<8:31:33, 38.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-9.pth
Results:
  total_reward: -169.5, step_mean: -0.10886319845857419
  total_deaths: 20.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 6.41 minutes

Epoch #11
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-10.pth
Results:
  total_reward: -157.5, step_mean: -0.10115606936416185
  total_deaths: 22.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 7.06 minutes

Epoch #12
  2%|▏         | 12/800 [07:41<8:26:34, 38.57s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-11.pth
Results:
  total_reward: -145.5, step_mean: -0.09338896020539153
  total_deaths: 24.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 7.69 minutes

Epoch #13
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-12.pth
Results:
  total_reward: -157.0, step_mean: -0.10109465550547328
  total_deaths: 27.0
  frag: 0.0
  death: 3.0
  global_step: 1553
Total elapsed time: 8.33 minutes

Epoch #14
  2%|▏         | 14/800 [08:56<8:17:18, 37.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-13.pth
Results:
  total_reward: -148.0, step_mean: -0.09554551323434474
  total_deaths: 30.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 8.94 minutes

Epoch #15
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-14.pth
Results:
  total_reward: -123.0, step_mean: -0.07854406130268199
  total_deaths: 31.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 9.57 minutes

Epoch #16
  2%|▏         | 16/800 [10:12<8:15:10, 37.90s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-15.pth
Results:
  total_reward: -128.0, step_mean: -0.08258064516129032
  total_deaths: 34.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 10.20 minutes

Epoch #17
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-16.pth
Results:
  total_reward: -117.0, step_mean: -0.0750481077613855
  total_deaths: 36.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 10.85 minutes

Epoch #18
  2%|▏         | 18/800 [11:30<8:23:04, 38.60s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-17.pth
Results:
  total_reward: -118.5, step_mean: -0.07610789980732177
  total_deaths: 38.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 11.51 minutes

Epoch #19
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-18.pth
Results:
  total_reward: -125.5, step_mean: -0.08055198973042361
  total_deaths: 40.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 12.18 minutes

Epoch #20
  2%|▎         | 20/800 [12:50<8:29:20, 39.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-19.pth
Results:
  total_reward: -95.5, step_mean: -0.061296534017971756
  total_deaths: 42.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 12.84 minutes

Epoch #21
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-20.pth
Results:
  total_reward: -125.0, step_mean: -0.08023106546854943
  total_deaths: 44.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 13.50 minutes

Epoch #22
  3%|▎         | 22/800 [14:10<8:33:51, 39.63s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-21.pth
Results:
  total_reward: -107.0, step_mean: -0.06867779204107831
  total_deaths: 46.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 14.17 minutes

Epoch #23
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-22.pth
Results:
  total_reward: -99.0, step_mean: -0.0631780472239949
  total_deaths: 47.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 14.84 minutes

Epoch #24
  3%|▎         | 24/800 [15:31<8:40:00, 40.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-23.pth
Results:
  total_reward: -107.0, step_mean: -0.06867779204107831
  total_deaths: 49.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 15.53 minutes

Epoch #25
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-24.pth
Results:
  total_reward: -100.5, step_mean: -0.06450577663671374
  total_deaths: 51.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 16.20 minutes

Epoch #26
  3%|▎         | 26/800 [16:52<8:41:58, 40.46s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-25.pth
Results:
  total_reward: -115.0, step_mean: -0.07424144609425436
  total_deaths: 54.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 16.88 minutes

Epoch #27
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-26.pth
Results:
  total_reward: -97.0, step_mean: -0.06225930680359435
  total_deaths: 56.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 17.56 minutes

Epoch #28
  4%|▎         | 28/800 [18:14<8:43:34, 40.69s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-27.pth
Results:
  total_reward: -93.0, step_mean: -0.05938697318007663
  total_deaths: 57.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 18.25 minutes

Epoch #29
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-28.pth
Results:
  total_reward: -97.5, step_mean: -0.06258023106546855
  total_deaths: 59.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 18.92 minutes

Epoch #30
  4%|▍         | 30/800 [19:36<8:42:25, 40.71s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-29.pth
Results:
  total_reward: -96.0, step_mean: -0.06197546804389929
  total_deaths: 62.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 19.60 minutes

Epoch #31
  4%|▍         | 31/800 [20:16<8:40:48, 40.64s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-30.pth
Results:
  total_reward: -92.5, step_mean: -0.05971594577146546
  total_deaths: 65.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 20.28 minutes

Epoch #32
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-31.pth
Results:
  total_reward: -90.0, step_mean: -0.058102001291155586
  total_deaths: 68.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 20.95 minutes

Epoch #33
  4%|▍         | 33/800 [21:38<8:40:52, 40.75s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-32.pth
Results:
  total_reward: -92.5, step_mean: -0.05940912010276172
  total_deaths: 70.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 21.64 minutes

Epoch #34
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-33.pth
Results:
  total_reward: -104.0, step_mean: -0.06675224646983312
  total_deaths: 72.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 22.33 minutes

Epoch #35
  4%|▍         | 35/800 [23:01<8:44:12, 41.11s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-34.pth
Results:
  total_reward: -92.5, step_mean: -0.05937098844672657
  total_deaths: 74.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 23.02 minutes

Epoch #36
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-35.pth
Results:
  total_reward: -91.0, step_mean: -0.05870967741935484
  total_deaths: 77.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 23.71 minutes

Epoch #37
  5%|▍         | 37/800 [24:24<8:46:54, 41.43s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-36.pth
Results:
  total_reward: -69.5, step_mean: -0.04435226547543076
  total_deaths: 78.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 24.41 minutes

Epoch #38
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-37.pth
Results:
  total_reward: -87.0, step_mean: -0.05616526791478373
  total_deaths: 81.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 25.08 minutes

Epoch #39
  5%|▍         | 39/800 [25:46<8:43:48, 41.30s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-38.pth
Results:
  total_reward: -75.0, step_mean: -0.04789272030651341
  total_deaths: 82.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 25.78 minutes

Epoch #40
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-39.pth
Results:
  total_reward: -62.5, step_mean: -0.0398851308232291
  total_deaths: 83.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 26.47 minutes

Epoch #41
  5%|▌         | 41/800 [27:11<8:49:26, 41.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-40.pth
Results:
  total_reward: -81.0, step_mean: -0.052258064516129035
  total_deaths: 86.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 27.19 minutes

Epoch #42
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-41.pth
Results:
  total_reward: -58.5, step_mean: -0.03735632183908046
  total_deaths: 87.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 27.91 minutes

Epoch #43
  5%|▌         | 43/800 [28:38<8:58:50, 42.71s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-42.pth
Results:
  total_reward: -64.0, step_mean: -0.04086845466155811
  total_deaths: 88.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 28.64 minutes

Epoch #44
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-43.pth
Results:
  total_reward: -71.0, step_mean: -0.045571245186136075
  total_deaths: 90.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 29.34 minutes

Epoch #45
  6%|▌         | 45/800 [30:02<8:53:21, 42.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-44.pth
Results:
  total_reward: -61.0, step_mean: -0.039380245319561004
  total_deaths: 93.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 30.04 minutes

Epoch #46
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-45.pth
Results:
  total_reward: -78.5, step_mean: -0.05035279025016036
  total_deaths: 95.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 30.74 minutes

Epoch #47
  6%|▌         | 47/800 [31:26<8:49:07, 42.16s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-46.pth
Results:
  total_reward: -77.0, step_mean: -0.04942233632862644
  total_deaths: 97.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 31.44 minutes

Epoch #48
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-47.pth
Results:
  total_reward: -52.5, step_mean: -0.03350350989151244
  total_deaths: 98.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 32.14 minutes

Epoch #49
  6%|▌         | 49/800 [32:50<8:45:46, 42.01s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-48.pth
Results:
  total_reward: -83.0, step_mean: -0.053548387096774196
  total_deaths: 101.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 32.84 minutes

Epoch #50
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-49.pth
Results:
  total_reward: -76.5, step_mean: -0.04910141206675225
  total_deaths: 103.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 33.54 minutes

Epoch #51
  6%|▋         | 51/800 [34:13<8:42:53, 41.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-50.pth
Results:
  total_reward: -67.0, step_mean: -0.043225806451612905
  total_deaths: 106.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 34.23 minutes

Epoch #52
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-51.pth
Results:
  total_reward: -45.5, step_mean: -0.028888888888888888
  total_deaths: 106.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 34.93 minutes

Epoch #53
  7%|▋         | 53/800 [35:37<8:40:28, 41.80s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-52.pth
Results:
  total_reward: -67.0, step_mean: -0.043225806451612905
  total_deaths: 109.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 35.62 minutes

Epoch #54
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-53.pth
Results:
  total_reward: -83.0, step_mean: -0.05358295674628793
  total_deaths: 112.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 36.32 minutes

Epoch #55
  7%|▋         | 55/800 [36:59<8:34:57, 41.47s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-54.pth
Results:
  total_reward: -52.0, step_mean: -0.03337612323491656
  total_deaths: 114.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 37.00 minutes

Epoch #56
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-55.pth
  7%|▋         | 56/800 [37:40<8:30:50, 41.20s/it]Results:
  total_reward: -73.0, step_mean: -0.04712717882504842
  total_deaths: 117.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 37.67 minutes

Epoch #57
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-56.pth
Results:
  total_reward: -71.5, step_mean: -0.04589216944801027
  total_deaths: 119.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 38.43 minutes

Epoch #58
  7%|▋         | 58/800 [39:08<8:45:27, 42.49s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-57.pth
Results:
  total_reward: -51.0, step_mean: -0.032567049808429116
  total_deaths: 120.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 39.14 minutes

Epoch #59
  7%|▋         | 59/800 [39:50<8:41:51, 42.26s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-58.pth
Results:
  total_reward: -66.0, step_mean: -0.04238921001926782
  total_deaths: 122.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 39.83 minutes

Epoch #60
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-59.pth
  8%|▊         | 60/800 [40:32<8:42:16, 42.35s/it]Results:
  total_reward: -62.0, step_mean: -0.03956604977664327
  total_deaths: 123.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 40.54 minutes

Epoch #61
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-60.pth
  8%|▊         | 61/800 [41:14<8:40:59, 42.30s/it]Results:
  total_reward: -58.0, step_mean: -0.03720333547145606
  total_deaths: 125.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 41.25 minutes

Epoch #62
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-61.pth
Results:
  total_reward: -62.5, step_mean: -0.04011553273427471
  total_deaths: 127.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 41.97 minutes

Epoch #63
  8%|▊         | 63/800 [42:40<8:43:14, 42.60s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-62.pth
Results:
  total_reward: -64.5, step_mean: -0.041639767591994836
  total_deaths: 130.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 42.68 minutes

Epoch #64
  8%|▊         | 64/800 [43:23<8:43:00, 42.64s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-63.pth
Results:
  total_reward: -68.5, step_mean: -0.04396662387676508
  total_deaths: 132.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 43.39 minutes

Epoch #65
  8%|▊         | 65/800 [44:05<8:41:04, 42.54s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-64.pth
Results:
  total_reward: -72.5, step_mean: -0.046804389928986445
  total_deaths: 135.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 44.10 minutes

Epoch #66
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-65.pth
Results:
  total_reward: -63.0, step_mean: -0.040229885057471264
  total_deaths: 136.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 44.81 minutes

Epoch #67
  8%|▊         | 67/800 [45:31<8:40:40, 42.62s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-66.pth
Results:
  total_reward: -73.0, step_mean: -0.046885035324341684
  total_deaths: 138.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 45.52 minutes

Epoch #68
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-67.pth
Results:
  total_reward: -81.0, step_mean: -0.05202312138728324
  total_deaths: 141.0
  frag: 0.0
  death: 3.0
  global_step: 1557
Total elapsed time: 46.22 minutes

Epoch #69
  9%|▊         | 69/800 [46:54<8:33:42, 42.16s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-68.pth
Results:
  total_reward: -84.0, step_mean: -0.054510058403634
  total_deaths: 145.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 46.91 minutes

Epoch #70
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-69.pth
Results:
  total_reward: -64.5, step_mean: -0.041399229781771504
  total_deaths: 147.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 47.69 minutes

Epoch #71
  9%|▉         | 71/800 [48:28<9:01:48, 44.59s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-70.pth
Results:
  total_reward: -64.0, step_mean: -0.0408423739629866
  total_deaths: 148.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 48.48 minutes

Epoch #72
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-71.pth
Results:
  total_reward: -72.0, step_mean: -0.04621309370988447
  total_deaths: 150.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 49.33 minutes

Epoch #73
  9%|▉         | 73/800 [50:07<9:30:17, 47.07s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-72.pth
Results:
  total_reward: -92.5, step_mean: -0.05971594577146546
  total_deaths: 153.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 50.13 minutes

Epoch #74
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-73.pth
  9%|▉         | 74/800 [50:56<9:34:10, 47.45s/it]Results:
  total_reward: -95.0, step_mean: -0.06168831168831169
  total_deaths: 157.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 50.94 minutes

Epoch #75
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-74.pth
Results:
  total_reward: -49.5, step_mean: -0.03158902361199745
  total_deaths: 158.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 51.81 minutes

Epoch #76
 10%|▉         | 76/800 [52:39<9:57:28, 49.52s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-75.pth
Results:
  total_reward: -74.0, step_mean: -0.04774193548387097
  total_deaths: 161.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 52.66 minutes

Epoch #77
 10%|▉         | 77/800 [53:28<9:54:49, 49.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-76.pth
Results:
  total_reward: -64.0, step_mean: -0.0410783055198973
  total_deaths: 163.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 53.47 minutes

Epoch #78
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-77.pth
 10%|▉         | 78/800 [54:17<9:54:31, 49.41s/it]Results:
  total_reward: -55.5, step_mean: -0.035440613026819924
  total_deaths: 164.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 54.30 minutes

Epoch #79
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-78.pth
Results:
  total_reward: -69.5, step_mean: -0.04460847240051348
  total_deaths: 166.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 55.14 minutes

Epoch #80
 10%|█         | 80/800 [55:58<9:57:28, 49.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-79.pth
Results:
  total_reward: -59.0, step_mean: -0.037869062901155326
  total_deaths: 168.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 55.97 minutes

Epoch #81
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-80.pth
Results:
  total_reward: -48.5, step_mean: -0.030970625798212005
  total_deaths: 169.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 56.82 minutes

Epoch #82
 10%|█         | 82/800 [57:40<10:02:57, 50.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-81.pth
Results:
  total_reward: -74.5, step_mean: -0.047817715019255455
  total_deaths: 171.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 57.67 minutes

Epoch #83
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-82.pth
Results:
  total_reward: -52.0, step_mean: -0.033205619412515965
  total_deaths: 172.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 58.54 minutes

Epoch #84
 10%|█         | 84/800 [59:15<9:39:27, 48.56s/it] Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-83.pth
Results:
  total_reward: -65.5, step_mean: -0.042068079640333975
  total_deaths: 174.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 59.26 minutes

Epoch #85
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-84.pth
Results:
  total_reward: -80.0, step_mean: -0.05191434133679429
  total_deaths: 178.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 59.97 minutes

Epoch #86
 11%|█         | 86/800 [1:00:41<9:05:59, 45.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-85.pth
Results:
  total_reward: -49.0, step_mean: -0.031289910600255426
  total_deaths: 179.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 60.70 minutes

Epoch #87
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-86.pth
Results:
  total_reward: -72.5, step_mean: -0.046534017971758664
  total_deaths: 181.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 61.53 minutes

Epoch #88
 11%|█         | 88/800 [1:02:23<9:34:22, 48.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-87.pth
Results:
  total_reward: -85.0, step_mean: -0.05519480519480519
  total_deaths: 185.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 62.39 minutes

Epoch #89
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-88.pth
Results:
  total_reward: -80.0, step_mean: -0.051646223369916075
  total_deaths: 188.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 63.25 minutes

Epoch #90
 11%|█▏        | 90/800 [1:04:04<9:44:41, 49.41s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-89.pth
Results:
  total_reward: -66.0, step_mean: -0.04260813428018076
  total_deaths: 191.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 64.08 minutes

Epoch #91
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-90.pth
Results:
  total_reward: -69.5, step_mean: -0.04486765655261459
  total_deaths: 194.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 64.87 minutes

Epoch #92
 12%|█▏        | 92/800 [1:05:35<9:17:09, 47.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-91.pth
Results:
  total_reward: -60.0, step_mean: -0.038314176245210725
  total_deaths: 195.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 65.59 minutes

Epoch #93
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-92.pth
Results:
  total_reward: -86.5, step_mean: -0.055842479018721754
  total_deaths: 198.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 66.31 minutes

Epoch #94
 12%|█▏        | 94/800 [1:07:00<8:46:38, 44.76s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-93.pth
Results:
  total_reward: -79.0, step_mean: -0.050706033376123234
  total_deaths: 200.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 67.01 minutes

Epoch #95
 12%|█▏        | 95/800 [1:07:42<8:36:10, 43.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-94.pth
Results:
  total_reward: -45.0, step_mean: -0.02857142857142857
  total_deaths: 200.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 67.71 minutes

Epoch #96
 12%|█▏        | 96/800 [1:08:23<8:25:53, 43.12s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-95.pth
Results:
  total_reward: -73.5, step_mean: -0.047419354838709675
  total_deaths: 203.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 68.40 minutes

Epoch #97
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-96.pth
Results:
  total_reward: -74.0, step_mean: -0.04749679075738126
  total_deaths: 205.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 69.08 minutes

Epoch #98
 12%|█▏        | 98/800 [1:09:46<8:15:35, 42.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-97.pth
Results:
  total_reward: -86.0, step_mean: -0.055807916937053864
  total_deaths: 209.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 69.78 minutes

Epoch #99
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-98.pth
Results:
  total_reward: -68.5, step_mean: -0.04396662387676508
  total_deaths: 211.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 70.49 minutes

Epoch #100
 12%|█▎        | 100/800 [1:11:10<8:11:10, 42.10s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-99.pth
Results:
  total_reward: -58.0, step_mean: -0.037227214377406934
  total_deaths: 213.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 71.18 minutes

Epoch #101
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-100.pth
Results:
  total_reward: -77.0, step_mean: -0.0499675535366645
  total_deaths: 217.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 71.86 minutes

Epoch #102
 13%|█▎        | 102/800 [1:12:33<8:04:23, 41.64s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-101.pth
Results:
  total_reward: -66.5, step_mean: -0.042682926829268296
  total_deaths: 219.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 72.55 minutes

Epoch #103
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-102.pth
Results:
  total_reward: -75.5, step_mean: -0.0487411233053583
  total_deaths: 222.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 73.23 minutes

Epoch #104
 13%|█▎        | 104/800 [1:13:55<7:59:54, 41.37s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-103.pth
Results:
  total_reward: -57.5, step_mean: -0.03690629011553274
  total_deaths: 224.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 73.92 minutes

Epoch #105
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-104.pth
Results:
  total_reward: -56.0, step_mean: -0.035737077217613274
  total_deaths: 225.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 74.61 minutes

Epoch #106
 13%|█▎        | 106/800 [1:15:17<7:58:36, 41.38s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-105.pth
Results:
  total_reward: -58.5, step_mean: -0.03754813863928113
  total_deaths: 227.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 75.30 minutes

Epoch #107
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-106.pth
Results:
  total_reward: -66.0, step_mean: -0.042118698149329926
  total_deaths: 228.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 76.00 minutes

Epoch #108
 14%|█▎        | 108/800 [1:16:41<7:59:03, 41.54s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-107.pth
Results:
  total_reward: -75.5, step_mean: -0.04849068721901092
  total_deaths: 230.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 76.69 minutes

Epoch #109
 14%|█▎        | 109/800 [1:17:25<8:08:12, 42.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-108.pth
Results:
  total_reward: -66.0, step_mean: -0.0421455938697318
  total_deaths: 231.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 77.43 minutes

Epoch #110
 14%|█▍        | 110/800 [1:18:10<8:14:12, 42.97s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-109.pth
Results:
  total_reward: -65.0, step_mean: -0.041507024265644954
  total_deaths: 232.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 78.17 minutes

Epoch #111
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-110.pth
Results:
  total_reward: -68.0, step_mean: -0.04342273307790549
  total_deaths: 233.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 78.88 minutes

Epoch #112
 14%|█▍        | 112/800 [1:19:36<8:16:08, 43.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-111.pth
Results:
  total_reward: -69.0, step_mean: -0.044061302681992334
  total_deaths: 234.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 79.62 minutes

Epoch #113
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-112.pth
Results:
  total_reward: -80.5, step_mean: -0.05193548387096774
  total_deaths: 237.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 80.35 minutes

Epoch #114
 14%|█▍        | 114/800 [1:21:02<8:12:14, 43.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-113.pth
Results:
  total_reward: -71.0, step_mean: -0.04533844189016603
  total_deaths: 238.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 81.05 minutes

Epoch #115
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-114.pth
Results:
  total_reward: -81.0, step_mean: -0.05195638229634381
  total_deaths: 240.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 81.74 minutes

Epoch #116
 14%|█▍        | 116/800 [1:22:25<7:59:21, 42.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-115.pth
Results:
  total_reward: -67.5, step_mean: -0.04357650096836669
  total_deaths: 243.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 82.42 minutes

Epoch #117
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-116.pth
Results:
  total_reward: -78.0, step_mean: -0.05006418485237484
  total_deaths: 245.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 83.12 minutes

Epoch #118
 15%|█▍        | 118/800 [1:23:48<7:55:47, 41.86s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-117.pth
Results:
  total_reward: -92.0, step_mean: -0.05970149253731343
  total_deaths: 249.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 83.81 minutes

Epoch #119
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-118.pth
 15%|█▍        | 119/800 [1:24:31<7:57:12, 42.04s/it]Results:
  total_reward: -51.5, step_mean: -0.03286534779834078
  total_deaths: 250.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 84.52 minutes

Epoch #120
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-119.pth
Results:
  total_reward: -58.5, step_mean: -0.03735632183908046
  total_deaths: 251.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 85.19 minutes

Epoch #121
 15%|█▌        | 121/800 [1:25:51<7:46:26, 41.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-120.pth
Results:
  total_reward: -73.0, step_mean: -0.04709677419354839
  total_deaths: 254.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 85.87 minutes

Epoch #122
 15%|█▌        | 122/800 [1:26:33<7:47:01, 41.33s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-121.pth
Results:
  total_reward: -66.0, step_mean: -0.0421455938697318
  total_deaths: 255.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 86.56 minutes

Epoch #123
 15%|█▌        | 123/800 [1:27:14<7:46:27, 41.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-122.pth
Results:
  total_reward: -58.0, step_mean: -0.037013401403956606
  total_deaths: 256.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 87.25 minutes

Epoch #124
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-123.pth
Results:
  total_reward: -66.0, step_mean: -0.04238921001926782
  total_deaths: 258.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 87.94 minutes

Epoch #125
 16%|█▌        | 125/800 [1:28:37<7:45:02, 41.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-124.pth
Results:
  total_reward: -69.5, step_mean: -0.04438058748403576
  total_deaths: 259.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 88.63 minutes

Epoch #126
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-125.pth
Results:
  total_reward: -72.5, step_mean: -0.04656390494540784
  total_deaths: 261.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 89.32 minutes

Epoch #127
 16%|█▌        | 127/800 [1:30:00<7:45:13, 41.48s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-126.pth
Results:
  total_reward: -82.5, step_mean: -0.05295250320924262
  total_deaths: 263.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 90.01 minutes

Epoch #128
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-127.pth
Results:
  total_reward: -95.0, step_mean: -0.06097560975609756
  total_deaths: 265.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 90.70 minutes

Epoch #129
 16%|█▌        | 129/800 [1:31:24<7:46:28, 41.71s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-128.pth
Results:
  total_reward: -76.0, step_mean: -0.04878048780487805
  total_deaths: 267.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 91.40 minutes

Epoch #130
 16%|█▋        | 130/800 [1:32:06<7:45:55, 41.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-129.pth
Results:
  total_reward: -67.0, step_mean: -0.04300385109114249
  total_deaths: 269.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 92.10 minutes

Epoch #131
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-130.pth
Results:
  total_reward: -74.5, step_mean: -0.04806451612903226
  total_deaths: 272.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 92.81 minutes

Epoch #132
 16%|█▋        | 132/800 [1:33:31<7:49:50, 42.20s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-131.pth
Results:
  total_reward: -69.5, step_mean: -0.04438058748403576
  total_deaths: 273.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 93.52 minutes

Epoch #133
 17%|█▋        | 133/800 [1:34:13<7:47:29, 42.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-132.pth
Results:
  total_reward: -74.5, step_mean: -0.04806451612903226
  total_deaths: 276.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 94.22 minutes

Epoch #134
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-133.pth
Results:
  total_reward: -66.0, step_mean: -0.042118698149329926
  total_deaths: 277.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 94.93 minutes

Epoch #135
 17%|█▋        | 135/800 [1:35:38<7:50:38, 42.46s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-134.pth
Results:
  total_reward: -131.5, step_mean: -0.08391831525207402
  total_deaths: 278.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 95.65 minutes

Epoch #136
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-135.pth
 17%|█▋        | 136/800 [1:36:21<7:50:31, 42.52s/it]Results:
  total_reward: -78.5, step_mean: -0.05009572431397575
  total_deaths: 279.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 96.36 minutes

Epoch #137
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-136.pth
Results:
  total_reward: -49.5, step_mean: -0.03158902361199745
  total_deaths: 280.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 97.06 minutes

Epoch #138
 17%|█▋        | 138/800 [1:37:45<7:45:35, 42.20s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-137.pth
Results:
  total_reward: -69.5, step_mean: -0.04460847240051348
  total_deaths: 282.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 97.75 minutes

Epoch #139
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-138.pth
Results:
  total_reward: -49.0, step_mean: -0.03111111111111111
  total_deaths: 282.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 98.45 minutes

Epoch #140
 18%|█▊        | 140/800 [1:39:08<7:40:52, 41.90s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-139.pth
Results:
  total_reward: -51.5, step_mean: -0.03286534779834078
  total_deaths: 283.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 99.14 minutes

Epoch #141
 18%|█▊        | 141/800 [1:39:49<7:37:41, 41.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-140.pth
Results:
  total_reward: -72.0, step_mean: -0.046242774566473986
  total_deaths: 285.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 99.83 minutes

Epoch #142
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-141.pth
Results:
  total_reward: -61.5, step_mean: -0.039272030651340994
  total_deaths: 286.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 100.52 minutes

Epoch #143
 18%|█▊        | 143/800 [1:41:13<7:38:13, 41.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-142.pth
Results:
  total_reward: -58.0, step_mean: -0.037013401403956606
  total_deaths: 287.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 101.23 minutes

Epoch #144
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-143.pth
Results:
  total_reward: -70.0, step_mean: -0.04516129032258064
  total_deaths: 290.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 101.93 minutes

Epoch #145
 18%|█▊        | 145/800 [1:42:37<7:36:14, 41.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-144.pth
Results:
  total_reward: -77.5, step_mean: -0.04974326059050064
  total_deaths: 292.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 102.62 minutes

Epoch #146
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-145.pth
Results:
  total_reward: -60.0, step_mean: -0.038510911424903725
  total_deaths: 294.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 103.30 minutes

Epoch #147
 18%|█▊        | 147/800 [1:43:59<7:31:19, 41.47s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-146.pth
Results:
  total_reward: -75.5, step_mean: -0.048459563543003854
  total_deaths: 296.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 103.99 minutes

Epoch #148
 18%|█▊        | 148/800 [1:44:40<7:28:21, 41.26s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-147.pth
Results:
  total_reward: -77.5, step_mean: -0.050292018170019465
  total_deaths: 300.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 104.67 minutes

Epoch #149
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-148.pth
Results:
  total_reward: -69.0, step_mean: -0.04431599229287091
  total_deaths: 302.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 105.35 minutes

Epoch #150
 19%|█▉        | 150/800 [1:46:01<7:22:39, 40.86s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-149.pth
Results:
  total_reward: -73.0, step_mean: -0.046885035324341684
  total_deaths: 304.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 106.02 minutes

Epoch #151
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-150.pth
Results:
  total_reward: -62.5, step_mean: -0.0398851308232291
  total_deaths: 305.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 106.70 minutes

Epoch #152
 19%|█▉        | 152/800 [1:47:23<7:21:42, 40.90s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-151.pth
Results:
  total_reward: -48.5, step_mean: -0.030793650793650793
  total_deaths: 305.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 107.39 minutes

Epoch #153
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-152.pth
Results:
  total_reward: -47.0, step_mean: -0.029841269841269842
  total_deaths: 305.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 108.07 minutes

Epoch #154
 19%|█▉        | 154/800 [1:48:44<7:19:50, 40.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-153.pth
Results:
  total_reward: -73.5, step_mean: -0.04717586649550706
  total_deaths: 307.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 108.75 minutes

Epoch #155
 19%|█▉        | 155/800 [1:49:25<7:19:19, 40.87s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-154.pth
Results:
  total_reward: -43.5, step_mean: -0.02761904761904762
  total_deaths: 307.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 109.43 minutes

Epoch #156
 20%|█▉        | 156/800 [1:50:06<7:19:15, 40.92s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-155.pth
Results:
  total_reward: -84.0, step_mean: -0.054510058403634
  total_deaths: 311.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 110.11 minutes

Epoch #157
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-156.pth
Results:
  total_reward: -58.0, step_mean: -0.037227214377406934
  total_deaths: 313.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 110.80 minutes

Epoch #158
 20%|█▉        | 158/800 [1:51:29<7:20:33, 41.17s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-157.pth
Results:
  total_reward: -62.5, step_mean: -0.03991060025542784
  total_deaths: 314.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 111.49 minutes

Epoch #159
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-158.pth
Results:
  total_reward: -58.5, step_mean: -0.03754813863928113
  total_deaths: 316.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 112.18 minutes

Epoch #160
 20%|██        | 160/800 [1:52:50<7:16:06, 40.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-159.pth
Results:
  total_reward: -60.0, step_mean: -0.038510911424903725
  total_deaths: 318.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 112.85 minutes

Epoch #161
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-160.pth
Results:
  total_reward: -79.5, step_mean: -0.051323434473854096
  total_deaths: 321.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 113.52 minutes

Epoch #162
 20%|██        | 162/800 [1:54:12<7:13:30, 40.77s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-161.pth
Results:
  total_reward: -57.5, step_mean: -0.036717752234993614
  total_deaths: 322.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 114.20 minutes

Epoch #163
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-162.pth
Results:
  total_reward: -78.5, step_mean: -0.05064516129032258
  total_deaths: 325.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 114.87 minutes

Epoch #164
 20%|██        | 164/800 [1:55:33<7:10:47, 40.64s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-163.pth
Results:
  total_reward: -59.0, step_mean: -0.037869062901155326
  total_deaths: 327.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 115.55 minutes

Epoch #165
 21%|██        | 165/800 [1:56:13<7:09:48, 40.61s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-164.pth
Results:
  total_reward: -62.5, step_mean: -0.04011553273427471
  total_deaths: 329.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 116.23 minutes

Epoch #166
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-165.pth
Results:
  total_reward: -63.5, step_mean: -0.04052329291640076
  total_deaths: 330.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 116.92 minutes

Epoch #167
 21%|██        | 167/800 [1:57:37<7:14:26, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-166.pth
Results:
  total_reward: -43.5, step_mean: -0.02761904761904762
  total_deaths: 330.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 117.62 minutes

Epoch #168
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-167.pth
Results:
  total_reward: -59.0, step_mean: -0.037675606641123884
  total_deaths: 331.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 118.31 minutes

Epoch #169
 21%|██        | 169/800 [1:58:59<7:12:47, 41.15s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-168.pth
Results:
  total_reward: -61.5, step_mean: -0.03924696873005743
  total_deaths: 332.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 118.99 minutes

Epoch #170
 21%|██▏       | 170/800 [1:59:40<7:10:34, 41.01s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-169.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 334.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 119.67 minutes

Epoch #171
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-170.pth
Results:
  total_reward: -68.0, step_mean: -0.043645699614890884
  total_deaths: 336.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 120.34 minutes

Epoch #172
 22%|██▏       | 172/800 [2:01:01<7:06:16, 40.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-171.pth
Results:
  total_reward: -70.0, step_mean: -0.0449582530507386
  total_deaths: 338.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 121.02 minutes

Epoch #173
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-172.pth
Results:
  total_reward: -60.5, step_mean: -0.03860880663688577
  total_deaths: 339.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 121.70 minutes

Epoch #174
 22%|██▏       | 174/800 [2:02:22<7:04:59, 40.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-173.pth
Results:
  total_reward: -63.0, step_mean: -0.040229885057471264
  total_deaths: 340.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 122.38 minutes

Epoch #175
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-174.pth
Results:
  total_reward: -63.5, step_mean: -0.040757381258023105
  total_deaths: 342.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 123.05 minutes

Epoch #176
 22%|██▏       | 176/800 [2:03:44<7:05:11, 40.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-175.pth
Results:
  total_reward: -54.5, step_mean: -0.0346031746031746
  total_deaths: 342.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 123.74 minutes

Epoch #177
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-176.pth
Results:
  total_reward: -59.0, step_mean: -0.037869062901155326
  total_deaths: 344.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 124.42 minutes

Epoch #178
 22%|██▏       | 178/800 [2:05:06<7:04:16, 40.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-177.pth
Results:
  total_reward: -81.5, step_mean: -0.052614590058102
  total_deaths: 347.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 125.11 minutes

Epoch #179
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-178.pth
Results:
  total_reward: -65.5, step_mean: -0.0420410783055199
  total_deaths: 349.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 125.81 minutes

Epoch #180
 22%|██▎       | 180/800 [2:06:29<7:06:11, 41.25s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-179.pth
Results:
  total_reward: -71.5, step_mean: -0.04589216944801027
  total_deaths: 351.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 126.50 minutes

Epoch #181
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-180.pth
Results:
  total_reward: -61.0, step_mean: -0.03915275994865212
  total_deaths: 353.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 127.17 minutes

Epoch #182
 23%|██▎       | 182/800 [2:07:50<7:01:54, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-181.pth
Results:
  total_reward: -61.5, step_mean: -0.039473684210526314
  total_deaths: 355.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 127.85 minutes

Epoch #183
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-182.pth
Results:
  total_reward: -70.5, step_mean: -0.04525032092426187
  total_deaths: 357.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 128.54 minutes

Epoch #184
 23%|██▎       | 184/800 [2:09:13<7:01:26, 41.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-183.pth
Results:
  total_reward: -79.0, step_mean: -0.0512987012987013
  total_deaths: 361.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 129.22 minutes

Epoch #185
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-184.pth
Results:
  total_reward: -45.0, step_mean: -0.02857142857142857
  total_deaths: 361.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 129.92 minutes

Epoch #186
 23%|██▎       | 186/800 [2:10:36<7:02:12, 41.26s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-185.pth
Results:
  total_reward: -82.0, step_mean: -0.05290322580645161
  total_deaths: 364.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 130.60 minutes

Epoch #187
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-186.pth
Results:
  total_reward: -53.5, step_mean: -0.03431686978832585
  total_deaths: 366.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 131.30 minutes

Epoch #188
 24%|██▎       | 188/800 [2:11:59<7:02:39, 41.44s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-187.pth
Results:
  total_reward: -51.0, step_mean: -0.032567049808429116
  total_deaths: 367.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 131.99 minutes

Epoch #189
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-188.pth
Results:
  total_reward: -80.0, step_mean: -0.05161290322580645
  total_deaths: 370.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 132.67 minutes

Epoch #190
 24%|██▍       | 190/800 [2:13:21<6:58:12, 41.13s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-189.pth
Results:
  total_reward: -54.5, step_mean: -0.03498074454428755
  total_deaths: 372.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 133.35 minutes

Epoch #191
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-190.pth
Results:
  total_reward: -63.0, step_mean: -0.040229885057471264
  total_deaths: 373.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 134.04 minutes

Epoch #192
 24%|██▍       | 192/800 [2:14:43<6:55:40, 41.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-191.pth
Results:
  total_reward: -67.5, step_mean: -0.04332477535301669
  total_deaths: 375.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 134.72 minutes

Epoch #193
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-192.pth
Results:
  total_reward: -71.5, step_mean: -0.04589216944801027
  total_deaths: 377.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 135.41 minutes

Epoch #194
 24%|██▍       | 194/800 [2:16:05<6:56:02, 41.19s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-193.pth
Results:
  total_reward: -70.0, step_mean: -0.0449582530507386
  total_deaths: 379.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 136.10 minutes

Epoch #195
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-194.pth
Results:
  total_reward: -100.5, step_mean: -0.06521739130434782
  total_deaths: 383.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 136.77 minutes

Epoch #196
 24%|██▍       | 196/800 [2:17:28<6:54:49, 41.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-195.pth
Results:
  total_reward: -61.0, step_mean: -0.038952745849297574
  total_deaths: 384.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 137.47 minutes

Epoch #197
 25%|██▍       | 197/800 [2:18:13<7:06:14, 42.41s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-196.pth
Results:
  total_reward: -69.5, step_mean: -0.04460847240051348
  total_deaths: 386.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 138.22 minutes

Epoch #198
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-197.pth
Results:
  total_reward: -54.5, step_mean: -0.034802043422733075
  total_deaths: 387.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 138.97 minutes

Epoch #199
 25%|██▍       | 199/800 [2:19:43<7:20:00, 43.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-198.pth
Results:
  total_reward: -54.5, step_mean: -0.03477983407785577
  total_deaths: 388.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 139.73 minutes

Epoch #200
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-199.pth
Results:
  total_reward: -58.0, step_mean: -0.037013401403956606
  total_deaths: 389.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 140.44 minutes

Epoch #201
 25%|██▌       | 201/800 [2:21:07<7:07:56, 42.87s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-200.pth
Results:
  total_reward: -69.0, step_mean: -0.044516129032258066
  total_deaths: 392.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 141.13 minutes

Epoch #202
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-201.pth
Results:
  total_reward: -58.0, step_mean: -0.03720333547145606
  total_deaths: 394.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 141.83 minutes

Epoch #203
 25%|██▌       | 203/800 [2:22:31<7:02:07, 42.42s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-202.pth
Results:
  total_reward: -53.0, step_mean: -0.03384418901660281
  total_deaths: 395.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 142.53 minutes

Epoch #204
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-203.pth
Results:
  total_reward: -61.5, step_mean: -0.039473684210526314
  total_deaths: 397.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 143.23 minutes

Epoch #205
 26%|██▌       | 205/800 [2:23:56<7:00:22, 42.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-204.pth
Results:
  total_reward: -74.0, step_mean: -0.04774193548387097
  total_deaths: 400.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 143.94 minutes

Epoch #206
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-205.pth
Results:
  total_reward: -44.0, step_mean: -0.028241335044929396
  total_deaths: 402.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 144.66 minutes

Epoch #207
 26%|██▌       | 207/800 [2:25:28<7:21:32, 44.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-206.pth
Results:
  total_reward: -66.0, step_mean: -0.04238921001926782
  total_deaths: 404.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 145.48 minutes

Epoch #208
 26%|██▌       | 208/800 [2:26:26<7:58:36, 48.51s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-207.pth
Results:
  total_reward: -69.0, step_mean: -0.044287548138639284
  total_deaths: 406.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 146.44 minutes

Epoch #209
 26%|██▌       | 209/800 [2:27:23<8:22:51, 51.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-208.pth
Results:
  total_reward: -55.5, step_mean: -0.035440613026819924
  total_deaths: 407.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 147.39 minutes

Epoch #210
 26%|██▋       | 210/800 [2:28:13<8:18:28, 50.69s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-209.pth
Results:
  total_reward: -55.0, step_mean: -0.0351213282247765
  total_deaths: 408.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 148.22 minutes

Epoch #211
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-210.pth
Results:
  total_reward: -55.5, step_mean: -0.035440613026819924
  total_deaths: 409.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 148.96 minutes

Epoch #212
 26%|██▋       | 212/800 [2:29:41<7:44:12, 47.37s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-211.pth
Results:
  total_reward: -63.0, step_mean: -0.040229885057471264
  total_deaths: 410.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 149.70 minutes

Epoch #213
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-212.pth
Results:
  total_reward: -52.0, step_mean: -0.033205619412515965
  total_deaths: 411.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 150.41 minutes

Epoch #214
 27%|██▋       | 214/800 [2:31:06<7:17:12, 44.77s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-213.pth
Results:
  total_reward: -62.5, step_mean: -0.03991060025542784
  total_deaths: 412.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 151.11 minutes

Epoch #215
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-214.pth
Results:
  total_reward: -38.0, step_mean: -0.02412698412698413
  total_deaths: 412.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 151.82 minutes

Epoch #216
 27%|██▋       | 216/800 [2:32:31<7:03:29, 43.51s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-215.pth
Results:
  total_reward: -70.5, step_mean: -0.04525032092426187
  total_deaths: 414.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 152.52 minutes

Epoch #217
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-216.pth
Results:
  total_reward: -72.0, step_mean: -0.046481601032924466
  total_deaths: 417.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 153.23 minutes

Epoch #218
 27%|██▋       | 218/800 [2:33:54<6:52:46, 42.55s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-217.pth
Results:
  total_reward: -59.0, step_mean: -0.037869062901155326
  total_deaths: 419.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 153.91 minutes

Epoch #219
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-218.pth
Results:
  total_reward: -67.0, step_mean: -0.04300385109114249
  total_deaths: 421.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 154.60 minutes

Epoch #220
 28%|██▊       | 220/800 [2:35:18<6:48:53, 42.30s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-219.pth
Results:
  total_reward: -74.5, step_mean: -0.04809554551323435
  total_deaths: 424.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 155.31 minutes

Epoch #221
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-220.pth
Results:
  total_reward: -60.0, step_mean: -0.038510911424903725
  total_deaths: 426.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 156.01 minutes

Epoch #222
 28%|██▊       | 222/800 [2:36:41<6:42:27, 41.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-221.pth
Results:
  total_reward: -55.0, step_mean: -0.03509891512444161
  total_deaths: 427.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 156.69 minutes

Epoch #223
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-222.pth
Results:
  total_reward: -38.0, step_mean: -0.02412698412698413
  total_deaths: 427.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 157.40 minutes

Epoch #224
 28%|██▊       | 224/800 [2:38:05<6:43:03, 41.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-223.pth
Results:
  total_reward: -71.5, step_mean: -0.04592164418754014
  total_deaths: 429.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 158.10 minutes

Epoch #225
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-224.pth
Results:
  total_reward: -59.5, step_mean: -0.03818998716302952
  total_deaths: 431.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 158.78 minutes

Epoch #226
 28%|██▊       | 226/800 [2:39:27<6:37:08, 41.51s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-225.pth
Results:
  total_reward: -65.5, step_mean: -0.04225806451612903
  total_deaths: 434.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 159.47 minutes

Epoch #227
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-226.pth
Results:
  total_reward: -52.0, step_mean: -0.03318442884492661
  total_deaths: 435.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 160.15 minutes

Epoch #228
 28%|██▊       | 228/800 [2:40:50<6:34:03, 41.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-227.pth
Results:
  total_reward: -35.5, step_mean: -0.02253968253968254
  total_deaths: 435.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 160.84 minutes

Epoch #229
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-228.pth
Results:
  total_reward: -50.5, step_mean: -0.03239255933290571
  total_deaths: 437.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 161.52 minutes

Epoch #230
 29%|██▉       | 230/800 [2:42:12<6:31:02, 41.16s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-229.pth
Results:
  total_reward: -75.5, step_mean: -0.048709677419354835
  total_deaths: 440.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 162.20 minutes

Epoch #231
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-230.pth
Results:
  total_reward: -57.0, step_mean: -0.036608863198458574
  total_deaths: 442.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 162.88 minutes

Epoch #232
 29%|██▉       | 232/800 [2:43:34<6:29:29, 41.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-231.pth
Results:
  total_reward: -58.5, step_mean: -0.03733248245054244
  total_deaths: 443.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 163.57 minutes

Epoch #233
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-232.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 445.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 164.26 minutes

Epoch #234
 29%|██▉       | 234/800 [2:44:56<6:26:37, 40.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-233.pth
Results:
  total_reward: -68.5, step_mean: -0.04419354838709678
  total_deaths: 448.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 164.94 minutes

Epoch #235
 29%|██▉       | 235/800 [2:45:36<6:25:22, 40.92s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-234.pth
Results:
  total_reward: -62.0, step_mean: -0.03982016698779704
  total_deaths: 450.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 165.62 minutes

Epoch #236
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-235.pth
Results:
  total_reward: -84.0, step_mean: -0.05422853453841188
  total_deaths: 453.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 166.29 minutes

Epoch #237
 30%|██▉       | 237/800 [2:46:58<6:23:51, 40.91s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-236.pth
Results:
  total_reward: -70.5, step_mean: -0.04527938342967245
  total_deaths: 455.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 166.98 minutes

Epoch #238
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-237.pth
Results:
  total_reward: -80.5, step_mean: -0.05196901226597805
  total_deaths: 458.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 167.67 minutes

Epoch #239
 30%|██▉       | 239/800 [2:48:22<6:27:33, 41.45s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-238.pth
Results:
  total_reward: -66.5, step_mean: -0.042682926829268296
  total_deaths: 460.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 168.38 minutes

Epoch #240
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-239.pth
Results:
  total_reward: -75.0, step_mean: -0.04813863928112965
  total_deaths: 462.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 169.07 minutes

Epoch #241
 30%|███       | 241/800 [2:49:45<6:25:40, 41.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-240.pth
Results:
  total_reward: -63.5, step_mean: -0.040757381258023105
  total_deaths: 464.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 169.75 minutes

Epoch #242
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-241.pth
Results:
  total_reward: -63.5, step_mean: -0.04052329291640076
  total_deaths: 465.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 170.45 minutes

Epoch #243
 30%|███       | 243/800 [2:51:10<6:31:58, 42.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-242.pth
Results:
  total_reward: -72.5, step_mean: -0.046534017971758664
  total_deaths: 467.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 171.18 minutes

Epoch #244
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-243.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 469.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 171.90 minutes

Epoch #245
 31%|███       | 245/800 [2:52:36<6:33:15, 42.51s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-244.pth
Results:
  total_reward: -59.0, step_mean: -0.03765156349712827
  total_deaths: 470.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 172.61 minutes

Epoch #246
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-245.pth
Results:
  total_reward: -52.0, step_mean: -0.033205619412515965
  total_deaths: 471.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 173.31 minutes

Epoch #247
 31%|███       | 247/800 [2:53:59<6:27:07, 42.00s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-246.pth
Results:
  total_reward: -48.5, step_mean: -0.030970625798212005
  total_deaths: 472.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 173.99 minutes

Epoch #248
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-247.pth
Results:
  total_reward: -57.0, step_mean: -0.03639846743295019
  total_deaths: 473.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 174.68 minutes

Epoch #249
 31%|███       | 249/800 [2:55:22<6:24:09, 41.83s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-248.pth
Results:
  total_reward: -55.5, step_mean: -0.03559974342527261
  total_deaths: 475.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 175.38 minutes

Epoch #250
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-249.pth
Results:
  total_reward: -61.0, step_mean: -0.03915275994865212
  total_deaths: 477.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 176.07 minutes

Epoch #251
 31%|███▏      | 251/800 [2:56:45<6:19:22, 41.46s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-250.pth
Results:
  total_reward: -70.5, step_mean: -0.045221295702373314
  total_deaths: 479.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 176.75 minutes

Epoch #252
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-251.pth
Results:
  total_reward: -60.0, step_mean: -0.03870967741935484
  total_deaths: 482.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 177.44 minutes

Epoch #253
 32%|███▏      | 253/800 [2:58:07<6:15:37, 41.20s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-252.pth
Results:
  total_reward: -58.0, step_mean: -0.037013401403956606
  total_deaths: 483.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 178.12 minutes

Epoch #254
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-253.pth
Results:
  total_reward: -57.5, step_mean: -0.03690629011553274
  total_deaths: 485.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 179.04 minutes

Epoch #255
 32%|███▏      | 255/800 [2:59:45<6:46:51, 44.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-254.pth
Results:
  total_reward: -54.0, step_mean: -0.03446075303126994
  total_deaths: 486.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 179.76 minutes

Epoch #256
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-255.pth
Results:
  total_reward: -78.5, step_mean: -0.05067785668173015
  total_deaths: 489.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 180.57 minutes

Epoch #257
 32%|███▏      | 257/800 [3:01:20<6:55:09, 45.87s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-256.pth
Results:
  total_reward: -54.5, step_mean: -0.034802043422733075
  total_deaths: 490.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 181.34 minutes

Epoch #258
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-257.pth
Results:
  total_reward: -94.0, step_mean: -0.06103896103896104
  total_deaths: 494.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 182.04 minutes

Epoch #259
 32%|███▏      | 259/800 [3:02:52<6:57:37, 46.32s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-258.pth
Results:
  total_reward: -51.0, step_mean: -0.03254626675175495
  total_deaths: 495.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 182.87 minutes

Epoch #260
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-259.pth
Results:
  total_reward: -69.5, step_mean: -0.04463712267180475
  total_deaths: 497.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 183.66 minutes

Epoch #261
 33%|███▎      | 261/800 [3:04:25<6:56:19, 46.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-260.pth
Results:
  total_reward: -48.5, step_mean: -0.030970625798212005
  total_deaths: 498.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 184.42 minutes

Epoch #262
 33%|███▎      | 262/800 [3:05:10<6:51:51, 45.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-261.pth
Results:
  total_reward: -62.0, step_mean: -0.03959131545338442
  total_deaths: 499.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 185.17 minutes

Epoch #263
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-262.pth
Results:
  total_reward: -53.0, step_mean: -0.03384418901660281
  total_deaths: 500.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 185.90 minutes

Epoch #264
 33%|███▎      | 264/800 [3:06:37<6:40:48, 44.87s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-263.pth
Results:
  total_reward: -75.5, step_mean: -0.048709677419354835
  total_deaths: 503.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 186.63 minutes

Epoch #265
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-264.pth
Results:
  total_reward: -74.5, step_mean: -0.04809554551323435
  total_deaths: 506.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 187.36 minutes

Epoch #266
 33%|███▎      | 266/800 [3:08:02<6:26:36, 43.44s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-265.pth
Results:
  total_reward: -67.0, step_mean: -0.04300385109114249
  total_deaths: 508.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 188.04 minutes

Epoch #267
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-266.pth
Results:
  total_reward: -50.5, step_mean: -0.032247765006385695
  total_deaths: 509.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 188.73 minutes

Epoch #268
 34%|███▎      | 268/800 [3:09:27<6:20:29, 42.91s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-267.pth
Results:
  total_reward: -34.0, step_mean: -0.02158730158730159
  total_deaths: 509.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 189.45 minutes

Epoch #269
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-268.pth
Results:
  total_reward: -75.0, step_mean: -0.04813863928112965
  total_deaths: 511.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 190.15 minutes

Epoch #270
 34%|███▍      | 270/800 [3:10:49<6:11:54, 42.10s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-269.pth
Results:
  total_reward: -89.0, step_mean: -0.057456423499031635
  total_deaths: 514.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 190.83 minutes

Epoch #271
 34%|███▍      | 271/800 [3:11:32<6:12:15, 42.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-270.pth
Results:
  total_reward: -39.0, step_mean: -0.024761904761904763
  total_deaths: 514.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 191.54 minutes

Epoch #272
 34%|███▍      | 272/800 [3:12:14<6:10:28, 42.10s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-271.pth
Results:
  total_reward: -79.5, step_mean: -0.05158987670343933
  total_deaths: 518.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 192.24 minutes

Epoch #273
 34%|███▍      | 273/800 [3:12:55<6:08:36, 41.97s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-272.pth
Results:
  total_reward: -76.5, step_mean: -0.04910141206675225
  total_deaths: 520.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 192.93 minutes

Epoch #274
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-273.pth
Results:
  total_reward: -58.0, step_mean: -0.037013401403956606
  total_deaths: 521.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 193.63 minutes

Epoch #275
 34%|███▍      | 275/800 [3:14:19<6:06:54, 41.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-274.pth
Results:
  total_reward: -61.0, step_mean: -0.038952745849297574
  total_deaths: 522.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 194.33 minutes

Epoch #276
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-275.pth
Results:
  total_reward: -75.5, step_mean: -0.048709677419354835
  total_deaths: 525.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 195.04 minutes

Epoch #277
 35%|███▍      | 277/800 [3:15:44<6:07:24, 42.15s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-276.pth
Results:
  total_reward: -60.0, step_mean: -0.038314176245210725
  total_deaths: 526.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 195.74 minutes

Epoch #278
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-277.pth
Results:
  total_reward: -67.0, step_mean: -0.043225806451612905
  total_deaths: 529.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 196.43 minutes

Epoch #279
 35%|███▍      | 279/800 [3:17:08<6:04:54, 42.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-278.pth
Results:
  total_reward: -80.0, step_mean: -0.05161290322580645
  total_deaths: 532.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 197.14 minutes

Epoch #280
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-279.pth
Results:
  total_reward: -51.0, step_mean: -0.032567049808429116
  total_deaths: 533.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 197.84 minutes

Epoch #281
 35%|███▌      | 281/800 [3:18:32<6:03:21, 42.01s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-280.pth
Results:
  total_reward: -62.5, step_mean: -0.040141297366730895
  total_deaths: 535.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 198.54 minutes

Epoch #282
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-281.pth
Results:
  total_reward: -76.0, step_mean: -0.04878048780487805
  total_deaths: 537.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 199.24 minutes

Epoch #283
 35%|███▌      | 283/800 [3:19:54<5:58:00, 41.55s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-282.pth
Results:
  total_reward: -73.5, step_mean: -0.04717586649550706
  total_deaths: 539.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 199.91 minutes

Epoch #284
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-283.pth
Results:
  total_reward: -82.0, step_mean: -0.05290322580645161
  total_deaths: 542.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 200.58 minutes

Epoch #285
 36%|███▌      | 285/800 [3:21:14<5:49:04, 40.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-284.pth
Results:
  total_reward: -81.0, step_mean: -0.05256327060350422
  total_deaths: 546.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 201.24 minutes

Epoch #286
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-285.pth
Results:
  total_reward: -75.5, step_mean: -0.048459563543003854
  total_deaths: 548.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 201.91 minutes

Epoch #287
 36%|███▌      | 287/800 [3:22:34<5:44:25, 40.28s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-286.pth
Results:
  total_reward: -71.0, step_mean: -0.045806451612903226
  total_deaths: 551.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 202.57 minutes

Epoch #288
 36%|███▌      | 288/800 [3:23:14<5:43:08, 40.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-287.pth
Results:
  total_reward: -64.0, step_mean: -0.0410783055198973
  total_deaths: 553.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 203.24 minutes

Epoch #289
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-288.pth
Results:
  total_reward: -45.0, step_mean: -0.02871729419272495
  total_deaths: 554.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 203.92 minutes

Epoch #290
 36%|███▋      | 290/800 [3:24:35<5:42:54, 40.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-289.pth
Results:
  total_reward: -69.5, step_mean: -0.04463712267180475
  total_deaths: 556.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 204.59 minutes

Epoch #291
 36%|███▋      | 291/800 [3:25:16<5:44:01, 40.55s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-290.pth
Results:
  total_reward: -52.5, step_mean: -0.033697047496790755
  total_deaths: 558.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 205.27 minutes

Epoch #292
 36%|███▋      | 292/800 [3:25:56<5:43:09, 40.53s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-291.pth
Results:
  total_reward: -65.0, step_mean: -0.041480536056158264
  total_deaths: 559.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 205.95 minutes

Epoch #293
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-292.pth
Results:
  total_reward: -60.0, step_mean: -0.038510911424903725
  total_deaths: 561.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 206.62 minutes

Epoch #294
 37%|███▋      | 294/800 [3:27:17<5:41:52, 40.54s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-293.pth
Results:
  total_reward: -55.5, step_mean: -0.03541799617102744
  total_deaths: 562.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 207.30 minutes

Epoch #295
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-294.pth
Results:
  total_reward: -53.0, step_mean: -0.03384418901660281
  total_deaths: 563.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 207.97 minutes

Epoch #296
 37%|███▋      | 296/800 [3:28:39<5:40:57, 40.59s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-295.pth
Results:
  total_reward: -43.0, step_mean: -0.027301587301587302
  total_deaths: 563.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 208.65 minutes

Epoch #297
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-296.pth
Results:
  total_reward: -64.5, step_mean: -0.041399229781771504
  total_deaths: 565.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 209.33 minutes

Epoch #298
 37%|███▋      | 298/800 [3:30:01<5:42:39, 40.95s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-297.pth
Results:
  total_reward: -79.5, step_mean: -0.05099422706863374
  total_deaths: 567.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 210.02 minutes

Epoch #299
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-298.pth
Results:
  total_reward: -86.0, step_mean: -0.05551969012265978
  total_deaths: 570.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 210.69 minutes

Epoch #300
 38%|███▊      | 300/800 [3:31:21<5:38:23, 40.61s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-299.pth
Results:
  total_reward: -79.0, step_mean: -0.051000645577792124
  total_deaths: 573.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 211.37 minutes

Epoch #301
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-300.pth
Results:
  total_reward: -62.0, step_mean: -0.040025823111684955
  total_deaths: 576.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 212.04 minutes

Epoch #302
 38%|███▊      | 302/800 [3:32:42<5:35:07, 40.38s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-301.pth
Results:
  total_reward: -73.5, step_mean: -0.04717586649550706
  total_deaths: 578.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 212.71 minutes

Epoch #303
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-302.pth
Results:
  total_reward: -71.5, step_mean: -0.04592164418754014
  total_deaths: 580.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 213.40 minutes

Epoch #304
 38%|███▊      | 304/800 [3:34:03<5:33:28, 40.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-303.pth
Results:
  total_reward: -73.0, step_mean: -0.04709677419354839
  total_deaths: 583.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 214.06 minutes

Epoch #305
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-304.pth
Results:
  total_reward: -54.0, step_mean: -0.034482758620689655
  total_deaths: 584.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 214.72 minutes

Epoch #306
 38%|███▊      | 306/800 [3:35:24<5:32:55, 40.44s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-305.pth
Results:
  total_reward: -50.5, step_mean: -0.032063492063492065
  total_deaths: 584.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 215.40 minutes

Epoch #307
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-306.pth
Results:
  total_reward: -60.0, step_mean: -0.03828972559029994
  total_deaths: 585.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 216.08 minutes

Epoch #308
 38%|███▊      | 308/800 [3:36:44<5:30:12, 40.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-307.pth
Results:
  total_reward: -72.5, step_mean: -0.046534017971758664
  total_deaths: 587.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 216.74 minutes

Epoch #309
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-308.pth
Results:
  total_reward: -50.5, step_mean: -0.032413350449293964
  total_deaths: 589.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 217.41 minutes

Epoch #310
 39%|███▉      | 310/800 [3:38:04<5:28:07, 40.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-309.pth
Results:
  total_reward: -51.0, step_mean: -0.03238095238095238
  total_deaths: 589.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 218.08 minutes

Epoch #311
 39%|███▉      | 311/800 [3:38:44<5:25:51, 39.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-310.pth
Results:
  total_reward: -84.0, step_mean: -0.054510058403634
  total_deaths: 593.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 218.74 minutes

Epoch #312
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-311.pth
Results:
  total_reward: -56.5, step_mean: -0.03624118024374599
  total_deaths: 595.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 219.41 minutes

Epoch #313
 39%|███▉      | 313/800 [3:40:04<5:24:10, 39.94s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-312.pth
Results:
  total_reward: -79.5, step_mean: -0.051323434473854096
  total_deaths: 598.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 220.07 minutes

Epoch #314
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-313.pth
Results:
  total_reward: -63.0, step_mean: -0.04043645699614891
  total_deaths: 600.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 220.74 minutes

Epoch #315
 39%|███▉      | 315/800 [3:41:24<5:23:28, 40.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-314.pth
Results:
  total_reward: -66.0, step_mean: -0.04236200256739409
  total_deaths: 602.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 221.41 minutes

Epoch #316
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-315.pth
Results:
  total_reward: -40.0, step_mean: -0.025396825396825397
  total_deaths: 602.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 222.08 minutes

Epoch #317
 40%|███▉      | 317/800 [3:42:44<5:22:31, 40.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-316.pth
Results:
  total_reward: -60.5, step_mean: -0.03860880663688577
  total_deaths: 603.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 222.74 minutes

Epoch #318
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-317.pth
Results:
  total_reward: -45.0, step_mean: -0.028735632183908046
  total_deaths: 604.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 223.42 minutes

Epoch #319
 40%|███▉      | 319/800 [3:44:05<5:22:13, 40.19s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-318.pth
Results:
  total_reward: -76.0, step_mean: -0.04878048780487805
  total_deaths: 606.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 224.09 minutes

Epoch #320
 40%|████      | 320/800 [3:44:45<5:20:33, 40.07s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-319.pth
Results:
  total_reward: -64.5, step_mean: -0.04116145500957243
  total_deaths: 607.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 224.75 minutes

Epoch #321
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-320.pth
Results:
  total_reward: -59.0, step_mean: -0.03765156349712827
  total_deaths: 608.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 225.42 minutes

Epoch #322
 40%|████      | 322/800 [3:46:05<5:19:52, 40.15s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-321.pth
Results:
  total_reward: -47.5, step_mean: -0.03033205619412516
  total_deaths: 609.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 226.09 minutes

Epoch #323
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-322.pth
Results:
  total_reward: -78.5, step_mean: -0.05090791180285344
  total_deaths: 613.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 226.75 minutes

Epoch #324
 40%|████      | 324/800 [3:47:25<5:18:40, 40.17s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-323.pth
Results:
  total_reward: -55.5, step_mean: -0.035806451612903224
  total_deaths: 616.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 227.43 minutes

Epoch #325
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-324.pth
Results:
  total_reward: -51.0, step_mean: -0.032567049808429116
  total_deaths: 617.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 228.10 minutes

Epoch #326
 41%|████      | 326/800 [3:48:46<5:17:51, 40.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-325.pth
Results:
  total_reward: -63.0, step_mean: -0.040671400903808906
  total_deaths: 620.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 228.77 minutes

Epoch #327
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-326.pth
Results:
  total_reward: -57.0, step_mean: -0.03639846743295019
  total_deaths: 621.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 229.44 minutes

Epoch #328
 41%|████      | 328/800 [3:50:07<5:17:13, 40.33s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-327.pth
Results:
  total_reward: -59.5, step_mean: -0.037970644543714106
  total_deaths: 622.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 230.12 minutes

Epoch #329
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-328.pth
Results:
  total_reward: -52.0, step_mean: -0.03337612323491656
  total_deaths: 624.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 230.78 minutes

Epoch #330
 41%|████▏     | 330/800 [3:51:26<5:13:44, 40.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-329.pth
Results:
  total_reward: -70.5, step_mean: -0.04525032092426187
  total_deaths: 626.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 231.45 minutes

Epoch #331
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-330.pth
Results:
  total_reward: -69.0, step_mean: -0.044287548138639284
  total_deaths: 628.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 232.11 minutes

Epoch #332
 42%|████▏     | 332/800 [3:52:46<5:12:28, 40.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-331.pth
Results:
  total_reward: -65.5, step_mean: -0.041826309067688375
  total_deaths: 629.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 232.78 minutes

Epoch #333
 42%|████▏     | 333/800 [3:53:27<5:13:39, 40.30s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-332.pth
Results:
  total_reward: -51.5, step_mean: -0.0326984126984127
  total_deaths: 629.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 233.46 minutes

Epoch #334
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-333.pth
Results:
  total_reward: -69.0, step_mean: -0.044287548138639284
  total_deaths: 631.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 234.14 minutes

Epoch #335
 42%|████▏     | 335/800 [3:54:47<5:10:22, 40.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-334.pth
Results:
  total_reward: -55.5, step_mean: -0.035622593068035946
  total_deaths: 633.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 234.79 minutes

Epoch #336
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-335.pth
Results:
  total_reward: -70.5, step_mean: -0.04548387096774194
  total_deaths: 636.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 235.45 minutes

Epoch #337
 42%|████▏     | 337/800 [3:56:07<5:08:07, 39.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-336.pth
Results:
  total_reward: -63.5, step_mean: -0.040994189799870885
  total_deaths: 639.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 236.12 minutes

Epoch #338
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-337.pth
Results:
  total_reward: -56.5, step_mean: -0.036056158264199105
  total_deaths: 640.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 236.79 minutes

Epoch #339
 42%|████▏     | 339/800 [3:57:28<5:10:06, 40.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-338.pth
Results:
  total_reward: -63.5, step_mean: -0.040549169859514685
  total_deaths: 641.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 237.48 minutes

Epoch #340
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-339.pth
Results:
  total_reward: -59.0, step_mean: -0.03784477228992944
  total_deaths: 643.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 238.14 minutes

Epoch #341
 43%|████▎     | 341/800 [3:58:48<5:08:12, 40.29s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-340.pth
Results:
  total_reward: -53.5, step_mean: -0.034163473818646234
  total_deaths: 644.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 238.82 minutes

Epoch #342
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-341.pth
Results:
  total_reward: -56.0, step_mean: -0.03594351732991014
  total_deaths: 646.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 239.49 minutes

Epoch #343
 43%|████▎     | 343/800 [4:00:10<5:08:31, 40.51s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-342.pth
Results:
  total_reward: -51.5, step_mean: -0.03286534779834078
  total_deaths: 647.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 240.17 minutes

Epoch #344
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-343.pth
Results:
  total_reward: -66.0, step_mean: -0.04236200256739409
  total_deaths: 649.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 240.84 minutes

Epoch #345
 43%|████▎     | 345/800 [4:01:30<5:06:04, 40.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-344.pth
Results:
  total_reward: -71.5, step_mean: -0.046129032258064515
  total_deaths: 652.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 241.51 minutes

Epoch #346
 43%|████▎     | 346/800 [4:02:11<5:06:58, 40.57s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-345.pth
Results:
  total_reward: -54.5, step_mean: -0.03477983407785577
  total_deaths: 653.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 242.20 minutes

Epoch #347
 43%|████▎     | 347/800 [4:02:53<5:08:19, 40.84s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-346.pth
Results:
  total_reward: -71.0, step_mean: -0.045571245186136075
  total_deaths: 655.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 242.89 minutes

Epoch #348
 44%|████▎     | 348/800 [4:03:33<5:07:13, 40.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-347.pth
Results:
  total_reward: -81.5, step_mean: -0.052614590058102
  total_deaths: 658.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 243.56 minutes

Epoch #349
 44%|████▎     | 349/800 [4:04:14<5:06:34, 40.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-348.pth
Results:
  total_reward: -65.5, step_mean: -0.04201411161000641
  total_deaths: 660.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 244.24 minutes

Epoch #350
 44%|████▍     | 350/800 [4:04:56<5:08:02, 41.07s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-349.pth
Results:
  total_reward: -75.0, step_mean: -0.04810776138550353
  total_deaths: 662.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 244.94 minutes

Epoch #351
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-350.pth
Results:
  total_reward: -59.5, step_mean: -0.03818998716302952
  total_deaths: 664.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 245.62 minutes

Epoch #352
 44%|████▍     | 352/800 [4:06:18<5:07:56, 41.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-351.pth
Results:
  total_reward: -38.5, step_mean: -0.024444444444444446
  total_deaths: 664.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 246.32 minutes

Epoch #353
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-352.pth
Results:
  total_reward: -75.5, step_mean: -0.04842847979474022
  total_deaths: 666.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 246.99 minutes

Epoch #354
 44%|████▍     | 354/800 [4:07:40<5:04:25, 40.95s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-353.pth
Results:
  total_reward: -88.0, step_mean: -0.057441253263707574
  total_deaths: 671.0
  frag: 0.0
  death: 5.0
  global_step: 1532
Total elapsed time: 247.67 minutes

Epoch #355
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-354.pth
Results:
  total_reward: -68.0, step_mean: -0.04387096774193548
  total_deaths: 674.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 248.35 minutes

Epoch #356
 44%|████▍     | 356/800 [4:09:02<5:03:15, 40.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-355.pth
Results:
  total_reward: -73.0, step_mean: -0.04712717882504842
  total_deaths: 677.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 249.04 minutes

Epoch #357
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-356.pth
Results:
  total_reward: -50.5, step_mean: -0.03239255933290571
  total_deaths: 679.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 249.72 minutes

Epoch #358
 45%|████▍     | 358/800 [4:10:25<5:03:59, 41.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-357.pth
Results:
  total_reward: -54.0, step_mean: -0.03465982028241335
  total_deaths: 681.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 250.42 minutes

Epoch #359
 45%|████▍     | 359/800 [4:11:05<5:00:35, 40.90s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-358.pth
Results:
  total_reward: -62.5, step_mean: -0.0398851308232291
  total_deaths: 682.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 251.08 minutes

Epoch #360
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-359.pth
Results:
  total_reward: -57.0, step_mean: -0.036585365853658534
  total_deaths: 684.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 251.74 minutes

Epoch #361
 45%|████▌     | 361/800 [4:12:23<4:53:07, 40.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-360.pth
Results:
  total_reward: -47.0, step_mean: -0.029993618379068283
  total_deaths: 685.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 252.39 minutes

Epoch #362
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-361.pth
Results:
  total_reward: -67.0, step_mean: -0.042976266837716486
  total_deaths: 687.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 253.05 minutes

Epoch #363
 45%|████▌     | 363/800 [4:13:42<4:49:31, 39.75s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-362.pth
Results:
  total_reward: -45.5, step_mean: -0.029036375239310786
  total_deaths: 688.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 253.71 minutes

Epoch #364
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-363.pth
Results:
  total_reward: -63.5, step_mean: -0.040757381258023105
  total_deaths: 690.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 254.36 minutes

Epoch #365
 46%|████▌     | 365/800 [4:15:01<4:48:05, 39.74s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-364.pth
Results:
  total_reward: -51.5, step_mean: -0.032886334610472544
  total_deaths: 691.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 255.03 minutes

Epoch #366
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-365.pth
Results:
  total_reward: -69.5, step_mean: -0.04463712267180475
  total_deaths: 693.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 255.71 minutes

Epoch #367
 46%|████▌     | 367/800 [4:16:23<4:50:44, 40.29s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-366.pth
Results:
  total_reward: -61.0, step_mean: -0.03915275994865212
  total_deaths: 695.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 256.39 minutes

Epoch #368
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-367.pth
Results:
  total_reward: -71.5, step_mean: -0.046158812136862494
  total_deaths: 698.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 257.07 minutes

Epoch #369
 46%|████▌     | 369/800 [4:17:46<4:53:50, 40.91s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-368.pth
Results:
  total_reward: -56.5, step_mean: -0.036079182630906766
  total_deaths: 699.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 257.77 minutes

Epoch #370
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-369.pth
Results:
  total_reward: -58.0, step_mean: -0.037013401403956606
  total_deaths: 700.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 258.46 minutes

Epoch #371
 46%|████▋     | 371/800 [4:19:10<4:56:52, 41.52s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-370.pth
Results:
  total_reward: -66.0, step_mean: -0.0421455938697318
  total_deaths: 701.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 259.17 minutes

Epoch #372
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-371.pth
Results:
  total_reward: -68.5, step_mean: -0.04396662387676508
  total_deaths: 703.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 259.85 minutes

Epoch #373
 47%|████▋     | 373/800 [4:20:31<4:52:48, 41.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-372.pth
Results:
  total_reward: -57.0, step_mean: -0.036608863198458574
  total_deaths: 705.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 260.53 minutes

Epoch #374
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-373.pth
Results:
  total_reward: -58.5, step_mean: -0.03733248245054244
  total_deaths: 706.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 261.22 minutes

Epoch #375
 47%|████▋     | 375/800 [4:21:54<4:52:50, 41.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-374.pth
Results:
  total_reward: -45.0, step_mean: -0.02871729419272495
  total_deaths: 707.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 261.91 minutes

Epoch #376
 47%|████▋     | 376/800 [4:22:35<4:51:34, 41.26s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-375.pth
Results:
  total_reward: -70.5, step_mean: -0.04527938342967245
  total_deaths: 709.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 262.60 minutes

Epoch #377
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-376.pth
Results:
  total_reward: -72.5, step_mean: -0.046534017971758664
  total_deaths: 711.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 263.29 minutes

Epoch #378
 47%|████▋     | 378/800 [4:23:57<4:48:54, 41.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-377.pth
Results:
  total_reward: -59.0, step_mean: -0.037869062901155326
  total_deaths: 713.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 263.96 minutes

Epoch #379
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-378.pth
Results:
  total_reward: -69.5, step_mean: -0.04460847240051348
  total_deaths: 715.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 264.64 minutes

Epoch #380
 48%|████▊     | 380/800 [4:25:18<4:44:09, 40.59s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-379.pth
Results:
  total_reward: -69.0, step_mean: -0.044516129032258066
  total_deaths: 718.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 265.30 minutes

Epoch #381
 48%|████▊     | 381/800 [4:25:58<4:43:55, 40.66s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-380.pth
Results:
  total_reward: -42.5, step_mean: -0.027121888959795788
  total_deaths: 719.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 265.98 minutes

Epoch #382
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-381.pth
Results:
  total_reward: -76.0, step_mean: -0.04878048780487805
  total_deaths: 721.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 266.64 minutes

Epoch #383
 48%|████▊     | 383/800 [4:27:17<4:37:43, 39.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-382.pth
Results:
  total_reward: -67.0, step_mean: -0.042976266837716486
  total_deaths: 723.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 267.29 minutes

Epoch #384
 48%|████▊     | 384/800 [4:27:56<4:35:26, 39.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-383.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 725.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 267.94 minutes

Epoch #385
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-384.pth
Results:
  total_reward: -53.0, step_mean: -0.03384418901660281
  total_deaths: 726.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 268.60 minutes

Epoch #386
 48%|████▊     | 386/800 [4:29:14<4:31:35, 39.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-385.pth
Results:
  total_reward: -67.5, step_mean: -0.04332477535301669
  total_deaths: 728.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 269.25 minutes

Epoch #387
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-386.pth
Results:
  total_reward: -71.5, step_mean: -0.04589216944801027
  total_deaths: 730.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 269.90 minutes

Epoch #388
 48%|████▊     | 388/800 [4:30:32<4:29:29, 39.25s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-387.pth
Results:
  total_reward: -54.0, step_mean: -0.03446075303126994
  total_deaths: 731.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 270.55 minutes

Epoch #389
 49%|████▊     | 389/800 [4:31:12<4:29:02, 39.28s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-388.pth
Results:
  total_reward: -63.5, step_mean: -0.04052329291640076
  total_deaths: 732.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 271.21 minutes

Epoch #390
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-389.pth
Results:
  total_reward: -57.5, step_mean: -0.036717752234993614
  total_deaths: 733.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 271.86 minutes

Epoch #391
 49%|████▉     | 391/800 [4:32:31<4:28:10, 39.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-390.pth
Results:
  total_reward: -59.5, step_mean: -0.038387096774193545
  total_deaths: 736.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 272.52 minutes

Epoch #392
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-391.pth
Results:
  total_reward: -51.0, step_mean: -0.03238095238095238
  total_deaths: 736.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 273.19 minutes

Epoch #393
 49%|████▉     | 393/800 [4:33:51<4:30:05, 39.82s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-392.pth
Results:
  total_reward: -67.0, step_mean: -0.04303147077713552
  total_deaths: 738.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 273.86 minutes

Epoch #394
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-393.pth
Results:
  total_reward: -61.5, step_mean: -0.03967741935483871
  total_deaths: 741.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 274.53 minutes

Epoch #395
 49%|████▉     | 395/800 [4:35:11<4:28:23, 39.76s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-394.pth
Results:
  total_reward: -82.0, step_mean: -0.05293737895416398
  total_deaths: 744.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 275.19 minutes

Epoch #396
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-395.pth
Results:
  total_reward: -57.0, step_mean: -0.03639846743295019
  total_deaths: 745.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 275.86 minutes

Epoch #397
 50%|████▉     | 397/800 [4:36:31<4:28:38, 40.00s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-396.pth
Results:
  total_reward: -46.5, step_mean: -0.029674537332482452
  total_deaths: 746.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 276.53 minutes

Epoch #398
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-397.pth
Results:
  total_reward: -54.5, step_mean: -0.034802043422733075
  total_deaths: 747.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 277.20 minutes

Epoch #399
 50%|████▉     | 399/800 [4:37:53<4:30:08, 40.42s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-398.pth
Results:
  total_reward: -61.0, step_mean: -0.0389278876834716
  total_deaths: 748.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 277.89 minutes

Epoch #400
 50%|█████     | 400/800 [4:38:33<4:29:05, 40.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-399.pth
Results:
  total_reward: -71.5, step_mean: -0.04589216944801027
  total_deaths: 750.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 278.56 minutes

Epoch #401
 50%|█████     | 401/800 [4:39:13<4:28:10, 40.33s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-400.pth
Results:
  total_reward: -67.5, step_mean: -0.04310344827586207
  total_deaths: 751.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 279.23 minutes

Epoch #402
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-401.pth
Results:
  total_reward: -56.0, step_mean: -0.035737077217613274
  total_deaths: 752.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 279.90 minutes

Epoch #403
 50%|█████     | 403/800 [4:40:36<4:31:09, 40.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-402.pth
Results:
  total_reward: -84.0, step_mean: -0.054474708171206226
  total_deaths: 756.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 280.61 minutes

Epoch #404
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-403.pth
Results:
  total_reward: -53.0, step_mean: -0.03401797175866496
  total_deaths: 758.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 281.31 minutes

Epoch #405
 51%|█████     | 405/800 [4:41:59<4:31:48, 41.29s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-404.pth
Results:
  total_reward: -71.5, step_mean: -0.04589216944801027
  total_deaths: 760.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 282.00 minutes

Epoch #406
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-405.pth
Results:
  total_reward: -66.5, step_mean: -0.042682926829268296
  total_deaths: 762.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 282.68 minutes

Epoch #407
 51%|█████     | 407/800 [4:43:21<4:29:15, 41.11s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-406.pth
Results:
  total_reward: -65.5, step_mean: -0.04225806451612903
  total_deaths: 765.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 283.36 minutes

Epoch #408
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-407.pth
Results:
  total_reward: -73.5, step_mean: -0.04717586649550706
  total_deaths: 767.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 284.05 minutes

Epoch #409
 51%|█████     | 409/800 [4:44:44<4:28:43, 41.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-408.pth
Results:
  total_reward: -48.5, step_mean: -0.030970625798212005
  total_deaths: 768.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 284.74 minutes

Epoch #410
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-409.pth
Results:
  total_reward: -61.0, step_mean: -0.03915275994865212
  total_deaths: 770.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 285.43 minutes

Epoch #411
 51%|█████▏    | 411/800 [4:46:08<4:29:59, 41.64s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-410.pth
Results:
  total_reward: -55.0, step_mean: -0.03509891512444161
  total_deaths: 771.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 286.14 minutes

Epoch #412
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-411.pth
Results:
  total_reward: -53.0, step_mean: -0.03384418901660281
  total_deaths: 772.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 286.84 minutes

Epoch #413
 52%|█████▏    | 413/800 [4:47:32<4:30:09, 41.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-412.pth
Results:
  total_reward: -49.0, step_mean: -0.031269942565411615
  total_deaths: 773.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 287.54 minutes

Epoch #414
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-413.pth
Results:
  total_reward: -57.5, step_mean: -0.037096774193548385
  total_deaths: 776.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 288.24 minutes

Epoch #415
 52%|█████▏    | 415/800 [4:48:55<4:28:03, 41.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-414.pth
Results:
  total_reward: -63.5, step_mean: -0.040757381258023105
  total_deaths: 778.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 288.93 minutes

Epoch #416
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-415.pth
Results:
  total_reward: -45.5, step_mean: -0.028888888888888888
  total_deaths: 778.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 289.64 minutes

Epoch #417
 52%|█████▏    | 417/800 [4:50:20<4:27:57, 41.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-416.pth
Results:
  total_reward: -66.5, step_mean: -0.042682926829268296
  total_deaths: 780.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 290.34 minutes

Epoch #418
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-417.pth
Results:
  total_reward: -68.0, step_mean: -0.043645699614890884
  total_deaths: 782.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 291.04 minutes

Epoch #419
 52%|█████▏    | 419/800 [4:51:43<4:25:42, 41.84s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-418.pth
Results:
  total_reward: -70.0, step_mean: -0.0449582530507386
  total_deaths: 784.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 291.73 minutes

Epoch #420
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-419.pth
Results:
  total_reward: -77.5, step_mean: -0.05
  total_deaths: 787.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 292.43 minutes

Epoch #421
 53%|█████▎    | 421/800 [4:53:08<4:25:36, 42.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-420.pth
Results:
  total_reward: -58.5, step_mean: -0.03735632183908046
  total_deaths: 788.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 293.14 minutes

Epoch #422
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-421.pth
Results:
  total_reward: -74.5, step_mean: -0.047817715019255455
  total_deaths: 790.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 293.83 minutes

Epoch #423
 53%|█████▎    | 423/800 [4:54:32<4:25:24, 42.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-422.pth
Results:
  total_reward: -67.5, step_mean: -0.04335260115606936
  total_deaths: 792.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 294.55 minutes

Epoch #424
 53%|█████▎    | 424/800 [4:55:15<4:24:57, 42.28s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-423.pth
Results:
  total_reward: -61.0, step_mean: -0.0389278876834716
  total_deaths: 793.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 295.25 minutes

Epoch #425
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-424.pth
Results:
  total_reward: -73.0, step_mean: -0.047402597402597405
  total_deaths: 797.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 295.93 minutes

Epoch #426
 53%|█████▎    | 426/800 [4:56:36<4:17:33, 41.32s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-425.pth
Results:
  total_reward: -46.0, step_mean: -0.029206349206349208
  total_deaths: 797.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 296.60 minutes

Epoch #427
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-426.pth
Results:
  total_reward: -54.0, step_mean: -0.034482758620689655
  total_deaths: 798.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 297.29 minutes

Epoch #428
 54%|█████▎    | 428/800 [4:57:58<4:15:37, 41.23s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-427.pth
Results:
  total_reward: -34.5, step_mean: -0.022016592214422464
  total_deaths: 799.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 297.97 minutes

Epoch #429
 54%|█████▎    | 429/800 [4:58:39<4:14:23, 41.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-428.pth
Results:
  total_reward: -46.0, step_mean: -0.029206349206349208
  total_deaths: 799.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 298.65 minutes

Epoch #430
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-429.pth
Results:
  total_reward: -57.0, step_mean: -0.03639846743295019
  total_deaths: 800.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 299.33 minutes

Epoch #431
 54%|█████▍    | 431/800 [5:00:00<4:11:52, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-430.pth
Results:
  total_reward: -65.0, step_mean: -0.0417201540436457
  total_deaths: 802.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 300.01 minutes

Epoch #432
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-431.pth
Results:
  total_reward: -84.0, step_mean: -0.05422853453841188
  total_deaths: 805.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 300.68 minutes

Epoch #433
 54%|█████▍    | 433/800 [5:01:23<4:13:03, 41.37s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-432.pth
Results:
  total_reward: -49.5, step_mean: -0.03158902361199745
  total_deaths: 806.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 301.40 minutes

Epoch #434
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-433.pth
Results:
  total_reward: -71.0, step_mean: -0.045600513808606295
  total_deaths: 808.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 302.11 minutes

Epoch #435
 54%|█████▍    | 435/800 [5:02:48<4:14:32, 41.84s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-434.pth
Results:
  total_reward: -62.0, step_mean: -0.03979460847240052
  total_deaths: 810.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 302.81 minutes

Epoch #436
 55%|█████▍    | 436/800 [5:03:30<4:14:57, 42.03s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-435.pth
Results:
  total_reward: -73.5, step_mean: -0.04717586649550706
  total_deaths: 812.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 303.52 minutes

Epoch #437
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-436.pth
Results:
  total_reward: -87.0, step_mean: -0.05616526791478373
  total_deaths: 815.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 304.21 minutes

Epoch #438
 55%|█████▍    | 438/800 [5:04:54<4:11:58, 41.76s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-437.pth
Results:
  total_reward: -69.0, step_mean: -0.04431599229287091
  total_deaths: 817.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 304.90 minutes

Epoch #439
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-438.pth
Results:
  total_reward: -74.0, step_mean: -0.04749679075738126
  total_deaths: 819.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 305.58 minutes

Epoch #440
 55%|█████▌    | 440/800 [5:06:16<4:08:59, 41.50s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-439.pth
Results:
  total_reward: -48.0, step_mean: -0.03065134099616858
  total_deaths: 820.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 306.27 minutes

Epoch #441
 55%|█████▌    | 441/800 [5:06:56<4:06:36, 41.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-440.pth
Results:
  total_reward: -80.5, step_mean: -0.05166880616174583
  total_deaths: 822.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 306.95 minutes

Epoch #442
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-441.pth
Results:
  total_reward: -61.0, step_mean: -0.03915275994865212
  total_deaths: 824.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 307.64 minutes

Epoch #443
 55%|█████▌    | 443/800 [5:08:20<4:06:08, 41.37s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-442.pth
Results:
  total_reward: -66.0, step_mean: -0.04236200256739409
  total_deaths: 826.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 308.33 minutes

Epoch #444
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-443.pth
Results:
  total_reward: -54.5, step_mean: -0.03498074454428755
  total_deaths: 828.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 309.02 minutes

Epoch #445
 56%|█████▌    | 445/800 [5:09:42<4:03:49, 41.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-444.pth
Results:
  total_reward: -61.0, step_mean: -0.03915275994865212
  total_deaths: 830.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 309.70 minutes

Epoch #446
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-445.pth
Results:
  total_reward: -46.0, step_mean: -0.029206349206349208
  total_deaths: 830.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 310.39 minutes

Epoch #447
 56%|█████▌    | 447/800 [5:11:04<4:01:33, 41.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-446.pth
Results:
  total_reward: -71.5, step_mean: -0.046129032258064515
  total_deaths: 833.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 311.07 minutes

Epoch #448
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-447.pth
Results:
  total_reward: -64.0, step_mean: -0.0408423739629866
  total_deaths: 834.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 311.75 minutes

Epoch #449
 56%|█████▌    | 449/800 [5:12:26<4:00:27, 41.10s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-448.pth
Results:
  total_reward: -50.5, step_mean: -0.032227185705169116
  total_deaths: 835.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 312.44 minutes

Epoch #450
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-449.pth
Results:
  total_reward: -62.5, step_mean: -0.040348612007746934
  total_deaths: 838.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 313.11 minutes

Epoch #451
 56%|█████▋    | 451/800 [5:13:48<3:58:57, 41.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-450.pth
Results:
  total_reward: -58.5, step_mean: -0.03752405388069275
  total_deaths: 840.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 313.81 minutes

Epoch #452
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-451.pth
Results:
  total_reward: -62.5, step_mean: -0.04011553273427471
  total_deaths: 842.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 314.50 minutes

Epoch #453
 57%|█████▋    | 453/800 [5:15:10<3:57:44, 41.11s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-452.pth
Results:
  total_reward: -69.0, step_mean: -0.044287548138639284
  total_deaths: 844.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 315.18 minutes

Epoch #454
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-453.pth
Results:
  total_reward: -77.0, step_mean: -0.04970948999354422
  total_deaths: 847.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 315.85 minutes

Epoch #455
 57%|█████▋    | 455/800 [5:16:30<3:53:32, 40.62s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-454.pth
Results:
  total_reward: -45.5, step_mean: -0.028888888888888888
  total_deaths: 847.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 316.52 minutes

Epoch #456
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-455.pth
Results:
  total_reward: -57.0, step_mean: -0.036774193548387096
  total_deaths: 850.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 317.18 minutes

Epoch #457
 57%|█████▋    | 457/800 [5:17:50<3:50:01, 40.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-456.pth
Results:
  total_reward: -64.5, step_mean: -0.04116145500957243
  total_deaths: 851.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 317.84 minutes

Epoch #458
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-457.pth
Results:
  total_reward: -56.5, step_mean: -0.036056158264199105
  total_deaths: 852.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 318.51 minutes

Epoch #459
 57%|█████▋    | 459/800 [5:19:09<3:46:15, 39.81s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-458.pth
Results:
  total_reward: -49.5, step_mean: -0.031609195402298854
  total_deaths: 853.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 319.16 minutes

Epoch #460
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-459.pth
Results:
  total_reward: -81.5, step_mean: -0.052580645161290324
  total_deaths: 856.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 319.81 minutes

Epoch #461
 58%|█████▊    | 461/800 [5:20:27<3:41:52, 39.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-460.pth
Results:
  total_reward: -74.5, step_mean: -0.04831387808041505
  total_deaths: 860.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 320.45 minutes

Epoch #462
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-461.pth
Results:
  total_reward: -63.5, step_mean: -0.040549169859514685
  total_deaths: 861.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 321.10 minutes

Epoch #463
 58%|█████▊    | 463/800 [5:21:45<3:40:10, 39.20s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-462.pth
Results:
  total_reward: -62.5, step_mean: -0.0398851308232291
  total_deaths: 862.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 321.76 minutes

Epoch #464
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-463.pth
Results:
  total_reward: -80.5, step_mean: -0.05196901226597805
  total_deaths: 865.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 322.40 minutes

Epoch #465
 58%|█████▊    | 465/800 [5:23:03<3:37:59, 39.04s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-464.pth
Results:
  total_reward: -79.0, step_mean: -0.051000645577792124
  total_deaths: 868.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 323.05 minutes

Epoch #466
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-465.pth
Results:
  total_reward: -61.0, step_mean: -0.03915275994865212
  total_deaths: 870.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 323.72 minutes

Epoch #467
 58%|█████▊    | 467/800 [5:24:23<3:39:21, 39.52s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-466.pth
Results:
  total_reward: -78.5, step_mean: -0.05051480051480051
  total_deaths: 873.0
  frag: 0.0
  death: 3.0
  global_step: 1554
Total elapsed time: 324.39 minutes

Epoch #468
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-467.pth
Results:
  total_reward: -64.5, step_mean: -0.04116145500957243
  total_deaths: 874.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 325.04 minutes

Epoch #469
 59%|█████▊    | 469/800 [5:25:42<3:38:30, 39.61s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-468.pth
Results:
  total_reward: -50.0, step_mean: -0.031928480204342274
  total_deaths: 875.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 325.71 minutes

Epoch #470
 59%|█████▉    | 470/800 [5:26:22<3:38:16, 39.69s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-469.pth
Results:
  total_reward: -67.5, step_mean: -0.043548387096774194
  total_deaths: 878.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 326.37 minutes

Epoch #471
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-470.pth
Results:
  total_reward: -55.0, step_mean: -0.03530166880616174
  total_deaths: 880.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 327.04 minutes

Epoch #472
 59%|█████▉    | 472/800 [5:27:42<3:38:01, 39.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-471.pth
Results:
  total_reward: -59.0, step_mean: -0.03765156349712827
  total_deaths: 881.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 327.71 minutes

Epoch #473
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-472.pth
Results:
  total_reward: -44.5, step_mean: -0.02839821314613912
  total_deaths: 882.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 328.38 minutes

Epoch #474
 59%|█████▉    | 474/800 [5:29:04<3:40:58, 40.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-473.pth
Results:
  total_reward: -50.5, step_mean: -0.032247765006385695
  total_deaths: 883.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 329.08 minutes

Epoch #475
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-474.pth
Results:
  total_reward: -60.0, step_mean: -0.03873466752743705
  total_deaths: 886.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 329.81 minutes

Epoch #476
 60%|█████▉    | 476/800 [5:30:30<3:45:41, 41.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-475.pth
Results:
  total_reward: -53.0, step_mean: -0.03382259093809828
  total_deaths: 887.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 330.51 minutes

Epoch #477
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-476.pth
Results:
  total_reward: -57.5, step_mean: -0.03692999357739242
  total_deaths: 889.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 331.22 minutes

Epoch #478
 60%|█████▉    | 478/800 [5:31:57<3:48:14, 42.53s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-477.pth
Results:
  total_reward: -63.5, step_mean: -0.040549169859514685
  total_deaths: 890.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 331.95 minutes

Epoch #479
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-478.pth
Results:
  total_reward: -94.5, step_mean: -0.06136363636363636
  total_deaths: 894.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 332.66 minutes

Epoch #480
 60%|██████    | 480/800 [5:33:21<3:45:25, 42.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-479.pth
Results:
  total_reward: -84.0, step_mean: -0.05422853453841188
  total_deaths: 897.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 333.35 minutes

Epoch #481
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-480.pth
Results:
  total_reward: -78.0, step_mean: -0.05035506778566817
  total_deaths: 900.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 334.05 minutes

Epoch #482
 60%|██████    | 482/800 [5:34:45<3:43:50, 42.23s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-481.pth
Results:
  total_reward: -39.0, step_mean: -0.024761904761904763
  total_deaths: 900.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 334.76 minutes

Epoch #483
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-482.pth
Results:
  total_reward: -64.5, step_mean: -0.041399229781771504
  total_deaths: 902.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 335.46 minutes

Epoch #484
 60%|██████    | 484/800 [5:36:09<3:41:52, 42.13s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-483.pth
Results:
  total_reward: -60.5, step_mean: -0.03883183568677792
  total_deaths: 904.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 336.16 minutes

Epoch #485
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-484.pth
Results:
  total_reward: -66.0, step_mean: -0.04236200256739409
  total_deaths: 906.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 336.89 minutes

Epoch #486
 61%|██████    | 486/800 [5:37:37<3:44:53, 42.97s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-485.pth
Results:
  total_reward: -53.0, step_mean: -0.03365079365079365
  total_deaths: 906.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 337.62 minutes

Epoch #487
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-486.pth
Results:
  total_reward: -71.5, step_mean: -0.04589216944801027
  total_deaths: 908.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 338.33 minutes

Epoch #488
 61%|██████    | 488/800 [5:39:02<3:42:11, 42.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-487.pth
Results:
  total_reward: -46.0, step_mean: -0.029206349206349208
  total_deaths: 908.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 339.04 minutes

Epoch #489
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-488.pth
Results:
  total_reward: -53.5, step_mean: -0.03431686978832585
  total_deaths: 910.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 339.72 minutes

Epoch #490
 61%|██████▏   | 490/800 [5:40:25<3:37:35, 42.11s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-489.pth
Results:
  total_reward: -55.0, step_mean: -0.03530166880616174
  total_deaths: 912.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 340.42 minutes

Epoch #491
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-490.pth
Results:
  total_reward: -54.5, step_mean: -0.03498074454428755
  total_deaths: 914.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 341.11 minutes

Epoch #492
 62%|██████▏   | 492/800 [5:41:48<3:35:43, 42.03s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-491.pth
Results:
  total_reward: -46.0, step_mean: -0.029355456285896617
  total_deaths: 915.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 341.82 minutes

Epoch #493
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-492.pth
Results:
  total_reward: -66.0, step_mean: -0.04236200256739409
  total_deaths: 917.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 342.51 minutes

Epoch #494
 62%|██████▏   | 494/800 [5:43:12<3:34:05, 41.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-493.pth
Results:
  total_reward: -56.5, step_mean: -0.036056158264199105
  total_deaths: 918.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 343.21 minutes

Epoch #495
 62%|██████▏   | 495/800 [5:43:54<3:32:56, 41.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-494.pth
Results:
  total_reward: -52.5, step_mean: -0.03350350989151244
  total_deaths: 919.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 343.91 minutes

Epoch #496
 62%|██████▏   | 496/800 [5:44:36<3:31:55, 41.83s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-495.pth
Results:
  total_reward: -73.0, step_mean: -0.04685494223363286
  total_deaths: 921.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 344.60 minutes

Epoch #497
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-496.pth
Results:
  total_reward: -43.5, step_mean: -0.02761904761904762
  total_deaths: 921.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 345.31 minutes

Epoch #498
 62%|██████▏   | 498/800 [5:46:00<3:31:16, 41.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-497.pth
Results:
  total_reward: -46.5, step_mean: -0.029674537332482452
  total_deaths: 922.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 346.01 minutes

Epoch #499
 62%|██████▏   | 499/800 [5:46:44<3:33:28, 42.55s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-498.pth
Results:
  total_reward: -67.0, step_mean: -0.042756860242501596
  total_deaths: 923.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 346.74 minutes

Epoch #500
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-499.pth
Results:
  total_reward: -75.5, step_mean: -0.048772609819121446
  total_deaths: 926.0
  frag: 0.0
  death: 3.0
  global_step: 1548
Total elapsed time: 347.44 minutes

Epoch #501
 63%|██████▎   | 501/800 [5:48:08<3:31:01, 42.35s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-500.pth
Results:
  total_reward: -69.5, step_mean: -0.044838709677419354
  total_deaths: 929.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 348.14 minutes

Epoch #502
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-501.pth
Results:
  total_reward: -67.0, step_mean: -0.04300385109114249
  total_deaths: 931.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 348.86 minutes

Epoch #503
 63%|██████▎   | 503/800 [5:49:36<3:33:52, 43.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-502.pth
Results:
  total_reward: -77.0, step_mean: -0.04967741935483871
  total_deaths: 934.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 349.61 minutes

Epoch #504
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-503.pth
Results:
  total_reward: -46.5, step_mean: -0.029523809523809525
  total_deaths: 934.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 350.36 minutes

Epoch #505
 63%|██████▎   | 505/800 [5:51:06<3:36:32, 44.04s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-504.pth
Results:
  total_reward: -57.0, step_mean: -0.036797934151065206
  total_deaths: 937.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 351.10 minutes

Epoch #506
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-505.pth
Results:
  total_reward: -65.5, step_mean: -0.04225806451612903
  total_deaths: 940.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 351.83 minutes

Epoch #507
 63%|██████▎   | 507/800 [5:52:34<3:36:01, 44.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-506.pth
Results:
  total_reward: -64.0, step_mean: -0.04105195638229634
  total_deaths: 942.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 352.58 minutes

Epoch #508
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-507.pth
Results:
  total_reward: -51.0, step_mean: -0.03254626675175495
  total_deaths: 943.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 353.33 minutes

Epoch #509
 64%|██████▎   | 509/800 [5:54:03<3:34:46, 44.28s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-508.pth
Results:
  total_reward: -57.5, step_mean: -0.036717752234993614
  total_deaths: 944.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 354.06 minutes

Epoch #510
 64%|██████▍   | 510/800 [5:54:45<3:31:19, 43.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-509.pth
Results:
  total_reward: -89.5, step_mean: -0.05777921239509361
  total_deaths: 947.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 354.77 minutes

Epoch #511
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-510.pth
Results:
  total_reward: -45.0, step_mean: -0.028735632183908046
  total_deaths: 948.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 355.49 minutes

Epoch #512
 64%|██████▍   | 512/800 [5:56:12<3:28:38, 43.47s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-511.pth
Results:
  total_reward: -78.0, step_mean: -0.050616482803374434
  total_deaths: 952.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 356.21 minutes

Epoch #513
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-512.pth
Results:
  total_reward: -62.0, step_mean: -0.039769082745349585
  total_deaths: 954.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 356.93 minutes

Epoch #514
 64%|██████▍   | 514/800 [5:57:39<3:27:02, 43.44s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-513.pth
Results:
  total_reward: -87.0, step_mean: -0.056129032258064517
  total_deaths: 957.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 357.65 minutes

Epoch #515
 64%|██████▍   | 515/800 [5:58:20<3:23:43, 42.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-514.pth
Results:
  total_reward: -54.0, step_mean: -0.03465982028241335
  total_deaths: 959.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 358.35 minutes

Epoch #516
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-515.pth
Results:
  total_reward: -78.0, step_mean: -0.05035506778566817
  total_deaths: 962.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 359.04 minutes

Epoch #517
 65%|██████▍   | 517/800 [5:59:44<3:19:02, 42.20s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-516.pth
Results:
  total_reward: -65.5, step_mean: -0.04201411161000641
  total_deaths: 964.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 359.73 minutes

Epoch #518
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-517.pth
Results:
  total_reward: -76.5, step_mean: -0.04938670109748225
  total_deaths: 967.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 360.43 minutes

Epoch #519
 65%|██████▍   | 519/800 [6:01:07<3:16:50, 42.03s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-518.pth
Results:
  total_reward: -87.5, step_mean: -0.056451612903225805
  total_deaths: 970.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 361.13 minutes

Epoch #520
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-519.pth
Results:
  total_reward: -50.5, step_mean: -0.032247765006385695
  total_deaths: 971.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 361.84 minutes

Epoch #521
 65%|██████▌   | 521/800 [6:02:32<3:16:36, 42.28s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-520.pth
Results:
  total_reward: -54.0, step_mean: -0.03465982028241335
  total_deaths: 973.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 362.55 minutes

Epoch #522
 65%|██████▌   | 522/800 [6:03:14<3:14:47, 42.04s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-521.pth
Results:
  total_reward: -91.0, step_mean: -0.05870967741935484
  total_deaths: 976.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 363.24 minutes

Epoch #523
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-522.pth
Results:
  total_reward: -59.5, step_mean: -0.038141025641025644
  total_deaths: 978.0
  frag: 0.0
  death: 2.0
  global_step: 1560
Total elapsed time: 363.92 minutes

Epoch #524
 66%|██████▌   | 524/800 [6:04:35<3:10:08, 41.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-523.pth
Results:
  total_reward: -73.5, step_mean: -0.04717586649550706
  total_deaths: 980.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 364.59 minutes

Epoch #525
 66%|██████▌   | 525/800 [6:05:16<3:08:23, 41.10s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-524.pth
Results:
  total_reward: -61.0, step_mean: -0.0389278876834716
  total_deaths: 981.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 365.27 minutes

Epoch #526
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-525.pth
Results:
  total_reward: -77.0, step_mean: -0.0499675535366645
  total_deaths: 985.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 365.94 minutes

Epoch #527
 66%|██████▌   | 527/800 [6:06:36<3:05:31, 40.77s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-526.pth
Results:
  total_reward: -66.5, step_mean: -0.042682926829268296
  total_deaths: 987.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 366.62 minutes

Epoch #528
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-527.pth
Results:
  total_reward: -55.0, step_mean: -0.03509891512444161
  total_deaths: 988.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 367.29 minutes

Epoch #529
 66%|██████▌   | 529/800 [6:07:58<3:04:02, 40.75s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-528.pth
Results:
  total_reward: -53.0, step_mean: -0.03382259093809828
  total_deaths: 989.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 367.97 minutes

Epoch #530
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-529.pth
Results:
  total_reward: -46.0, step_mean: -0.029355456285896617
  total_deaths: 990.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 368.65 minutes

Epoch #531
 66%|██████▋   | 531/800 [6:09:19<3:01:54, 40.58s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-530.pth
Results:
  total_reward: -61.5, step_mean: -0.039473684210526314
  total_deaths: 992.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 369.32 minutes

Epoch #532
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-531.pth
Results:
  total_reward: -62.0, step_mean: -0.03982016698779704
  total_deaths: 994.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 369.98 minutes

Epoch #533
 67%|██████▋   | 533/800 [6:10:39<2:59:56, 40.43s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-532.pth
Results:
  total_reward: -59.5, step_mean: -0.037970644543714106
  total_deaths: 995.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 370.66 minutes

Epoch #534
 67%|██████▋   | 534/800 [6:11:20<2:59:44, 40.54s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-533.pth
Results:
  total_reward: -52.5, step_mean: -0.03333333333333333
  total_deaths: 995.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 371.34 minutes

Epoch #535
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-534.pth
Results:
  total_reward: -73.0, step_mean: -0.04709677419354839
  total_deaths: 998.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 372.02 minutes

Epoch #536
 67%|██████▋   | 536/800 [6:12:41<2:58:30, 40.57s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-535.pth
Results:
  total_reward: -58.5, step_mean: -0.03735632183908046
  total_deaths: 999.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 372.69 minutes

Epoch #537
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-536.pth
Results:
  total_reward: -66.5, step_mean: -0.04271034039820167
  total_deaths: 1001.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 373.37 minutes

Epoch #538
 67%|██████▋   | 538/800 [6:14:02<2:56:56, 40.52s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-537.pth
Results:
  total_reward: -56.5, step_mean: -0.036056158264199105
  total_deaths: 1002.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 374.04 minutes

Epoch #539
 67%|██████▋   | 539/800 [6:14:42<2:55:43, 40.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-538.pth
Results:
  total_reward: -84.5, step_mean: -0.05483452303698897
  total_deaths: 1006.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 374.71 minutes

Epoch #540
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-539.pth
 68%|██████▊   | 540/800 [6:15:23<2:55:09, 40.42s/it]Results:
  total_reward: -67.0, step_mean: -0.04300385109114249
  total_deaths: 1008.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 375.39 minutes

Epoch #541
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-540.pth
Results:
  total_reward: -50.0, step_mean: -0.03190810465858328
  total_deaths: 1009.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 376.07 minutes

Epoch #542
 68%|██████▊   | 542/800 [6:16:45<2:55:06, 40.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-541.pth
Results:
  total_reward: -79.5, step_mean: -0.05129032258064516
  total_deaths: 1012.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 376.75 minutes

Epoch #543
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-542.pth
Results:
  total_reward: -60.0, step_mean: -0.038510911424903725
  total_deaths: 1014.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 377.44 minutes

Epoch #544
 68%|██████▊   | 544/800 [6:18:06<2:53:20, 40.63s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-543.pth
Results:
  total_reward: -69.5, step_mean: -0.04460847240051348
  total_deaths: 1016.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 378.11 minutes

Epoch #545
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-544.pth
Results:
  total_reward: -45.5, step_mean: -0.029036375239310786
  total_deaths: 1017.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 378.76 minutes

Epoch #546
 68%|██████▊   | 546/800 [6:19:25<2:49:14, 39.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-545.pth
Results:
  total_reward: -52.0, step_mean: -0.033205619412515965
  total_deaths: 1018.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 379.42 minutes

Epoch #547
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-546.pth
Results:
  total_reward: -68.5, step_mean: -0.04396662387676508
  total_deaths: 1020.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 380.07 minutes

Epoch #548
 68%|██████▊   | 548/800 [6:20:43<2:45:38, 39.44s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-547.pth
Results:
  total_reward: -51.5, step_mean: -0.03305519897304236
  total_deaths: 1022.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 380.72 minutes

Epoch #549
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-548.pth
Results:
  total_reward: -62.0, step_mean: -0.03982016698779704
  total_deaths: 1024.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 381.37 minutes

Epoch #550
 69%|██████▉   | 550/800 [6:22:01<2:43:45, 39.30s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-549.pth
Results:
  total_reward: -52.5, step_mean: -0.033524904214559385
  total_deaths: 1025.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 382.02 minutes

Epoch #551
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-550.pth
Results:
  total_reward: -55.0, step_mean: -0.0351213282247765
  total_deaths: 1026.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 382.67 minutes

Epoch #552
 69%|██████▉   | 552/800 [6:23:19<2:41:39, 39.11s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-551.pth
Results:
  total_reward: -86.0, step_mean: -0.05548387096774193
  total_deaths: 1029.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 383.32 minutes

Epoch #553
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-552.pth
Results:
  total_reward: -53.0, step_mean: -0.03401797175866496
  total_deaths: 1031.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 383.97 minutes

Epoch #554
 69%|██████▉   | 554/800 [6:24:36<2:39:11, 38.83s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-553.pth
Results:
  total_reward: -87.0, step_mean: -0.05675146771037182
  total_deaths: 1036.0
  frag: 0.0
  death: 5.0
  global_step: 1533
Total elapsed time: 384.61 minutes

Epoch #555
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-554.pth
Results:
  total_reward: -56.0, step_mean: -0.03594351732991014
  total_deaths: 1038.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 385.26 minutes

Epoch #556
 70%|██████▉   | 556/800 [6:25:54<2:38:05, 38.87s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-555.pth
Results:
  total_reward: -68.0, step_mean: -0.04387096774193548
  total_deaths: 1041.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 385.91 minutes

Epoch #557
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-556.pth
Results:
  total_reward: -67.0, step_mean: -0.04303147077713552
  total_deaths: 1043.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 386.55 minutes

Epoch #558
 70%|██████▉   | 558/800 [6:27:12<2:36:59, 38.92s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-557.pth
Results:
  total_reward: -68.0, step_mean: -0.04367373153500321
  total_deaths: 1045.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 387.20 minutes

Epoch #559
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-558.pth
Results:
  total_reward: -62.5, step_mean: -0.04032258064516129
  total_deaths: 1048.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 387.85 minutes

Epoch #560
 70%|███████   | 560/800 [6:28:30<2:35:53, 38.97s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-559.pth
Results:
  total_reward: -77.5, step_mean: -0.04974326059050064
  total_deaths: 1050.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 388.50 minutes

Epoch #561
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-560.pth
Results:
  total_reward: -79.0, step_mean: -0.051000645577792124
  total_deaths: 1053.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 389.15 minutes

Epoch #562
 70%|███████   | 562/800 [6:29:47<2:34:06, 38.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-561.pth
Results:
  total_reward: -78.5, step_mean: -0.05067785668173015
  total_deaths: 1056.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 389.80 minutes

Epoch #563
 70%|███████   | 563/800 [6:30:27<2:34:04, 39.00s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-562.pth
Results:
  total_reward: -72.0, step_mean: -0.04621309370988447
  total_deaths: 1058.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 390.45 minutes

Epoch #564
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-563.pth
Results:
  total_reward: -47.5, step_mean: -0.03033205619412516
  total_deaths: 1059.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 391.10 minutes

Epoch #565
 71%|███████   | 565/800 [6:31:45<2:33:04, 39.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-564.pth
Results:
  total_reward: -56.5, step_mean: -0.036056158264199105
  total_deaths: 1060.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 391.76 minutes

Epoch #566
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-565.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 1062.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 392.40 minutes

Epoch #567
 71%|███████   | 567/800 [6:33:03<2:31:30, 39.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-566.pth
Results:
  total_reward: -86.5, step_mean: -0.055842479018721754
  total_deaths: 1065.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 393.05 minutes

Epoch #568
 71%|███████   | 568/800 [6:33:42<2:31:11, 39.10s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-567.pth
Results:
  total_reward: -82.5, step_mean: -0.05326016785022595
  total_deaths: 1068.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 393.71 minutes

Epoch #569
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-568.pth
Results:
  total_reward: -57.5, step_mean: -0.036717752234993614
  total_deaths: 1069.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 394.38 minutes

Epoch #570
 71%|███████▏  | 570/800 [6:35:02<2:31:44, 39.58s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-569.pth
Results:
  total_reward: -78.5, step_mean: -0.05038510911424904
  total_deaths: 1071.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 395.04 minutes

Epoch #571
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-570.pth
Results:
  total_reward: -80.5, step_mean: -0.05193548387096774
  total_deaths: 1074.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 395.71 minutes

Epoch #572
 72%|███████▏  | 572/800 [6:36:22<2:30:53, 39.71s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-571.pth
Results:
  total_reward: -56.5, step_mean: -0.03626444159178434
  total_deaths: 1076.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 396.37 minutes

Epoch #573
 72%|███████▏  | 573/800 [6:37:01<2:29:11, 39.43s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-572.pth
Results:
  total_reward: -67.0, step_mean: -0.04303147077713552
  total_deaths: 1078.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 397.02 minutes

Epoch #574
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-573.pth
Results:
  total_reward: -89.0, step_mean: -0.057456423499031635
  total_deaths: 1081.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 397.68 minutes

Epoch #575
 72%|███████▏  | 575/800 [6:38:20<2:28:46, 39.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-574.pth
Results:
  total_reward: -63.5, step_mean: -0.040757381258023105
  total_deaths: 1083.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 398.35 minutes

Epoch #576
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-575.pth
Results:
  total_reward: -57.5, step_mean: -0.03690629011553274
  total_deaths: 1085.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 399.01 minutes

Epoch #577
 72%|███████▏  | 577/800 [6:39:40<2:27:27, 39.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-576.pth
Results:
  total_reward: -84.5, step_mean: -0.05455132343447385
  total_deaths: 1088.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 399.67 minutes

Epoch #578
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-577.pth
Results:
  total_reward: -52.5, step_mean: -0.033697047496790755
  total_deaths: 1090.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 400.34 minutes

Epoch #579
 72%|███████▏  | 579/800 [6:40:59<2:26:20, 39.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-578.pth
Results:
  total_reward: -62.5, step_mean: -0.040141297366730895
  total_deaths: 1092.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 401.00 minutes

Epoch #580
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-579.pth
Results:
  total_reward: -72.0, step_mean: -0.046481601032924466
  total_deaths: 1095.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 401.66 minutes

Epoch #581
 73%|███████▎  | 581/800 [6:42:19<2:25:33, 39.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-580.pth
Results:
  total_reward: -64.5, step_mean: -0.04116145500957243
  total_deaths: 1096.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 402.33 minutes

Epoch #582
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-581.pth
Results:
  total_reward: -48.5, step_mean: -0.030970625798212005
  total_deaths: 1097.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 402.98 minutes

Epoch #583
 73%|███████▎  | 583/800 [6:43:38<2:23:50, 39.77s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-582.pth
Results:
  total_reward: -47.5, step_mean: -0.03015873015873016
  total_deaths: 1097.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 403.65 minutes

Epoch #584
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-583.pth
Results:
  total_reward: -68.5, step_mean: -0.04396662387676508
  total_deaths: 1099.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 404.31 minutes

Epoch #585
 73%|███████▎  | 585/800 [6:44:58<2:22:46, 39.84s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-584.pth
Results:
  total_reward: -68.5, step_mean: -0.04399486191393706
  total_deaths: 1101.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 404.98 minutes

Epoch #586
 73%|███████▎  | 586/800 [6:45:38<2:21:54, 39.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-585.pth
Results:
  total_reward: -84.0, step_mean: -0.05422853453841188
  total_deaths: 1104.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 405.64 minutes

Epoch #587
 73%|███████▎  | 587/800 [6:46:22<2:26:12, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-586.pth
Results:
  total_reward: -51.5, step_mean: -0.03305519897304236
  total_deaths: 1106.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 406.38 minutes

Epoch #588
 74%|███████▎  | 588/800 [6:47:04<2:26:03, 41.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-587.pth
Results:
  total_reward: -47.5, step_mean: -0.030312699425654115
  total_deaths: 1107.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 407.08 minutes

Epoch #589
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-588.pth
Results:
  total_reward: -65.5, step_mean: -0.0420410783055199
  total_deaths: 1109.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 407.79 minutes

Epoch #590
 74%|███████▍  | 590/800 [6:48:29<2:27:10, 42.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-589.pth
Results:
  total_reward: -69.0, step_mean: -0.044287548138639284
  total_deaths: 1111.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 408.50 minutes

Epoch #591
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-590.pth
Results:
  total_reward: -81.0, step_mean: -0.05256327060350422
  total_deaths: 1115.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 409.18 minutes

Epoch #592
 74%|███████▍  | 592/800 [6:49:52<2:24:18, 41.63s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-591.pth
Results:
  total_reward: -63.5, step_mean: -0.040757381258023105
  total_deaths: 1117.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 409.87 minutes

Epoch #593
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-592.pth
Results:
  total_reward: -62.0, step_mean: -0.03956604977664327
  total_deaths: 1118.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 410.56 minutes

Epoch #594
 74%|███████▍  | 594/800 [6:51:16<2:23:57, 41.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-593.pth
Results:
  total_reward: -69.0, step_mean: -0.044287548138639284
  total_deaths: 1120.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 411.28 minutes

Epoch #595
 74%|███████▍  | 595/800 [6:51:59<2:23:56, 42.13s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-594.pth
Results:
  total_reward: -72.0, step_mean: -0.04621309370988447
  total_deaths: 1122.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 411.99 minutes

Epoch #596
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-595.pth
Results:
  total_reward: -70.0, step_mean: -0.04516129032258064
  total_deaths: 1125.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 412.67 minutes

Epoch #597
 75%|███████▍  | 597/800 [6:53:21<2:20:29, 41.53s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-596.pth
Results:
  total_reward: -70.5, step_mean: -0.04525032092426187
  total_deaths: 1127.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 413.35 minutes

Epoch #598
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-597.pth
Results:
  total_reward: -51.5, step_mean: -0.032886334610472544
  total_deaths: 1128.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 414.04 minutes

Epoch #599
 75%|███████▍  | 599/800 [6:54:42<2:17:59, 41.19s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-598.pth
Results:
  total_reward: -87.0, step_mean: -0.0562015503875969
  total_deaths: 1131.0
  frag: 0.0
  death: 3.0
  global_step: 1548
Total elapsed time: 414.71 minutes

Epoch #600
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-599.pth
Results:
  total_reward: -62.5, step_mean: -0.04032258064516129
  total_deaths: 1134.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 415.39 minutes

Epoch #601
 75%|███████▌  | 601/800 [6:56:05<2:16:51, 41.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-600.pth
Results:
  total_reward: -90.5, step_mean: -0.05838709677419355
  total_deaths: 1137.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 416.09 minutes

Epoch #602
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-601.pth
Results:
  total_reward: -61.0, step_mean: -0.03915275994865212
  total_deaths: 1139.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 416.80 minutes

Epoch #603
 75%|███████▌  | 603/800 [6:57:33<2:20:06, 42.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-602.pth
Results:
  total_reward: -65.0, step_mean: -0.0417201540436457
  total_deaths: 1141.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 417.55 minutes

Epoch #604
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-603.pth
Results:
  total_reward: -44.0, step_mean: -0.027936507936507936
  total_deaths: 1141.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 418.26 minutes

Epoch #605
 76%|███████▌  | 605/800 [6:58:56<2:16:37, 42.04s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-604.pth
Results:
  total_reward: -50.0, step_mean: -0.03209242618741977
  total_deaths: 1143.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 418.94 minutes

Epoch #606
 76%|███████▌  | 606/800 [6:59:36<2:14:35, 41.63s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-605.pth
Results:
  total_reward: -68.0, step_mean: -0.043645699614890884
  total_deaths: 1145.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 419.61 minutes

Epoch #607
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-606.pth
Results:
  total_reward: -64.0, step_mean: -0.0410783055198973
  total_deaths: 1147.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 420.29 minutes

Epoch #608
 76%|███████▌  | 608/800 [7:00:57<2:11:17, 41.03s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-607.pth
Results:
  total_reward: -64.5, step_mean: -0.041399229781771504
  total_deaths: 1149.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 420.96 minutes

Epoch #609
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-608.pth
Results:
  total_reward: -65.0, step_mean: -0.04174694926140013
  total_deaths: 1151.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 421.66 minutes

Epoch #610
 76%|███████▋  | 610/800 [7:02:21<2:10:53, 41.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-609.pth
Results:
  total_reward: -66.0, step_mean: -0.04258064516129032
  total_deaths: 1154.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 422.35 minutes

Epoch #611
 76%|███████▋  | 611/800 [7:03:02<2:10:23, 41.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-610.pth
Results:
  total_reward: -69.5, step_mean: -0.044838709677419354
  total_deaths: 1157.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 423.04 minutes

Epoch #612
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-611.pth
Results:
  total_reward: -69.0, step_mean: -0.044287548138639284
  total_deaths: 1159.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 423.74 minutes

Epoch #613
 77%|███████▋  | 613/800 [7:04:25<2:08:56, 41.37s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-612.pth
Results:
  total_reward: -71.0, step_mean: -0.045806451612903226
  total_deaths: 1162.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 424.42 minutes

Epoch #614
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-613.pth
Results:
  total_reward: -54.0, step_mean: -0.03465982028241335
  total_deaths: 1164.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 425.11 minutes

Epoch #615
 77%|███████▋  | 615/800 [7:05:48<2:07:42, 41.42s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-614.pth
Results:
  total_reward: -67.0, step_mean: -0.04300385109114249
  total_deaths: 1166.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 425.81 minutes

Epoch #616
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-615.pth
Results:
  total_reward: -58.5, step_mean: -0.03774193548387097
  total_deaths: 1169.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 426.50 minutes

Epoch #617
 77%|███████▋  | 617/800 [7:07:11<2:06:27, 41.46s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-616.pth
Results:
  total_reward: -43.5, step_mean: -0.027760051052967454
  total_deaths: 1170.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 427.19 minutes

Epoch #618
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-617.pth
 77%|███████▋  | 618/800 [7:07:54<2:07:07, 41.91s/it]Results:
  total_reward: -57.0, step_mean: -0.036375239310784936
  total_deaths: 1171.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 427.91 minutes

Epoch #619
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-618.pth
Results:
  total_reward: -72.5, step_mean: -0.046804389928986445
  total_deaths: 1174.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 428.59 minutes

Epoch #620
 78%|███████▊  | 620/800 [7:09:15<2:03:33, 41.19s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-619.pth
Results:
  total_reward: -63.5, step_mean: -0.040757381258023105
  total_deaths: 1176.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 429.26 minutes

Epoch #621
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-620.pth
Results:
  total_reward: -66.5, step_mean: -0.04293092317624274
  total_deaths: 1179.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 429.93 minutes

Epoch #622
 78%|███████▊  | 622/800 [7:10:35<2:00:49, 40.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-621.pth
Results:
  total_reward: -49.0, step_mean: -0.031269942565411615
  total_deaths: 1180.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 430.60 minutes

Epoch #623
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-622.pth
Results:
  total_reward: -43.0, step_mean: -0.02744097000638162
  total_deaths: 1181.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 431.28 minutes

Epoch #624
 78%|███████▊  | 624/800 [7:11:56<1:58:56, 40.55s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-623.pth
Results:
  total_reward: -65.0, step_mean: -0.0417201540436457
  total_deaths: 1183.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 431.95 minutes

Epoch #625
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-624.pth
Results:
  total_reward: -51.0, step_mean: -0.03273427471116817
  total_deaths: 1185.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 432.61 minutes

Epoch #626
 78%|███████▊  | 626/800 [7:13:16<1:56:36, 40.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-625.pth
Results:
  total_reward: -81.0, step_mean: -0.05202312138728324
  total_deaths: 1187.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 433.28 minutes

Epoch #627
 78%|███████▊  | 627/800 [7:13:57<1:56:40, 40.47s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-626.pth
Results:
  total_reward: -72.0, step_mean: -0.04645161290322581
  total_deaths: 1190.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 433.96 minutes

Epoch #628
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-627.pth
Results:
  total_reward: -54.5, step_mean: -0.03477983407785577
  total_deaths: 1191.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 434.63 minutes

Epoch #629
 79%|███████▊  | 629/800 [7:15:17<1:54:45, 40.26s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-628.pth
Results:
  total_reward: -73.0, step_mean: -0.04685494223363286
  total_deaths: 1193.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 435.30 minutes

Epoch #630
 79%|███████▉  | 630/800 [7:15:58<1:54:00, 40.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-629.pth
Results:
  total_reward: -47.5, step_mean: -0.03048780487804878
  total_deaths: 1195.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 435.97 minutes

Epoch #631
 79%|███████▉  | 631/800 [7:16:38<1:53:22, 40.25s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-630.pth
Results:
  total_reward: -72.0, step_mean: -0.04621309370988447
  total_deaths: 1197.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 436.64 minutes

Epoch #632
 79%|███████▉  | 632/800 [7:17:18<1:52:48, 40.29s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-631.pth
Results:
  total_reward: -68.5, step_mean: -0.04393842206542656
  total_deaths: 1199.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 437.31 minutes

Epoch #633
 79%|███████▉  | 633/800 [7:17:59<1:52:51, 40.55s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-632.pth
Results:
  total_reward: -47.0, step_mean: -0.029841269841269842
  total_deaths: 1199.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 438.00 minutes

Epoch #634
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-633.pth
Results:
  total_reward: -64.0, step_mean: -0.0410783055198973
  total_deaths: 1201.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 438.70 minutes

Epoch #635
 79%|███████▉  | 635/800 [7:19:22<1:52:14, 40.82s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-634.pth
Results:
  total_reward: -78.0, step_mean: -0.05032258064516129
  total_deaths: 1204.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 439.37 minutes

Epoch #636
 80%|███████▉  | 636/800 [7:20:03<1:51:26, 40.77s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-635.pth
Results:
  total_reward: -54.0, step_mean: -0.03465982028241335
  total_deaths: 1206.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 440.05 minutes

Epoch #637
 80%|███████▉  | 637/800 [7:20:42<1:50:06, 40.53s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-636.pth
Results:
  total_reward: -85.0, step_mean: -0.05512321660181582
  total_deaths: 1210.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 440.72 minutes

Epoch #638
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-637.pth
Results:
  total_reward: -59.0, step_mean: -0.03765156349712827
  total_deaths: 1211.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 441.39 minutes

Epoch #639
 80%|███████▉  | 639/800 [7:22:03<1:48:35, 40.47s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-638.pth
Results:
  total_reward: -61.5, step_mean: -0.039473684210526314
  total_deaths: 1213.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 442.06 minutes

Epoch #640
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-639.pth
Results:
  total_reward: -85.0, step_mean: -0.05487411233053583
  total_deaths: 1216.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 442.73 minutes

Epoch #641
 80%|████████  | 641/800 [7:23:25<1:47:39, 40.62s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-640.pth
Results:
  total_reward: -74.5, step_mean: -0.04784842646114323
  total_deaths: 1218.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 443.42 minutes

Epoch #642
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-641.pth
Results:
  total_reward: -54.5, step_mean: -0.03477983407785577
  total_deaths: 1219.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 444.11 minutes

Epoch #643
 80%|████████  | 643/800 [7:24:47<1:46:55, 40.86s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-642.pth
Results:
  total_reward: -40.5, step_mean: -0.02586206896551724
  total_deaths: 1220.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 444.79 minutes

Epoch #644
 80%|████████  | 644/800 [7:25:28<1:46:24, 40.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-643.pth
Results:
  total_reward: -66.5, step_mean: -0.042682926829268296
  total_deaths: 1222.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 445.47 minutes

Epoch #645
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-644.pth
Results:
  total_reward: -65.5, step_mean: -0.04225806451612903
  total_deaths: 1225.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 446.16 minutes

Epoch #646
 81%|████████  | 646/800 [7:26:51<1:45:36, 41.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-645.pth
Results:
  total_reward: -42.5, step_mean: -0.026984126984126985
  total_deaths: 1225.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 446.85 minutes

Epoch #647
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-646.pth
Results:
  total_reward: -51.0, step_mean: -0.03273427471116817
  total_deaths: 1227.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 447.53 minutes

Epoch #648
 81%|████████  | 648/800 [7:28:12<1:43:51, 40.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-647.pth
Results:
  total_reward: -66.0, step_mean: -0.04236200256739409
  total_deaths: 1229.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 448.21 minutes

Epoch #649
 81%|████████  | 649/800 [7:28:53<1:43:08, 40.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-648.pth
Results:
  total_reward: -69.5, step_mean: -0.04460847240051348
  total_deaths: 1231.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 448.90 minutes

Epoch #650
 81%|████████▏ | 650/800 [7:29:34<1:42:20, 40.94s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-649.pth
Results:
  total_reward: -79.5, step_mean: -0.05129032258064516
  total_deaths: 1234.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 449.58 minutes

Epoch #651
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-650.pth
Results:
  total_reward: -54.0, step_mean: -0.03446075303126994
  total_deaths: 1235.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 450.24 minutes

Epoch #652
 82%|████████▏ | 652/800 [7:30:54<1:39:29, 40.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-651.pth
Results:
  total_reward: -62.0, step_mean: -0.03979460847240052
  total_deaths: 1237.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 450.90 minutes

Epoch #653
 82%|████████▏ | 653/800 [7:31:35<1:39:43, 40.70s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-652.pth
Results:
  total_reward: -51.0, step_mean: -0.03273427471116817
  total_deaths: 1239.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 451.60 minutes

Epoch #654
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-653.pth
Results:
  total_reward: -62.0, step_mean: -0.03982016698779704
  total_deaths: 1241.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 452.29 minutes

Epoch #655
 82%|████████▏ | 655/800 [7:32:59<1:39:38, 41.23s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-654.pth
Results:
  total_reward: -61.5, step_mean: -0.0394990366088632
  total_deaths: 1243.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 452.99 minutes

Epoch #656
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-655.pth
Results:
  total_reward: -69.0, step_mean: -0.044287548138639284
  total_deaths: 1245.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 453.67 minutes

Epoch #657
 82%|████████▏ | 657/800 [7:34:20<1:37:42, 41.00s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-656.pth
Results:
  total_reward: -66.0, step_mean: -0.04236200256739409
  total_deaths: 1247.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 454.35 minutes

Epoch #658
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-657.pth
Results:
  total_reward: -43.5, step_mean: -0.027760051052967454
  total_deaths: 1248.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 455.04 minutes

Epoch #659
 82%|████████▏ | 659/800 [7:35:43<1:36:49, 41.20s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-658.pth
Results:
  total_reward: -57.5, step_mean: -0.03690629011553274
  total_deaths: 1250.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 455.73 minutes

Epoch #660
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-659.pth
Results:
  total_reward: -59.5, step_mean: -0.037970644543714106
  total_deaths: 1251.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 456.42 minutes

Epoch #661
 83%|████████▎ | 661/800 [7:37:04<1:34:12, 40.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-660.pth
Results:
  total_reward: -71.5, step_mean: -0.04592164418754014
  total_deaths: 1253.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 457.07 minutes

Epoch #662
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-661.pth
Results:
  total_reward: -76.5, step_mean: -0.04941860465116279
  total_deaths: 1256.0
  frag: 0.0
  death: 3.0
  global_step: 1548
Total elapsed time: 457.72 minutes

Epoch #663
 83%|████████▎ | 663/800 [7:38:24<1:32:15, 40.41s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-662.pth
Results:
  total_reward: -80.0, step_mean: -0.051646223369916075
  total_deaths: 1259.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 458.41 minutes

Epoch #664
 83%|████████▎ | 664/800 [7:39:04<1:31:12, 40.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-663.pth
Results:
  total_reward: -60.5, step_mean: -0.03880692751763951
  total_deaths: 1261.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 459.07 minutes

Epoch #665
 83%|████████▎ | 665/800 [7:39:44<1:30:18, 40.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-664.pth
Results:
  total_reward: -59.5, step_mean: -0.03818998716302952
  total_deaths: 1263.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 459.74 minutes

Epoch #666
 83%|████████▎ | 666/800 [7:40:24<1:29:39, 40.15s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-665.pth
Results:
  total_reward: -58.5, step_mean: -0.03735632183908046
  total_deaths: 1264.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 460.40 minutes

Epoch #667
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-666.pth
Results:
  total_reward: -86.5, step_mean: -0.05580645161290323
  total_deaths: 1267.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 461.06 minutes

Epoch #668
 84%|████████▎ | 668/800 [7:41:43<1:27:41, 39.86s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-667.pth
Results:
  total_reward: -54.0, step_mean: -0.034482758620689655
  total_deaths: 1268.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 461.72 minutes

Epoch #669
 84%|████████▎ | 669/800 [7:42:22<1:26:44, 39.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-668.pth
Results:
  total_reward: -60.5, step_mean: -0.03883183568677792
  total_deaths: 1270.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 462.38 minutes

Epoch #670
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-669.pth
Results:
  total_reward: -69.0, step_mean: -0.04431599229287091
  total_deaths: 1272.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 463.04 minutes

Epoch #671
 84%|████████▍ | 671/800 [7:43:42<1:25:48, 39.91s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-670.pth
Results:
  total_reward: -72.0, step_mean: -0.046481601032924466
  total_deaths: 1275.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 463.71 minutes

Epoch #672
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-671.pth
Results:
  total_reward: -57.5, step_mean: -0.03688261706221937
  total_deaths: 1277.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 464.38 minutes

Epoch #673
 84%|████████▍ | 673/800 [7:45:03<1:24:43, 40.03s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-672.pth
Results:
  total_reward: -76.0, step_mean: -0.04884318766066838
  total_deaths: 1280.0
  frag: 0.0
  death: 3.0
  global_step: 1556
Total elapsed time: 465.05 minutes

Epoch #674
 84%|████████▍ | 674/800 [7:45:43<1:24:18, 40.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-673.pth
Results:
  total_reward: -68.5, step_mean: -0.04396662387676508
  total_deaths: 1282.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 465.73 minutes

Epoch #675
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-674.pth
Results:
  total_reward: -40.5, step_mean: -0.025845564773452456
  total_deaths: 1283.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 466.41 minutes

Epoch #676
 84%|████████▍ | 676/800 [7:47:04<1:23:30, 40.41s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-675.pth
Results:
  total_reward: -67.0, step_mean: -0.04300385109114249
  total_deaths: 1285.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 467.08 minutes

Epoch #677
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-676.pth
Results:
  total_reward: -64.0, step_mean: -0.0408423739629866
  total_deaths: 1286.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 467.77 minutes

Epoch #678
 85%|████████▍ | 678/800 [7:48:26<1:22:19, 40.49s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-677.pth
Results:
  total_reward: -92.5, step_mean: -0.060378590078328985
  total_deaths: 1291.0
  frag: 0.0
  death: 5.0
  global_step: 1532
Total elapsed time: 468.44 minutes

Epoch #679
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-678.pth
Results:
  total_reward: -58.5, step_mean: -0.03754813863928113
  total_deaths: 1293.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 469.11 minutes

Epoch #680
 85%|████████▌ | 680/800 [7:49:46<1:20:37, 40.32s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-679.pth
Results:
  total_reward: -80.5, step_mean: -0.05193548387096774
  total_deaths: 1296.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 469.78 minutes

Epoch #681
 85%|████████▌ | 681/800 [7:50:26<1:19:29, 40.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-680.pth
Results:
  total_reward: -67.0, step_mean: -0.04325371207230471
  total_deaths: 1299.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 470.44 minutes

Epoch #682
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-681.pth
Results:
  total_reward: -58.0, step_mean: -0.03741935483870968
  total_deaths: 1302.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 471.09 minutes

Epoch #683
 85%|████████▌ | 683/800 [7:51:43<1:16:52, 39.43s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-682.pth
Results:
  total_reward: -96.5, step_mean: -0.06298955613577023
  total_deaths: 1307.0
  frag: 0.0
  death: 5.0
  global_step: 1532
Total elapsed time: 471.73 minutes

Epoch #684
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-683.pth
Results:
  total_reward: -53.0, step_mean: -0.03384418901660281
  total_deaths: 1308.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 472.40 minutes

Epoch #685
 86%|████████▌ | 685/800 [7:53:03<1:15:51, 39.58s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-684.pth
Results:
  total_reward: -59.0, step_mean: -0.037869062901155326
  total_deaths: 1310.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 473.06 minutes

Epoch #686
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-685.pth
Results:
  total_reward: -52.0, step_mean: -0.03318442884492661
  total_deaths: 1311.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 473.72 minutes

Epoch #687
 86%|████████▌ | 687/800 [7:54:22<1:14:43, 39.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-686.pth
Results:
  total_reward: -60.0, step_mean: -0.03870967741935484
  total_deaths: 1314.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 474.38 minutes

Epoch #688
 86%|████████▌ | 688/800 [7:55:02<1:14:10, 39.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-687.pth
Results:
  total_reward: -72.5, step_mean: -0.0467741935483871
  total_deaths: 1317.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 475.05 minutes

Epoch #689
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-688.pth
Results:
  total_reward: -51.0, step_mean: -0.032567049808429116
  total_deaths: 1318.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 475.75 minutes

Epoch #690
 86%|████████▋ | 690/800 [7:56:25<1:14:12, 40.47s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-689.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 1320.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 476.42 minutes

Epoch #691
 86%|████████▋ | 691/800 [7:57:05<1:13:16, 40.33s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-690.pth
Results:
  total_reward: -63.0, step_mean: -0.04046242774566474
  total_deaths: 1322.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 477.09 minutes

Epoch #692
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-691.pth
Results:
  total_reward: -56.5, step_mean: -0.036056158264199105
  total_deaths: 1323.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 477.78 minutes

Epoch #693
 87%|████████▋ | 693/800 [7:58:26<1:12:08, 40.45s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-692.pth
Results:
  total_reward: -58.0, step_mean: -0.037227214377406934
  total_deaths: 1325.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 478.45 minutes

Epoch #694
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-693.pth
Results:
  total_reward: -50.0, step_mean: -0.03190810465858328
  total_deaths: 1326.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 479.12 minutes

Epoch #695
 87%|████████▋ | 695/800 [7:59:47<1:10:46, 40.44s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-694.pth
Results:
  total_reward: -46.0, step_mean: -0.02937420178799489
  total_deaths: 1327.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 479.79 minutes

Epoch #696
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-695.pth
Results:
  total_reward: -66.0, step_mean: -0.04236200256739409
  total_deaths: 1329.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 480.45 minutes

Epoch #697
 87%|████████▋ | 697/800 [8:01:06<1:08:39, 39.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-696.pth
Results:
  total_reward: -74.0, step_mean: -0.04749679075738126
  total_deaths: 1331.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 481.11 minutes

Epoch #698
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-697.pth
Results:
  total_reward: -52.0, step_mean: -0.033205619412515965
  total_deaths: 1332.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 481.78 minutes

Epoch #699
 87%|████████▋ | 699/800 [8:02:26<1:07:19, 39.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-698.pth
Results:
  total_reward: -61.0, step_mean: -0.0389278876834716
  total_deaths: 1333.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 482.44 minutes

Epoch #700
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-699.pth
Results:
  total_reward: -64.0, step_mean: -0.04110468850353243
  total_deaths: 1335.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 483.10 minutes

Epoch #701
 88%|████████▊ | 701/800 [8:03:46<1:05:48, 39.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-700.pth
Results:
  total_reward: -52.5, step_mean: -0.033524904214559385
  total_deaths: 1336.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 483.77 minutes

Epoch #702
 88%|████████▊ | 702/800 [8:04:26<1:05:24, 40.04s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-701.pth
Results:
  total_reward: -56.5, step_mean: -0.03626444159178434
  total_deaths: 1338.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 484.44 minutes

Epoch #703
 88%|████████▊ | 703/800 [8:05:06<1:04:41, 40.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-702.pth
Results:
  total_reward: -66.0, step_mean: -0.04236200256739409
  total_deaths: 1340.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 485.11 minutes

Epoch #704
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-703.pth
Results:
  total_reward: -62.5, step_mean: -0.040141297366730895
  total_deaths: 1342.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 485.77 minutes

Epoch #705
 88%|████████▊ | 705/800 [8:06:27<1:03:41, 40.23s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-704.pth
Results:
  total_reward: -59.5, step_mean: -0.03818998716302952
  total_deaths: 1344.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 486.45 minutes

Epoch #706
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-705.pth
Results:
  total_reward: -78.5, step_mean: -0.05064516129032258
  total_deaths: 1347.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 487.13 minutes

Epoch #707
 88%|████████▊ | 707/800 [8:07:49<1:03:08, 40.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-706.pth
Results:
  total_reward: -58.0, step_mean: -0.037251123956326265
  total_deaths: 1349.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 487.83 minutes

Epoch #708
 88%|████████▊ | 708/800 [8:08:31<1:02:48, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-707.pth
Results:
  total_reward: -56.5, step_mean: -0.036056158264199105
  total_deaths: 1350.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 488.52 minutes

Epoch #709
 89%|████████▊ | 709/800 [8:09:11<1:01:57, 40.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-708.pth
Results:
  total_reward: -62.0, step_mean: -0.03979460847240052
  total_deaths: 1352.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 489.19 minutes

Epoch #710
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-709.pth
Results:
  total_reward: -43.0, step_mean: -0.027301587301587302
  total_deaths: 1352.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 489.88 minutes

Epoch #711
 89%|████████▉ | 711/800 [8:10:35<1:01:25, 41.41s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-710.pth
Results:
  total_reward: -53.0, step_mean: -0.03384418901660281
  total_deaths: 1353.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 490.59 minutes

Epoch #712
 89%|████████▉ | 712/800 [8:11:15<1:00:11, 41.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-711.pth
Results:
  total_reward: -71.5, step_mean: -0.04589216944801027
  total_deaths: 1355.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 491.26 minutes

Epoch #713
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-712.pth
Results:
  total_reward: -57.0, step_mean: -0.03639846743295019
  total_deaths: 1356.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 491.95 minutes

Epoch #714
 89%|████████▉ | 714/800 [8:12:37<58:51, 41.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-713.pth
Results:
  total_reward: -71.5, step_mean: -0.04636835278858625
  total_deaths: 1360.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 492.63 minutes

Epoch #715
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-714.pth
Results:
  total_reward: -80.5, step_mean: -0.05196901226597805
  total_deaths: 1363.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 493.30 minutes

Epoch #716
 90%|████████▉ | 716/800 [8:13:59<57:31, 41.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-715.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 1365.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 494.00 minutes

Epoch #717
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-716.pth
Results:
  total_reward: -62.5, step_mean: -0.04011553273427471
  total_deaths: 1367.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 494.67 minutes

Epoch #718
 90%|████████▉ | 718/800 [8:15:19<55:17, 40.46s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-717.pth
Results:
  total_reward: -80.5, step_mean: -0.05227272727272727
  total_deaths: 1371.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 495.33 minutes

Epoch #719
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-718.pth
Results:
  total_reward: -56.0, step_mean: -0.035759897828863345
  total_deaths: 1372.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 496.00 minutes

Epoch #720
 90%|█████████ | 720/800 [8:16:41<54:09, 40.62s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-719.pth
Results:
  total_reward: -67.0, step_mean: -0.04300385109114249
  total_deaths: 1374.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 496.68 minutes

Epoch #721
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-720.pth
Results:
  total_reward: -46.0, step_mean: -0.02937420178799489
  total_deaths: 1375.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 497.37 minutes

Epoch #722
 90%|█████████ | 722/800 [8:18:03<53:22, 41.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-721.pth
Results:
  total_reward: -59.5, step_mean: -0.03818998716302952
  total_deaths: 1377.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 498.06 minutes

Epoch #723
 90%|█████████ | 723/800 [8:18:44<52:23, 40.82s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-722.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 1379.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 498.74 minutes

Epoch #724
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-723.pth
Results:
  total_reward: -85.0, step_mean: -0.05487411233053583
  total_deaths: 1382.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 499.41 minutes

Epoch #725
 91%|█████████ | 725/800 [8:20:05<51:06, 40.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-724.pth
Results:
  total_reward: -65.5, step_mean: -0.0420410783055199
  total_deaths: 1384.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 500.10 minutes

Epoch #726
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-725.pth
Results:
  total_reward: -83.0, step_mean: -0.05358295674628793
  total_deaths: 1387.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 500.78 minutes

Epoch #727
 91%|█████████ | 727/800 [8:21:27<49:50, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-726.pth
Results:
  total_reward: -71.5, step_mean: -0.04592164418754014
  total_deaths: 1389.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 501.47 minutes

Epoch #728
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-727.pth
Results:
  total_reward: -83.5, step_mean: -0.053870967741935484
  total_deaths: 1392.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 502.15 minutes

Epoch #729
 91%|█████████ | 729/800 [8:22:50<48:34, 41.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-728.pth
Results:
  total_reward: -45.5, step_mean: -0.029036375239310786
  total_deaths: 1393.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 502.83 minutes

Epoch #730
 91%|█████████▏| 730/800 [8:23:31<48:02, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-729.pth
Results:
  total_reward: -52.0, step_mean: -0.03318442884492661
  total_deaths: 1394.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 503.53 minutes

Epoch #731
 91%|█████████▏| 731/800 [8:24:13<47:31, 41.32s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-730.pth
Results:
  total_reward: -37.5, step_mean: -0.023809523809523808
  total_deaths: 1394.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 504.22 minutes

Epoch #732
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-731.pth
Results:
  total_reward: -48.0, step_mean: -0.03063178047223995
  total_deaths: 1395.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 504.90 minutes

Epoch #733
 92%|█████████▏| 733/800 [8:25:36<46:19, 41.48s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-732.pth
Results:
  total_reward: -56.0, step_mean: -0.035759897828863345
  total_deaths: 1396.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 505.60 minutes

Epoch #734
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-733.pth
Results:
  total_reward: -62.0, step_mean: -0.03956604977664327
  total_deaths: 1397.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 506.30 minutes

Epoch #735
 92%|█████████▏| 735/800 [8:26:58<44:40, 41.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-734.pth
Results:
  total_reward: -65.0, step_mean: -0.04174694926140013
  total_deaths: 1399.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 506.97 minutes

Epoch #736
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-735.pth
Results:
  total_reward: -78.0, step_mean: -0.05035506778566817
  total_deaths: 1402.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 507.68 minutes

Epoch #737
 92%|█████████▏| 737/800 [8:28:22<43:39, 41.58s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-736.pth
Results:
  total_reward: -49.5, step_mean: -0.03177150192554557
  total_deaths: 1404.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 508.37 minutes

Epoch #738
 92%|█████████▏| 738/800 [8:29:05<43:21, 41.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-737.pth
Results:
  total_reward: -55.0, step_mean: -0.03530166880616174
  total_deaths: 1406.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 509.09 minutes

Epoch #739
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-738.pth
Results:
  total_reward: -56.0, step_mean: -0.035759897828863345
  total_deaths: 1407.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 509.79 minutes

Epoch #740
 92%|█████████▎| 740/800 [8:30:28<41:42, 41.70s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-739.pth
Results:
  total_reward: -73.5, step_mean: -0.047449967721110396
  total_deaths: 1410.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 510.47 minutes

Epoch #741
 93%|█████████▎| 741/800 [8:31:09<40:45, 41.45s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-740.pth
Results:
  total_reward: -59.5, step_mean: -0.037994891443167304
  total_deaths: 1411.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 511.15 minutes

Epoch #742
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-741.pth
Results:
  total_reward: -60.0, step_mean: -0.038510911424903725
  total_deaths: 1413.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 511.85 minutes

Epoch #743
 93%|█████████▎| 743/800 [8:32:32<39:29, 41.57s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-742.pth
Results:
  total_reward: -63.0, step_mean: -0.04043645699614891
  total_deaths: 1415.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 512.54 minutes

Epoch #744
 93%|█████████▎| 744/800 [8:33:13<38:39, 41.42s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-743.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 1417.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 513.23 minutes

Epoch #745
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-744.pth
Results:
  total_reward: -66.0, step_mean: -0.04258064516129032
  total_deaths: 1420.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 513.93 minutes

Epoch #746
 93%|█████████▎| 746/800 [8:34:37<37:22, 41.54s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-745.pth
Results:
  total_reward: -88.5, step_mean: -0.057133634602969656
  total_deaths: 1423.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 514.62 minutes

Epoch #747
 93%|█████████▎| 747/800 [8:35:18<36:33, 41.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-746.pth
Results:
  total_reward: -90.0, step_mean: -0.05806451612903226
  total_deaths: 1426.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 515.30 minutes

Epoch #748
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-747.pth
Results:
  total_reward: -73.5, step_mean: -0.047419354838709675
  total_deaths: 1429.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 515.98 minutes

Epoch #749
 94%|█████████▎| 749/800 [8:36:40<35:00, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-748.pth
Results:
  total_reward: -71.5, step_mean: -0.04589216944801027
  total_deaths: 1431.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 516.67 minutes

Epoch #750
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-749.pth
 94%|█████████▍| 750/800 [8:37:20<34:07, 40.96s/it]Results:
  total_reward: -92.0, step_mean: -0.05966277561608301
  total_deaths: 1435.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 517.34 minutes

Epoch #751
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-750.pth
Results:
  total_reward: -54.0, step_mean: -0.03463758819756254
  total_deaths: 1437.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 518.02 minutes

Epoch #752
 94%|█████████▍| 752/800 [8:38:43<33:06, 41.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-751.pth
Results:
  total_reward: -71.0, step_mean: -0.045571245186136075
  total_deaths: 1439.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 518.73 minutes

Epoch #753
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-752.pth
Results:
  total_reward: -41.5, step_mean: -0.026349206349206348
  total_deaths: 1439.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 519.42 minutes

Epoch #754
 94%|█████████▍| 754/800 [8:40:05<31:26, 41.00s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-753.pth
Results:
  total_reward: -64.5, step_mean: -0.041639767591994836
  total_deaths: 1442.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 520.09 minutes

Epoch #755
 94%|█████████▍| 755/800 [8:40:46<30:42, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-754.pth
Results:
  total_reward: -56.5, step_mean: -0.036056158264199105
  total_deaths: 1443.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 520.77 minutes

Epoch #756
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-755.pth
Results:
  total_reward: -64.0, step_mean: -0.04129032258064516
  total_deaths: 1446.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 521.46 minutes

Epoch #757
 95%|█████████▍| 757/800 [8:42:09<29:35, 41.29s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-756.pth
Results:
  total_reward: -51.5, step_mean: -0.03305519897304236
  total_deaths: 1448.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 522.16 minutes

Epoch #758
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-757.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 1450.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 522.82 minutes

Epoch #759
 95%|█████████▍| 759/800 [8:43:30<28:03, 41.07s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-758.pth
Results:
  total_reward: -58.0, step_mean: -0.037037037037037035
  total_deaths: 1451.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 523.51 minutes

Epoch #760
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-759.pth
Results:
  total_reward: -68.0, step_mean: -0.043645699614890884
  total_deaths: 1453.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 524.21 minutes

Epoch #761
 95%|█████████▌| 761/800 [8:44:53<26:45, 41.15s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-760.pth
Results:
  total_reward: -63.0, step_mean: -0.04043645699614891
  total_deaths: 1455.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 524.89 minutes

Epoch #762
 95%|█████████▌| 762/800 [8:45:33<25:53, 40.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-761.pth
Results:
  total_reward: -76.5, step_mean: -0.04964308890330954
  total_deaths: 1459.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 525.56 minutes

Epoch #763
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-762.pth
Results:
  total_reward: -70.5, step_mean: -0.04525032092426187
  total_deaths: 1461.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 526.26 minutes

Epoch #764
 96%|█████████▌| 764/800 [8:46:57<24:54, 41.51s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-763.pth
Results:
  total_reward: -55.0, step_mean: -0.03530166880616174
  total_deaths: 1463.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 526.96 minutes

Epoch #765
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-764.pth
Results:
  total_reward: -56.5, step_mean: -0.036056158264199105
  total_deaths: 1464.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 527.68 minutes

Epoch #766
 96%|█████████▌| 766/800 [8:48:21<23:33, 41.58s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-765.pth
Results:
  total_reward: -64.0, step_mean: -0.0410783055198973
  total_deaths: 1466.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 528.36 minutes

Epoch #767
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-766.pth
Results:
  total_reward: -75.5, step_mean: -0.0487411233053583
  total_deaths: 1469.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 529.02 minutes

Epoch #768
 96%|█████████▌| 768/800 [8:49:41<21:43, 40.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-767.pth
Results:
  total_reward: -72.5, step_mean: -0.046534017971758664
  total_deaths: 1471.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 529.69 minutes

Epoch #769
 96%|█████████▌| 769/800 [8:50:21<20:56, 40.52s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-768.pth
Results:
  total_reward: -63.0, step_mean: -0.04046242774566474
  total_deaths: 1473.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 530.35 minutes

Epoch #770
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-769.pth
Results:
  total_reward: -53.0, step_mean: -0.03382259093809828
  total_deaths: 1474.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 531.03 minutes

Epoch #771
 96%|█████████▋| 771/800 [8:51:42<19:33, 40.46s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-770.pth
Results:
  total_reward: -69.0, step_mean: -0.044287548138639284
  total_deaths: 1476.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 531.70 minutes

Epoch #772
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-771.pth
Results:
  total_reward: -56.0, step_mean: -0.035759897828863345
  total_deaths: 1477.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 532.37 minutes

Epoch #773
 97%|█████████▋| 773/800 [8:53:01<18:03, 40.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-772.pth
Results:
  total_reward: -70.5, step_mean: -0.04551323434473854
  total_deaths: 1480.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 533.03 minutes

Epoch #774
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-773.pth
Results:
  total_reward: -72.5, step_mean: -0.046804389928986445
  total_deaths: 1483.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 533.69 minutes

Epoch #775
 97%|█████████▋| 775/800 [8:54:21<16:41, 40.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-774.pth
Results:
  total_reward: -66.5, step_mean: -0.04271034039820167
  total_deaths: 1485.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 534.36 minutes

Epoch #776
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-775.pth
Results:
  total_reward: -69.0, step_mean: -0.044516129032258066
  total_deaths: 1488.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 535.02 minutes

Epoch #777
 97%|█████████▋| 777/800 [8:55:42<15:22, 40.12s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-776.pth
Results:
  total_reward: -53.0, step_mean: -0.03384418901660281
  total_deaths: 1489.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 535.70 minutes

Epoch #778
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-777.pth
Results:
  total_reward: -49.5, step_mean: -0.03175112251443233
  total_deaths: 1491.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 536.37 minutes

Epoch #779
 97%|█████████▋| 779/800 [8:57:02<14:05, 40.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-778.pth
Results:
  total_reward: -49.5, step_mean: -0.03158902361199745
  total_deaths: 1492.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 537.05 minutes

Epoch #780
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-779.pth
Results:
  total_reward: -67.0, step_mean: -0.043225806451612905
  total_deaths: 1495.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 537.73 minutes

Epoch #781
 98%|█████████▊| 781/800 [8:58:25<12:56, 40.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-780.pth
Results:
  total_reward: -58.0, step_mean: -0.037013401403956606
  total_deaths: 1496.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 538.43 minutes

Epoch #782
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-781.pth
Results:
  total_reward: -60.5, step_mean: -0.03883183568677792
  total_deaths: 1498.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 539.11 minutes

Epoch #783
 98%|█████████▊| 783/800 [8:59:48<11:38, 41.11s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-782.pth
Results:
  total_reward: -63.5, step_mean: -0.040783558124598586
  total_deaths: 1500.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 539.80 minutes

Epoch #784
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-783.pth
Results:
  total_reward: -64.0, step_mean: -0.04129032258064516
  total_deaths: 1503.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 540.48 minutes

Epoch #785
 98%|█████████▊| 785/800 [9:01:09<10:11, 40.76s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-784.pth
Results:
  total_reward: -73.5, step_mean: -0.04717586649550706
  total_deaths: 1505.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 541.15 minutes

Epoch #786
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-785.pth
Results:
  total_reward: -67.5, step_mean: -0.04332477535301669
  total_deaths: 1507.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 541.83 minutes

Epoch #787
 98%|█████████▊| 787/800 [9:02:30<08:50, 40.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-786.pth
Results:
  total_reward: -57.5, step_mean: -0.03690629011553274
  total_deaths: 1509.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 542.51 minutes

Epoch #788
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-787.pth
Results:
  total_reward: -62.5, step_mean: -0.03991060025542784
  total_deaths: 1510.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 543.20 minutes

Epoch #789
 99%|█████████▊| 789/800 [9:03:52<07:27, 40.69s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-788.pth
Results:
  total_reward: -70.5, step_mean: -0.04548387096774194
  total_deaths: 1513.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 543.87 minutes

Epoch #790
 99%|█████████▉| 790/800 [9:04:30<06:41, 40.15s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-789.pth
Results:
  total_reward: -70.0, step_mean: -0.044929396662387676
  total_deaths: 1515.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 544.51 minutes

Epoch #791
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-790.pth
Results:
  total_reward: -66.5, step_mean: -0.04290322580645161
  total_deaths: 1518.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 545.17 minutes

Epoch #792
 99%|█████████▉| 792/800 [9:05:49<05:17, 39.69s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-791.pth
Results:
  total_reward: -53.5, step_mean: -0.03414167198468411
  total_deaths: 1519.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 545.82 minutes

Epoch #793
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-792.pth
Results:
  total_reward: -72.0, step_mean: -0.04621309370988447
  total_deaths: 1521.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 546.48 minutes

Epoch #794
 99%|█████████▉| 794/800 [9:07:08<03:58, 39.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-793.pth
Results:
  total_reward: -55.0, step_mean: -0.0351213282247765
  total_deaths: 1522.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 547.14 minutes

Epoch #795
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-794.pth
Results:
  total_reward: -50.5, step_mean: -0.032227185705169116
  total_deaths: 1523.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 547.81 minutes

Epoch #796
100%|█████████▉| 796/800 [9:08:28<02:38, 39.69s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-795.pth
Results:
  total_reward: -60.0, step_mean: -0.03828972559029994
  total_deaths: 1524.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 548.47 minutes

Epoch #797
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-796.pth
Results:
  total_reward: -43.5, step_mean: -0.027760051052967454
  total_deaths: 1525.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 549.12 minutes

Epoch #798
100%|█████████▉| 798/800 [9:09:45<01:18, 39.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-797.pth
Results:
  total_reward: -65.5, step_mean: -0.0420410783055199
  total_deaths: 1527.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 549.76 minutes

Epoch #799
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-798.pth
Results:
  total_reward: -74.0, step_mean: -0.04749679075738126
  total_deaths: 1529.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 550.41 minutes

Epoch #800
Saving the network weights to: ../models/sec_models/only_kill_death_shot/model-799.pth
Results:
  total_reward: -64.0, step_mean: -0.0410783055198973
  total_deaths: 1531.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 551.04 minutes
Saving the network weights to: ../models/model-only_kill_death_shot.pth
======================================
Training finished. It's time to watch!
mean: -0.1235558408215661, total: -192.5, steps: 1558
mean: -0.11424903722721438, total: -178.0, steps: 1558
mean: -0.1241976893453145, total: -193.5, steps: 1558
mean: -0.11489088575096278, total: -179.0, steps: 1558
mean: -0.11553273427471117, total: -180.0, steps: 1558
mean: -0.12524334847501623, total: -193.0, steps: 1541
mean: -0.09884467265725289, total: -154.0, steps: 1558
mean: -0.11008296107211232, total: -172.5, steps: 1567
mean: -0.1111111111111111, total: -174.0, steps: 1566
mean: -0.10886319845857419, total: -169.5, steps: 1557
mean: -0.10115606936416185, total: -157.5, steps: 1557
mean: -0.09338896020539153, total: -145.5, steps: 1558
mean: -0.10109465550547328, total: -157.0, steps: 1553
mean: -0.09554551323434474, total: -148.0, steps: 1549
mean: -0.07854406130268199, total: -123.0, steps: 1566
mean: -0.08258064516129032, total: -128.0, steps: 1550
mean: -0.0750481077613855, total: -117.0, steps: 1559
mean: -0.07610789980732177, total: -118.5, steps: 1557
mean: -0.08055198973042361, total: -125.5, steps: 1558
mean: -0.061296534017971756, total: -95.5, steps: 1558
mean: -0.08023106546854943, total: -125.0, steps: 1558
mean: -0.06867779204107831, total: -107.0, steps: 1558
mean: -0.0631780472239949, total: -99.0, steps: 1567
mean: -0.06867779204107831, total: -107.0, steps: 1558
mean: -0.06450577663671374, total: -100.5, steps: 1558
mean: -0.07424144609425436, total: -115.0, steps: 1549
mean: -0.06225930680359435, total: -97.0, steps: 1558
mean: -0.05938697318007663, total: -93.0, steps: 1566
mean: -0.06258023106546855, total: -97.5, steps: 1558
mean: -0.06197546804389929, total: -96.0, steps: 1549
mean: -0.05971594577146546, total: -92.5, steps: 1549
mean: -0.058102001291155586, total: -90.0, steps: 1549
mean: -0.05940912010276172, total: -92.5, steps: 1557
mean: -0.06675224646983312, total: -104.0, steps: 1558
mean: -0.05937098844672657, total: -92.5, steps: 1558
mean: -0.05870967741935484, total: -91.0, steps: 1550
mean: -0.04435226547543076, total: -69.5, steps: 1567
mean: -0.05616526791478373, total: -87.0, steps: 1549
mean: -0.04789272030651341, total: -75.0, steps: 1566
mean: -0.0398851308232291, total: -62.5, steps: 1567
mean: -0.052258064516129035, total: -81.0, steps: 1550
mean: -0.03735632183908046, total: -58.5, steps: 1566
mean: -0.04086845466155811, total: -64.0, steps: 1566
mean: -0.045571245186136075, total: -71.0, steps: 1558
mean: -0.039380245319561004, total: -61.0, steps: 1549
mean: -0.05035279025016036, total: -78.5, steps: 1559
mean: -0.04942233632862644, total: -77.0, steps: 1558
mean: -0.03350350989151244, total: -52.5, steps: 1567
mean: -0.053548387096774196, total: -83.0, steps: 1550
mean: -0.04910141206675225, total: -76.5, steps: 1558
mean: -0.043225806451612905, total: -67.0, steps: 1550
mean: -0.028888888888888888, total: -45.5, steps: 1575
mean: -0.043225806451612905, total: -67.0, steps: 1550
mean: -0.05358295674628793, total: -83.0, steps: 1549
mean: -0.03337612323491656, total: -52.0, steps: 1558
mean: -0.04712717882504842, total: -73.0, steps: 1549
mean: -0.04589216944801027, total: -71.5, steps: 1558
mean: -0.032567049808429116, total: -51.0, steps: 1566
mean: -0.04238921001926782, total: -66.0, steps: 1557
mean: -0.03956604977664327, total: -62.0, steps: 1567
mean: -0.03720333547145606, total: -58.0, steps: 1559
mean: -0.04011553273427471, total: -62.5, steps: 1558
mean: -0.041639767591994836, total: -64.5, steps: 1549
mean: -0.04396662387676508, total: -68.5, steps: 1558
mean: -0.046804389928986445, total: -72.5, steps: 1549
mean: -0.040229885057471264, total: -63.0, steps: 1566
mean: -0.046885035324341684, total: -73.0, steps: 1557
mean: -0.05202312138728324, total: -81.0, steps: 1557
mean: -0.054510058403634, total: -84.0, steps: 1541
mean: -0.041399229781771504, total: -64.5, steps: 1558
mean: -0.0408423739629866, total: -64.0, steps: 1567
mean: -0.04621309370988447, total: -72.0, steps: 1558
mean: -0.05971594577146546, total: -92.5, steps: 1549
mean: -0.06168831168831169, total: -95.0, steps: 1540
mean: -0.03158902361199745, total: -49.5, steps: 1567
mean: -0.04774193548387097, total: -74.0, steps: 1550
mean: -0.0410783055198973, total: -64.0, steps: 1558
mean: -0.035440613026819924, total: -55.5, steps: 1566
mean: -0.04460847240051348, total: -69.5, steps: 1558
mean: -0.037869062901155326, total: -59.0, steps: 1558
mean: -0.030970625798212005, total: -48.5, steps: 1566
mean: -0.047817715019255455, total: -74.5, steps: 1558
mean: -0.033205619412515965, total: -52.0, steps: 1566
mean: -0.042068079640333975, total: -65.5, steps: 1557
mean: -0.05191434133679429, total: -80.0, steps: 1541
mean: -0.031289910600255426, total: -49.0, steps: 1566
mean: -0.046534017971758664, total: -72.5, steps: 1558
mean: -0.05519480519480519, total: -85.0, steps: 1540
mean: -0.051646223369916075, total: -80.0, steps: 1549
mean: -0.04260813428018076, total: -66.0, steps: 1549
mean: -0.04486765655261459, total: -69.5, steps: 1549
mean: -0.038314176245210725, total: -60.0, steps: 1566
mean: -0.055842479018721754, total: -86.5, steps: 1549
mean: -0.050706033376123234, total: -79.0, steps: 1558
mean: -0.02857142857142857, total: -45.0, steps: 1575
mean: -0.047419354838709675, total: -73.5, steps: 1550
mean: -0.04749679075738126, total: -74.0, steps: 1558
mean: -0.055807916937053864, total: -86.0, steps: 1541
mean: -0.04396662387676508, total: -68.5, steps: 1558
mean: -0.037227214377406934, total: -58.0, steps: 1558
mean: -0.0499675535366645, total: -77.0, steps: 1541
mean: -0.042682926829268296, total: -66.5, steps: 1558
mean: -0.0487411233053583, total: -75.5, steps: 1549
mean: -0.03690629011553274, total: -57.5, steps: 1558
mean: -0.035737077217613274, total: -56.0, steps: 1567
mean: -0.03754813863928113, total: -58.5, steps: 1558
mean: -0.042118698149329926, total: -66.0, steps: 1567
mean: -0.04849068721901092, total: -75.5, steps: 1557
mean: -0.0421455938697318, total: -66.0, steps: 1566
mean: -0.041507024265644954, total: -65.0, steps: 1566
mean: -0.04342273307790549, total: -68.0, steps: 1566
mean: -0.044061302681992334, total: -69.0, steps: 1566
mean: -0.05193548387096774, total: -80.5, steps: 1550
mean: -0.04533844189016603, total: -71.0, steps: 1566
mean: -0.05195638229634381, total: -81.0, steps: 1559
mean: -0.04357650096836669, total: -67.5, steps: 1549
mean: -0.05006418485237484, total: -78.0, steps: 1558
mean: -0.05970149253731343, total: -92.0, steps: 1541
mean: -0.03286534779834078, total: -51.5, steps: 1567
mean: -0.03735632183908046, total: -58.5, steps: 1566
mean: -0.04709677419354839, total: -73.0, steps: 1550
mean: -0.0421455938697318, total: -66.0, steps: 1566
mean: -0.037013401403956606, total: -58.0, steps: 1567
mean: -0.04238921001926782, total: -66.0, steps: 1557
mean: -0.04438058748403576, total: -69.5, steps: 1566
mean: -0.04656390494540784, total: -72.5, steps: 1557
mean: -0.05295250320924262, total: -82.5, steps: 1558
mean: -0.06097560975609756, total: -95.0, steps: 1558
mean: -0.04878048780487805, total: -76.0, steps: 1558
mean: -0.04300385109114249, total: -67.0, steps: 1558
mean: -0.04806451612903226, total: -74.5, steps: 1550
mean: -0.04438058748403576, total: -69.5, steps: 1566
mean: -0.04806451612903226, total: -74.5, steps: 1550
mean: -0.042118698149329926, total: -66.0, steps: 1567
mean: -0.08391831525207402, total: -131.5, steps: 1567
mean: -0.05009572431397575, total: -78.5, steps: 1567
mean: -0.03158902361199745, total: -49.5, steps: 1567
mean: -0.04460847240051348, total: -69.5, steps: 1558
mean: -0.03111111111111111, total: -49.0, steps: 1575
mean: -0.03286534779834078, total: -51.5, steps: 1567
mean: -0.046242774566473986, total: -72.0, steps: 1557
mean: -0.039272030651340994, total: -61.5, steps: 1566
mean: -0.037013401403956606, total: -58.0, steps: 1567
mean: -0.04516129032258064, total: -70.0, steps: 1550
mean: -0.04974326059050064, total: -77.5, steps: 1558
mean: -0.038510911424903725, total: -60.0, steps: 1558
mean: -0.048459563543003854, total: -75.5, steps: 1558
mean: -0.050292018170019465, total: -77.5, steps: 1541
mean: -0.04431599229287091, total: -69.0, steps: 1557
mean: -0.046885035324341684, total: -73.0, steps: 1557
mean: -0.0398851308232291, total: -62.5, steps: 1567
mean: -0.030793650793650793, total: -48.5, steps: 1575
mean: -0.029841269841269842, total: -47.0, steps: 1575
mean: -0.04717586649550706, total: -73.5, steps: 1558
mean: -0.02761904761904762, total: -43.5, steps: 1575
mean: -0.054510058403634, total: -84.0, steps: 1541
mean: -0.037227214377406934, total: -58.0, steps: 1558
mean: -0.03991060025542784, total: -62.5, steps: 1566
mean: -0.03754813863928113, total: -58.5, steps: 1558
mean: -0.038510911424903725, total: -60.0, steps: 1558
mean: -0.051323434473854096, total: -79.5, steps: 1549
mean: -0.036717752234993614, total: -57.5, steps: 1566
mean: -0.05064516129032258, total: -78.5, steps: 1550
mean: -0.037869062901155326, total: -59.0, steps: 1558
mean: -0.04011553273427471, total: -62.5, steps: 1558
mean: -0.04052329291640076, total: -63.5, steps: 1567
mean: -0.02761904761904762, total: -43.5, steps: 1575
mean: -0.037675606641123884, total: -59.0, steps: 1566
mean: -0.03924696873005743, total: -61.5, steps: 1567
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.043645699614890884, total: -68.0, steps: 1558
mean: -0.0449582530507386, total: -70.0, steps: 1557
mean: -0.03860880663688577, total: -60.5, steps: 1567
mean: -0.040229885057471264, total: -63.0, steps: 1566
mean: -0.040757381258023105, total: -63.5, steps: 1558
mean: -0.0346031746031746, total: -54.5, steps: 1575
mean: -0.037869062901155326, total: -59.0, steps: 1558
mean: -0.052614590058102, total: -81.5, steps: 1549
mean: -0.0420410783055199, total: -65.5, steps: 1558
mean: -0.04589216944801027, total: -71.5, steps: 1558
mean: -0.03915275994865212, total: -61.0, steps: 1558
mean: -0.039473684210526314, total: -61.5, steps: 1558
mean: -0.04525032092426187, total: -70.5, steps: 1558
mean: -0.0512987012987013, total: -79.0, steps: 1540
mean: -0.02857142857142857, total: -45.0, steps: 1575
mean: -0.05290322580645161, total: -82.0, steps: 1550
mean: -0.03431686978832585, total: -53.5, steps: 1559
mean: -0.032567049808429116, total: -51.0, steps: 1566
mean: -0.05161290322580645, total: -80.0, steps: 1550
mean: -0.03498074454428755, total: -54.5, steps: 1558
mean: -0.040229885057471264, total: -63.0, steps: 1566
mean: -0.04332477535301669, total: -67.5, steps: 1558
mean: -0.04589216944801027, total: -71.5, steps: 1558
mean: -0.0449582530507386, total: -70.0, steps: 1557
mean: -0.06521739130434782, total: -100.5, steps: 1541
mean: -0.038952745849297574, total: -61.0, steps: 1566
mean: -0.04460847240051348, total: -69.5, steps: 1558
mean: -0.034802043422733075, total: -54.5, steps: 1566
mean: -0.03477983407785577, total: -54.5, steps: 1567
mean: -0.037013401403956606, total: -58.0, steps: 1567
mean: -0.044516129032258066, total: -69.0, steps: 1550
mean: -0.03720333547145606, total: -58.0, steps: 1559
mean: -0.03384418901660281, total: -53.0, steps: 1566
mean: -0.039473684210526314, total: -61.5, steps: 1558
mean: -0.04774193548387097, total: -74.0, steps: 1550
mean: -0.028241335044929396, total: -44.0, steps: 1558
mean: -0.04238921001926782, total: -66.0, steps: 1557
mean: -0.044287548138639284, total: -69.0, steps: 1558
mean: -0.035440613026819924, total: -55.5, steps: 1566
mean: -0.0351213282247765, total: -55.0, steps: 1566
mean: -0.035440613026819924, total: -55.5, steps: 1566
mean: -0.040229885057471264, total: -63.0, steps: 1566
mean: -0.033205619412515965, total: -52.0, steps: 1566
mean: -0.03991060025542784, total: -62.5, steps: 1566
mean: -0.02412698412698413, total: -38.0, steps: 1575
mean: -0.04525032092426187, total: -70.5, steps: 1558
mean: -0.046481601032924466, total: -72.0, steps: 1549
mean: -0.037869062901155326, total: -59.0, steps: 1558
mean: -0.04300385109114249, total: -67.0, steps: 1558
mean: -0.04809554551323435, total: -74.5, steps: 1549
mean: -0.038510911424903725, total: -60.0, steps: 1558
mean: -0.03509891512444161, total: -55.0, steps: 1567
mean: -0.02412698412698413, total: -38.0, steps: 1575
mean: -0.04592164418754014, total: -71.5, steps: 1557
mean: -0.03818998716302952, total: -59.5, steps: 1558
mean: -0.04225806451612903, total: -65.5, steps: 1550
mean: -0.03318442884492661, total: -52.0, steps: 1567
mean: -0.02253968253968254, total: -35.5, steps: 1575
mean: -0.03239255933290571, total: -50.5, steps: 1559
mean: -0.048709677419354835, total: -75.5, steps: 1550
mean: -0.036608863198458574, total: -57.0, steps: 1557
mean: -0.03733248245054244, total: -58.5, steps: 1567
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.04419354838709678, total: -68.5, steps: 1550
mean: -0.03982016698779704, total: -62.0, steps: 1557
mean: -0.05422853453841188, total: -84.0, steps: 1549
mean: -0.04527938342967245, total: -70.5, steps: 1557
mean: -0.05196901226597805, total: -80.5, steps: 1549
mean: -0.042682926829268296, total: -66.5, steps: 1558
mean: -0.04813863928112965, total: -75.0, steps: 1558
mean: -0.040757381258023105, total: -63.5, steps: 1558
mean: -0.04052329291640076, total: -63.5, steps: 1567
mean: -0.046534017971758664, total: -72.5, steps: 1558
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.03765156349712827, total: -59.0, steps: 1567
mean: -0.033205619412515965, total: -52.0, steps: 1566
mean: -0.030970625798212005, total: -48.5, steps: 1566
mean: -0.03639846743295019, total: -57.0, steps: 1566
mean: -0.03559974342527261, total: -55.5, steps: 1559
mean: -0.03915275994865212, total: -61.0, steps: 1558
mean: -0.045221295702373314, total: -70.5, steps: 1559
mean: -0.03870967741935484, total: -60.0, steps: 1550
mean: -0.037013401403956606, total: -58.0, steps: 1567
mean: -0.03690629011553274, total: -57.5, steps: 1558
mean: -0.03446075303126994, total: -54.0, steps: 1567
mean: -0.05067785668173015, total: -78.5, steps: 1549
mean: -0.034802043422733075, total: -54.5, steps: 1566
mean: -0.06103896103896104, total: -94.0, steps: 1540
mean: -0.03254626675175495, total: -51.0, steps: 1567
mean: -0.04463712267180475, total: -69.5, steps: 1557
mean: -0.030970625798212005, total: -48.5, steps: 1566
mean: -0.03959131545338442, total: -62.0, steps: 1566
mean: -0.03384418901660281, total: -53.0, steps: 1566
mean: -0.048709677419354835, total: -75.5, steps: 1550
mean: -0.04809554551323435, total: -74.5, steps: 1549
mean: -0.04300385109114249, total: -67.0, steps: 1558
mean: -0.032247765006385695, total: -50.5, steps: 1566
mean: -0.02158730158730159, total: -34.0, steps: 1575
mean: -0.04813863928112965, total: -75.0, steps: 1558
mean: -0.057456423499031635, total: -89.0, steps: 1549
mean: -0.024761904761904763, total: -39.0, steps: 1575
mean: -0.05158987670343933, total: -79.5, steps: 1541
mean: -0.04910141206675225, total: -76.5, steps: 1558
mean: -0.037013401403956606, total: -58.0, steps: 1567
mean: -0.038952745849297574, total: -61.0, steps: 1566
mean: -0.048709677419354835, total: -75.5, steps: 1550
mean: -0.038314176245210725, total: -60.0, steps: 1566
mean: -0.043225806451612905, total: -67.0, steps: 1550
mean: -0.05161290322580645, total: -80.0, steps: 1550
mean: -0.032567049808429116, total: -51.0, steps: 1566
mean: -0.040141297366730895, total: -62.5, steps: 1557
mean: -0.04878048780487805, total: -76.0, steps: 1558
mean: -0.04717586649550706, total: -73.5, steps: 1558
mean: -0.05290322580645161, total: -82.0, steps: 1550
mean: -0.05256327060350422, total: -81.0, steps: 1541
mean: -0.048459563543003854, total: -75.5, steps: 1558
mean: -0.045806451612903226, total: -71.0, steps: 1550
mean: -0.0410783055198973, total: -64.0, steps: 1558
mean: -0.02871729419272495, total: -45.0, steps: 1567
mean: -0.04463712267180475, total: -69.5, steps: 1557
mean: -0.033697047496790755, total: -52.5, steps: 1558
mean: -0.041480536056158264, total: -65.0, steps: 1567
mean: -0.038510911424903725, total: -60.0, steps: 1558
mean: -0.03541799617102744, total: -55.5, steps: 1567
mean: -0.03384418901660281, total: -53.0, steps: 1566
mean: -0.027301587301587302, total: -43.0, steps: 1575
mean: -0.041399229781771504, total: -64.5, steps: 1558
mean: -0.05099422706863374, total: -79.5, steps: 1559
mean: -0.05551969012265978, total: -86.0, steps: 1549
mean: -0.051000645577792124, total: -79.0, steps: 1549
mean: -0.040025823111684955, total: -62.0, steps: 1549
mean: -0.04717586649550706, total: -73.5, steps: 1558
mean: -0.04592164418754014, total: -71.5, steps: 1557
mean: -0.04709677419354839, total: -73.0, steps: 1550
mean: -0.034482758620689655, total: -54.0, steps: 1566
mean: -0.032063492063492065, total: -50.5, steps: 1575
mean: -0.03828972559029994, total: -60.0, steps: 1567
mean: -0.046534017971758664, total: -72.5, steps: 1558
mean: -0.032413350449293964, total: -50.5, steps: 1558
mean: -0.03238095238095238, total: -51.0, steps: 1575
mean: -0.054510058403634, total: -84.0, steps: 1541
mean: -0.03624118024374599, total: -56.5, steps: 1559
mean: -0.051323434473854096, total: -79.5, steps: 1549
mean: -0.04043645699614891, total: -63.0, steps: 1558
mean: -0.04236200256739409, total: -66.0, steps: 1558
mean: -0.025396825396825397, total: -40.0, steps: 1575
mean: -0.03860880663688577, total: -60.5, steps: 1567
mean: -0.028735632183908046, total: -45.0, steps: 1566
mean: -0.04878048780487805, total: -76.0, steps: 1558
mean: -0.04116145500957243, total: -64.5, steps: 1567
mean: -0.03765156349712827, total: -59.0, steps: 1567
mean: -0.03033205619412516, total: -47.5, steps: 1566
mean: -0.05090791180285344, total: -78.5, steps: 1542
mean: -0.035806451612903224, total: -55.5, steps: 1550
mean: -0.032567049808429116, total: -51.0, steps: 1566
mean: -0.040671400903808906, total: -63.0, steps: 1549
mean: -0.03639846743295019, total: -57.0, steps: 1566
mean: -0.037970644543714106, total: -59.5, steps: 1567
mean: -0.03337612323491656, total: -52.0, steps: 1558
mean: -0.04525032092426187, total: -70.5, steps: 1558
mean: -0.044287548138639284, total: -69.0, steps: 1558
mean: -0.041826309067688375, total: -65.5, steps: 1566
mean: -0.0326984126984127, total: -51.5, steps: 1575
mean: -0.044287548138639284, total: -69.0, steps: 1558
mean: -0.035622593068035946, total: -55.5, steps: 1558
mean: -0.04548387096774194, total: -70.5, steps: 1550
mean: -0.040994189799870885, total: -63.5, steps: 1549
mean: -0.036056158264199105, total: -56.5, steps: 1567
mean: -0.040549169859514685, total: -63.5, steps: 1566
mean: -0.03784477228992944, total: -59.0, steps: 1559
mean: -0.034163473818646234, total: -53.5, steps: 1566
mean: -0.03594351732991014, total: -56.0, steps: 1558
mean: -0.03286534779834078, total: -51.5, steps: 1567
mean: -0.04236200256739409, total: -66.0, steps: 1558
mean: -0.046129032258064515, total: -71.5, steps: 1550
mean: -0.03477983407785577, total: -54.5, steps: 1567
mean: -0.045571245186136075, total: -71.0, steps: 1558
mean: -0.052614590058102, total: -81.5, steps: 1549
mean: -0.04201411161000641, total: -65.5, steps: 1559
mean: -0.04810776138550353, total: -75.0, steps: 1559
mean: -0.03818998716302952, total: -59.5, steps: 1558
mean: -0.024444444444444446, total: -38.5, steps: 1575
mean: -0.04842847979474022, total: -75.5, steps: 1559
mean: -0.057441253263707574, total: -88.0, steps: 1532
mean: -0.04387096774193548, total: -68.0, steps: 1550
mean: -0.04712717882504842, total: -73.0, steps: 1549
mean: -0.03239255933290571, total: -50.5, steps: 1559
mean: -0.03465982028241335, total: -54.0, steps: 1558
mean: -0.0398851308232291, total: -62.5, steps: 1567
mean: -0.036585365853658534, total: -57.0, steps: 1558
mean: -0.029993618379068283, total: -47.0, steps: 1567
mean: -0.042976266837716486, total: -67.0, steps: 1559
mean: -0.029036375239310786, total: -45.5, steps: 1567
mean: -0.040757381258023105, total: -63.5, steps: 1558
mean: -0.032886334610472544, total: -51.5, steps: 1566
mean: -0.04463712267180475, total: -69.5, steps: 1557
mean: -0.03915275994865212, total: -61.0, steps: 1558
mean: -0.046158812136862494, total: -71.5, steps: 1549
mean: -0.036079182630906766, total: -56.5, steps: 1566
mean: -0.037013401403956606, total: -58.0, steps: 1567
mean: -0.0421455938697318, total: -66.0, steps: 1566
mean: -0.04396662387676508, total: -68.5, steps: 1558
mean: -0.036608863198458574, total: -57.0, steps: 1557
mean: -0.03733248245054244, total: -58.5, steps: 1567
mean: -0.02871729419272495, total: -45.0, steps: 1567
mean: -0.04527938342967245, total: -70.5, steps: 1557
mean: -0.046534017971758664, total: -72.5, steps: 1558
mean: -0.037869062901155326, total: -59.0, steps: 1558
mean: -0.04460847240051348, total: -69.5, steps: 1558
mean: -0.044516129032258066, total: -69.0, steps: 1550
mean: -0.027121888959795788, total: -42.5, steps: 1567
mean: -0.04878048780487805, total: -76.0, steps: 1558
mean: -0.042976266837716486, total: -67.0, steps: 1559
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.03384418901660281, total: -53.0, steps: 1566
mean: -0.04332477535301669, total: -67.5, steps: 1558
mean: -0.04589216944801027, total: -71.5, steps: 1558
mean: -0.03446075303126994, total: -54.0, steps: 1567
mean: -0.04052329291640076, total: -63.5, steps: 1567
mean: -0.036717752234993614, total: -57.5, steps: 1566
mean: -0.038387096774193545, total: -59.5, steps: 1550
mean: -0.03238095238095238, total: -51.0, steps: 1575
mean: -0.04303147077713552, total: -67.0, steps: 1557
mean: -0.03967741935483871, total: -61.5, steps: 1550
mean: -0.05293737895416398, total: -82.0, steps: 1549
mean: -0.03639846743295019, total: -57.0, steps: 1566
mean: -0.029674537332482452, total: -46.5, steps: 1567
mean: -0.034802043422733075, total: -54.5, steps: 1566
mean: -0.0389278876834716, total: -61.0, steps: 1567
mean: -0.04589216944801027, total: -71.5, steps: 1558
mean: -0.04310344827586207, total: -67.5, steps: 1566
mean: -0.035737077217613274, total: -56.0, steps: 1567
mean: -0.054474708171206226, total: -84.0, steps: 1542
mean: -0.03401797175866496, total: -53.0, steps: 1558
mean: -0.04589216944801027, total: -71.5, steps: 1558
mean: -0.042682926829268296, total: -66.5, steps: 1558
mean: -0.04225806451612903, total: -65.5, steps: 1550
mean: -0.04717586649550706, total: -73.5, steps: 1558
mean: -0.030970625798212005, total: -48.5, steps: 1566
mean: -0.03915275994865212, total: -61.0, steps: 1558
mean: -0.03509891512444161, total: -55.0, steps: 1567
mean: -0.03384418901660281, total: -53.0, steps: 1566
mean: -0.031269942565411615, total: -49.0, steps: 1567
mean: -0.037096774193548385, total: -57.5, steps: 1550
mean: -0.040757381258023105, total: -63.5, steps: 1558
mean: -0.028888888888888888, total: -45.5, steps: 1575
mean: -0.042682926829268296, total: -66.5, steps: 1558
mean: -0.043645699614890884, total: -68.0, steps: 1558
mean: -0.0449582530507386, total: -70.0, steps: 1557
mean: -0.05, total: -77.5, steps: 1550
mean: -0.03735632183908046, total: -58.5, steps: 1566
mean: -0.047817715019255455, total: -74.5, steps: 1558
mean: -0.04335260115606936, total: -67.5, steps: 1557
mean: -0.0389278876834716, total: -61.0, steps: 1567
mean: -0.047402597402597405, total: -73.0, steps: 1540
mean: -0.029206349206349208, total: -46.0, steps: 1575
mean: -0.034482758620689655, total: -54.0, steps: 1566
mean: -0.022016592214422464, total: -34.5, steps: 1567
mean: -0.029206349206349208, total: -46.0, steps: 1575
mean: -0.03639846743295019, total: -57.0, steps: 1566
mean: -0.0417201540436457, total: -65.0, steps: 1558
mean: -0.05422853453841188, total: -84.0, steps: 1549
mean: -0.03158902361199745, total: -49.5, steps: 1567
mean: -0.045600513808606295, total: -71.0, steps: 1557
mean: -0.03979460847240052, total: -62.0, steps: 1558
mean: -0.04717586649550706, total: -73.5, steps: 1558
mean: -0.05616526791478373, total: -87.0, steps: 1549
mean: -0.04431599229287091, total: -69.0, steps: 1557
mean: -0.04749679075738126, total: -74.0, steps: 1558
mean: -0.03065134099616858, total: -48.0, steps: 1566
mean: -0.05166880616174583, total: -80.5, steps: 1558
mean: -0.03915275994865212, total: -61.0, steps: 1558
mean: -0.04236200256739409, total: -66.0, steps: 1558
mean: -0.03498074454428755, total: -54.5, steps: 1558
mean: -0.03915275994865212, total: -61.0, steps: 1558
mean: -0.029206349206349208, total: -46.0, steps: 1575
mean: -0.046129032258064515, total: -71.5, steps: 1550
mean: -0.0408423739629866, total: -64.0, steps: 1567
mean: -0.032227185705169116, total: -50.5, steps: 1567
mean: -0.040348612007746934, total: -62.5, steps: 1549
mean: -0.03752405388069275, total: -58.5, steps: 1559
mean: -0.04011553273427471, total: -62.5, steps: 1558
mean: -0.044287548138639284, total: -69.0, steps: 1558
mean: -0.04970948999354422, total: -77.0, steps: 1549
mean: -0.028888888888888888, total: -45.5, steps: 1575
mean: -0.036774193548387096, total: -57.0, steps: 1550
mean: -0.04116145500957243, total: -64.5, steps: 1567
mean: -0.036056158264199105, total: -56.5, steps: 1567
mean: -0.031609195402298854, total: -49.5, steps: 1566
mean: -0.052580645161290324, total: -81.5, steps: 1550
mean: -0.04831387808041505, total: -74.5, steps: 1542
mean: -0.040549169859514685, total: -63.5, steps: 1566
mean: -0.0398851308232291, total: -62.5, steps: 1567
mean: -0.05196901226597805, total: -80.5, steps: 1549
mean: -0.051000645577792124, total: -79.0, steps: 1549
mean: -0.03915275994865212, total: -61.0, steps: 1558
mean: -0.05051480051480051, total: -78.5, steps: 1554
mean: -0.04116145500957243, total: -64.5, steps: 1567
mean: -0.031928480204342274, total: -50.0, steps: 1566
mean: -0.043548387096774194, total: -67.5, steps: 1550
mean: -0.03530166880616174, total: -55.0, steps: 1558
mean: -0.03765156349712827, total: -59.0, steps: 1567
mean: -0.02839821314613912, total: -44.5, steps: 1567
mean: -0.032247765006385695, total: -50.5, steps: 1566
mean: -0.03873466752743705, total: -60.0, steps: 1549
mean: -0.03382259093809828, total: -53.0, steps: 1567
mean: -0.03692999357739242, total: -57.5, steps: 1557
mean: -0.040549169859514685, total: -63.5, steps: 1566
mean: -0.06136363636363636, total: -94.5, steps: 1540
mean: -0.05422853453841188, total: -84.0, steps: 1549
mean: -0.05035506778566817, total: -78.0, steps: 1549
mean: -0.024761904761904763, total: -39.0, steps: 1575
mean: -0.041399229781771504, total: -64.5, steps: 1558
mean: -0.03883183568677792, total: -60.5, steps: 1558
mean: -0.04236200256739409, total: -66.0, steps: 1558
mean: -0.03365079365079365, total: -53.0, steps: 1575
mean: -0.04589216944801027, total: -71.5, steps: 1558
mean: -0.029206349206349208, total: -46.0, steps: 1575
mean: -0.03431686978832585, total: -53.5, steps: 1559
mean: -0.03530166880616174, total: -55.0, steps: 1558
mean: -0.03498074454428755, total: -54.5, steps: 1558
mean: -0.029355456285896617, total: -46.0, steps: 1567
mean: -0.04236200256739409, total: -66.0, steps: 1558
mean: -0.036056158264199105, total: -56.5, steps: 1567
mean: -0.03350350989151244, total: -52.5, steps: 1567
mean: -0.04685494223363286, total: -73.0, steps: 1558
mean: -0.02761904761904762, total: -43.5, steps: 1575
mean: -0.029674537332482452, total: -46.5, steps: 1567
mean: -0.042756860242501596, total: -67.0, steps: 1567
mean: -0.048772609819121446, total: -75.5, steps: 1548
mean: -0.044838709677419354, total: -69.5, steps: 1550
mean: -0.04300385109114249, total: -67.0, steps: 1558
mean: -0.04967741935483871, total: -77.0, steps: 1550
mean: -0.029523809523809525, total: -46.5, steps: 1575
mean: -0.036797934151065206, total: -57.0, steps: 1549
mean: -0.04225806451612903, total: -65.5, steps: 1550
mean: -0.04105195638229634, total: -64.0, steps: 1559
mean: -0.03254626675175495, total: -51.0, steps: 1567
mean: -0.036717752234993614, total: -57.5, steps: 1566
mean: -0.05777921239509361, total: -89.5, steps: 1549
mean: -0.028735632183908046, total: -45.0, steps: 1566
mean: -0.050616482803374434, total: -78.0, steps: 1541
mean: -0.039769082745349585, total: -62.0, steps: 1559
mean: -0.056129032258064517, total: -87.0, steps: 1550
mean: -0.03465982028241335, total: -54.0, steps: 1558
mean: -0.05035506778566817, total: -78.0, steps: 1549
mean: -0.04201411161000641, total: -65.5, steps: 1559
mean: -0.04938670109748225, total: -76.5, steps: 1549
mean: -0.056451612903225805, total: -87.5, steps: 1550
mean: -0.032247765006385695, total: -50.5, steps: 1566
mean: -0.03465982028241335, total: -54.0, steps: 1558
mean: -0.05870967741935484, total: -91.0, steps: 1550
mean: -0.038141025641025644, total: -59.5, steps: 1560
mean: -0.04717586649550706, total: -73.5, steps: 1558
mean: -0.0389278876834716, total: -61.0, steps: 1567
mean: -0.0499675535366645, total: -77.0, steps: 1541
mean: -0.042682926829268296, total: -66.5, steps: 1558
mean: -0.03509891512444161, total: -55.0, steps: 1567
mean: -0.03382259093809828, total: -53.0, steps: 1567
mean: -0.029355456285896617, total: -46.0, steps: 1567
mean: -0.039473684210526314, total: -61.5, steps: 1558
mean: -0.03982016698779704, total: -62.0, steps: 1557
mean: -0.037970644543714106, total: -59.5, steps: 1567
mean: -0.03333333333333333, total: -52.5, steps: 1575
mean: -0.04709677419354839, total: -73.0, steps: 1550
mean: -0.03735632183908046, total: -58.5, steps: 1566
mean: -0.04271034039820167, total: -66.5, steps: 1557
mean: -0.036056158264199105, total: -56.5, steps: 1567
mean: -0.05483452303698897, total: -84.5, steps: 1541
mean: -0.04300385109114249, total: -67.0, steps: 1558
mean: -0.03190810465858328, total: -50.0, steps: 1567
mean: -0.05129032258064516, total: -79.5, steps: 1550
mean: -0.038510911424903725, total: -60.0, steps: 1558
mean: -0.04460847240051348, total: -69.5, steps: 1558
mean: -0.029036375239310786, total: -45.5, steps: 1567
mean: -0.033205619412515965, total: -52.0, steps: 1566
mean: -0.04396662387676508, total: -68.5, steps: 1558
mean: -0.03305519897304236, total: -51.5, steps: 1558
mean: -0.03982016698779704, total: -62.0, steps: 1557
mean: -0.033524904214559385, total: -52.5, steps: 1566
mean: -0.0351213282247765, total: -55.0, steps: 1566
mean: -0.05548387096774193, total: -86.0, steps: 1550
mean: -0.03401797175866496, total: -53.0, steps: 1558
mean: -0.05675146771037182, total: -87.0, steps: 1533
mean: -0.03594351732991014, total: -56.0, steps: 1558
mean: -0.04387096774193548, total: -68.0, steps: 1550
mean: -0.04303147077713552, total: -67.0, steps: 1557
mean: -0.04367373153500321, total: -68.0, steps: 1557
mean: -0.04032258064516129, total: -62.5, steps: 1550
mean: -0.04974326059050064, total: -77.5, steps: 1558
mean: -0.051000645577792124, total: -79.0, steps: 1549
mean: -0.05067785668173015, total: -78.5, steps: 1549
mean: -0.04621309370988447, total: -72.0, steps: 1558
mean: -0.03033205619412516, total: -47.5, steps: 1566
mean: -0.036056158264199105, total: -56.5, steps: 1567
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.055842479018721754, total: -86.5, steps: 1549
mean: -0.05326016785022595, total: -82.5, steps: 1549
mean: -0.036717752234993614, total: -57.5, steps: 1566
mean: -0.05038510911424904, total: -78.5, steps: 1558
mean: -0.05193548387096774, total: -80.5, steps: 1550
mean: -0.03626444159178434, total: -56.5, steps: 1558
mean: -0.04303147077713552, total: -67.0, steps: 1557
mean: -0.057456423499031635, total: -89.0, steps: 1549
mean: -0.040757381258023105, total: -63.5, steps: 1558
mean: -0.03690629011553274, total: -57.5, steps: 1558
mean: -0.05455132343447385, total: -84.5, steps: 1549
mean: -0.033697047496790755, total: -52.5, steps: 1558
mean: -0.040141297366730895, total: -62.5, steps: 1557
mean: -0.046481601032924466, total: -72.0, steps: 1549
mean: -0.04116145500957243, total: -64.5, steps: 1567
mean: -0.030970625798212005, total: -48.5, steps: 1566
mean: -0.03015873015873016, total: -47.5, steps: 1575
mean: -0.04396662387676508, total: -68.5, steps: 1558
mean: -0.04399486191393706, total: -68.5, steps: 1557
mean: -0.05422853453841188, total: -84.0, steps: 1549
mean: -0.03305519897304236, total: -51.5, steps: 1558
mean: -0.030312699425654115, total: -47.5, steps: 1567
mean: -0.0420410783055199, total: -65.5, steps: 1558
mean: -0.044287548138639284, total: -69.0, steps: 1558
mean: -0.05256327060350422, total: -81.0, steps: 1541
mean: -0.040757381258023105, total: -63.5, steps: 1558
mean: -0.03956604977664327, total: -62.0, steps: 1567
mean: -0.044287548138639284, total: -69.0, steps: 1558
mean: -0.04621309370988447, total: -72.0, steps: 1558
mean: -0.04516129032258064, total: -70.0, steps: 1550
mean: -0.04525032092426187, total: -70.5, steps: 1558
mean: -0.032886334610472544, total: -51.5, steps: 1566
mean: -0.0562015503875969, total: -87.0, steps: 1548
mean: -0.04032258064516129, total: -62.5, steps: 1550
mean: -0.05838709677419355, total: -90.5, steps: 1550
mean: -0.03915275994865212, total: -61.0, steps: 1558
mean: -0.0417201540436457, total: -65.0, steps: 1558
mean: -0.027936507936507936, total: -44.0, steps: 1575
mean: -0.03209242618741977, total: -50.0, steps: 1558
mean: -0.043645699614890884, total: -68.0, steps: 1558
mean: -0.0410783055198973, total: -64.0, steps: 1558
mean: -0.041399229781771504, total: -64.5, steps: 1558
mean: -0.04174694926140013, total: -65.0, steps: 1557
mean: -0.04258064516129032, total: -66.0, steps: 1550
mean: -0.044838709677419354, total: -69.5, steps: 1550
mean: -0.044287548138639284, total: -69.0, steps: 1558
mean: -0.045806451612903226, total: -71.0, steps: 1550
mean: -0.03465982028241335, total: -54.0, steps: 1558
mean: -0.04300385109114249, total: -67.0, steps: 1558
mean: -0.03774193548387097, total: -58.5, steps: 1550
mean: -0.027760051052967454, total: -43.5, steps: 1567
mean: -0.036375239310784936, total: -57.0, steps: 1567
mean: -0.046804389928986445, total: -72.5, steps: 1549
mean: -0.040757381258023105, total: -63.5, steps: 1558
mean: -0.04293092317624274, total: -66.5, steps: 1549
mean: -0.031269942565411615, total: -49.0, steps: 1567
mean: -0.02744097000638162, total: -43.0, steps: 1567
mean: -0.0417201540436457, total: -65.0, steps: 1558
mean: -0.03273427471116817, total: -51.0, steps: 1558
mean: -0.05202312138728324, total: -81.0, steps: 1557
mean: -0.04645161290322581, total: -72.0, steps: 1550
mean: -0.03477983407785577, total: -54.5, steps: 1567
mean: -0.04685494223363286, total: -73.0, steps: 1558
mean: -0.03048780487804878, total: -47.5, steps: 1558
mean: -0.04621309370988447, total: -72.0, steps: 1558
mean: -0.04393842206542656, total: -68.5, steps: 1559
mean: -0.029841269841269842, total: -47.0, steps: 1575
mean: -0.0410783055198973, total: -64.0, steps: 1558
mean: -0.05032258064516129, total: -78.0, steps: 1550
mean: -0.03465982028241335, total: -54.0, steps: 1558
mean: -0.05512321660181582, total: -85.0, steps: 1542
mean: -0.03765156349712827, total: -59.0, steps: 1567
mean: -0.039473684210526314, total: -61.5, steps: 1558
mean: -0.05487411233053583, total: -85.0, steps: 1549
mean: -0.04784842646114323, total: -74.5, steps: 1557
mean: -0.03477983407785577, total: -54.5, steps: 1567
mean: -0.02586206896551724, total: -40.5, steps: 1566
mean: -0.042682926829268296, total: -66.5, steps: 1558
mean: -0.04225806451612903, total: -65.5, steps: 1550
mean: -0.026984126984126985, total: -42.5, steps: 1575
mean: -0.03273427471116817, total: -51.0, steps: 1558
mean: -0.04236200256739409, total: -66.0, steps: 1558
mean: -0.04460847240051348, total: -69.5, steps: 1558
mean: -0.05129032258064516, total: -79.5, steps: 1550
mean: -0.03446075303126994, total: -54.0, steps: 1567
mean: -0.03979460847240052, total: -62.0, steps: 1558
mean: -0.03273427471116817, total: -51.0, steps: 1558
mean: -0.03982016698779704, total: -62.0, steps: 1557
mean: -0.0394990366088632, total: -61.5, steps: 1557
mean: -0.044287548138639284, total: -69.0, steps: 1558
mean: -0.04236200256739409, total: -66.0, steps: 1558
mean: -0.027760051052967454, total: -43.5, steps: 1567
mean: -0.03690629011553274, total: -57.5, steps: 1558
mean: -0.037970644543714106, total: -59.5, steps: 1567
mean: -0.04592164418754014, total: -71.5, steps: 1557
mean: -0.04941860465116279, total: -76.5, steps: 1548
mean: -0.051646223369916075, total: -80.0, steps: 1549
mean: -0.03880692751763951, total: -60.5, steps: 1559
mean: -0.03818998716302952, total: -59.5, steps: 1558
mean: -0.03735632183908046, total: -58.5, steps: 1566
mean: -0.05580645161290323, total: -86.5, steps: 1550
mean: -0.034482758620689655, total: -54.0, steps: 1566
mean: -0.03883183568677792, total: -60.5, steps: 1558
mean: -0.04431599229287091, total: -69.0, steps: 1557
mean: -0.046481601032924466, total: -72.0, steps: 1549
mean: -0.03688261706221937, total: -57.5, steps: 1559
mean: -0.04884318766066838, total: -76.0, steps: 1556
mean: -0.04396662387676508, total: -68.5, steps: 1558
mean: -0.025845564773452456, total: -40.5, steps: 1567
mean: -0.04300385109114249, total: -67.0, steps: 1558
mean: -0.0408423739629866, total: -64.0, steps: 1567
mean: -0.060378590078328985, total: -92.5, steps: 1532
mean: -0.03754813863928113, total: -58.5, steps: 1558
mean: -0.05193548387096774, total: -80.5, steps: 1550
mean: -0.04325371207230471, total: -67.0, steps: 1549
mean: -0.03741935483870968, total: -58.0, steps: 1550
mean: -0.06298955613577023, total: -96.5, steps: 1532
mean: -0.03384418901660281, total: -53.0, steps: 1566
mean: -0.037869062901155326, total: -59.0, steps: 1558
mean: -0.03318442884492661, total: -52.0, steps: 1567
mean: -0.03870967741935484, total: -60.0, steps: 1550
mean: -0.0467741935483871, total: -72.5, steps: 1550
mean: -0.032567049808429116, total: -51.0, steps: 1566
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.04046242774566474, total: -63.0, steps: 1557
mean: -0.036056158264199105, total: -56.5, steps: 1567
mean: -0.037227214377406934, total: -58.0, steps: 1558
mean: -0.03190810465858328, total: -50.0, steps: 1567
mean: -0.02937420178799489, total: -46.0, steps: 1566
mean: -0.04236200256739409, total: -66.0, steps: 1558
mean: -0.04749679075738126, total: -74.0, steps: 1558
mean: -0.033205619412515965, total: -52.0, steps: 1566
mean: -0.0389278876834716, total: -61.0, steps: 1567
mean: -0.04110468850353243, total: -64.0, steps: 1557
mean: -0.033524904214559385, total: -52.5, steps: 1566
mean: -0.03626444159178434, total: -56.5, steps: 1558
mean: -0.04236200256739409, total: -66.0, steps: 1558
mean: -0.040141297366730895, total: -62.5, steps: 1557
mean: -0.03818998716302952, total: -59.5, steps: 1558
mean: -0.05064516129032258, total: -78.5, steps: 1550
mean: -0.037251123956326265, total: -58.0, steps: 1557
mean: -0.036056158264199105, total: -56.5, steps: 1567
mean: -0.03979460847240052, total: -62.0, steps: 1558
mean: -0.027301587301587302, total: -43.0, steps: 1575
mean: -0.03384418901660281, total: -53.0, steps: 1566
mean: -0.04589216944801027, total: -71.5, steps: 1558
mean: -0.03639846743295019, total: -57.0, steps: 1566
mean: -0.04636835278858625, total: -71.5, steps: 1542
mean: -0.05196901226597805, total: -80.5, steps: 1549
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.04011553273427471, total: -62.5, steps: 1558
mean: -0.05227272727272727, total: -80.5, steps: 1540
mean: -0.035759897828863345, total: -56.0, steps: 1566
mean: -0.04300385109114249, total: -67.0, steps: 1558
mean: -0.02937420178799489, total: -46.0, steps: 1566
mean: -0.03818998716302952, total: -59.5, steps: 1558
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.05487411233053583, total: -85.0, steps: 1549
mean: -0.0420410783055199, total: -65.5, steps: 1558
mean: -0.05358295674628793, total: -83.0, steps: 1549
mean: -0.04592164418754014, total: -71.5, steps: 1557
mean: -0.053870967741935484, total: -83.5, steps: 1550
mean: -0.029036375239310786, total: -45.5, steps: 1567
mean: -0.03318442884492661, total: -52.0, steps: 1567
mean: -0.023809523809523808, total: -37.5, steps: 1575
mean: -0.03063178047223995, total: -48.0, steps: 1567
mean: -0.035759897828863345, total: -56.0, steps: 1566
mean: -0.03956604977664327, total: -62.0, steps: 1567
mean: -0.04174694926140013, total: -65.0, steps: 1557
mean: -0.05035506778566817, total: -78.0, steps: 1549
mean: -0.03177150192554557, total: -49.5, steps: 1558
mean: -0.03530166880616174, total: -55.0, steps: 1558
mean: -0.035759897828863345, total: -56.0, steps: 1566
mean: -0.047449967721110396, total: -73.5, steps: 1549
mean: -0.037994891443167304, total: -59.5, steps: 1566
mean: -0.038510911424903725, total: -60.0, steps: 1558
mean: -0.04043645699614891, total: -63.0, steps: 1558
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.04258064516129032, total: -66.0, steps: 1550
mean: -0.057133634602969656, total: -88.5, steps: 1549
mean: -0.05806451612903226, total: -90.0, steps: 1550
mean: -0.047419354838709675, total: -73.5, steps: 1550
mean: -0.04589216944801027, total: -71.5, steps: 1558
mean: -0.05966277561608301, total: -92.0, steps: 1542
mean: -0.03463758819756254, total: -54.0, steps: 1559
mean: -0.045571245186136075, total: -71.0, steps: 1558
mean: -0.026349206349206348, total: -41.5, steps: 1575
mean: -0.041639767591994836, total: -64.5, steps: 1549
mean: -0.036056158264199105, total: -56.5, steps: 1567
mean: -0.04129032258064516, total: -64.0, steps: 1550
mean: -0.03305519897304236, total: -51.5, steps: 1558
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.037037037037037035, total: -58.0, steps: 1566
mean: -0.043645699614890884, total: -68.0, steps: 1558
mean: -0.04043645699614891, total: -63.0, steps: 1558
mean: -0.04964308890330954, total: -76.5, steps: 1541
mean: -0.04525032092426187, total: -70.5, steps: 1558
mean: -0.03530166880616174, total: -55.0, steps: 1558
mean: -0.036056158264199105, total: -56.5, steps: 1567
mean: -0.0410783055198973, total: -64.0, steps: 1558
mean: -0.0487411233053583, total: -75.5, steps: 1549
mean: -0.046534017971758664, total: -72.5, steps: 1558
mean: -0.04046242774566474, total: -63.0, steps: 1557
mean: -0.03382259093809828, total: -53.0, steps: 1567
mean: -0.044287548138639284, total: -69.0, steps: 1558
mean: -0.035759897828863345, total: -56.0, steps: 1566
mean: -0.04551323434473854, total: -70.5, steps: 1549
mean: -0.046804389928986445, total: -72.5, steps: 1549
mean: -0.04271034039820167, total: -66.5, steps: 1557
mean: -0.044516129032258066, total: -69.0, steps: 1550
mean: -0.03384418901660281, total: -53.0, steps: 1566
mean: -0.03175112251443233, total: -49.5, steps: 1559
mean: -0.03158902361199745, total: -49.5, steps: 1567
mean: -0.043225806451612905, total: -67.0, steps: 1550
mean: -0.037013401403956606, total: -58.0, steps: 1567
mean: -0.03883183568677792, total: -60.5, steps: 1558
mean: -0.040783558124598586, total: -63.5, steps: 1557
mean: -0.04129032258064516, total: -64.0, steps: 1550
mean: -0.04717586649550706, total: -73.5, steps: 1558
mean: -0.04332477535301669, total: -67.5, steps: 1558
mean: -0.03690629011553274, total: -57.5, steps: 1558
mean: -0.03991060025542784, total: -62.5, steps: 1566
mean: -0.04548387096774194, total: -70.5, steps: 1550
mean: -0.044929396662387676, total: -70.0, steps: 1558
mean: -0.04290322580645161, total: -66.5, steps: 1550
mean: -0.03414167198468411, total: -53.5, steps: 1567
mean: -0.04621309370988447, total: -72.0, steps: 1558
mean: -0.0351213282247765, total: -55.0, steps: 1566
mean: -0.032227185705169116, total: -50.5, steps: 1567
mean: -0.03828972559029994, total: -60.0, steps: 1567
mean: -0.027760051052967454, total: -43.5, steps: 1567
mean: -0.0420410783055199, total: -65.5, steps: 1558
mean: -0.04749679075738126, total: -74.0, steps: 1558
mean: -0.0410783055198973, total: -64.0, steps: 1558
Player died.
Episode finished.
************************

kills: 0.0,
deaths: 1.0,
kill/death: 0.0
Results: (name: score)
AI: 0

Perfect: 1

Total score: -60.5
************************

Process finished with exit code 0
