D:\Programming\School\Hosei\ViZDoomOnSeminor\venv\Scripts\python.exe D:\Programming\School\Hosei\ViZDoomOnSeminor\examples\my_learning_deathmatch1.py
GPU available
Initializing doom...
Doom initialized.
Initializing new model
  0%|          | 0/800 [00:00<?, ?it/s]
Epoch #1
Saving the network weights to: ../models/sec_models/only_kill_death/model-0.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 2.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 0.64 minutes

Epoch #2
  0%|          | 2/800 [01:16<8:25:17, 37.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-1.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 4.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 1.27 minutes

Epoch #3
Saving the network weights to: ../models/sec_models/only_kill_death/model-2.pth
Results:
  total_reward: -16.0, step_mean: -0.01021059349074665
  total_deaths: 5.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 1.92 minutes

Epoch #4
  0%|          | 4/800 [02:33<8:30:55, 38.51s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-3.pth
Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 7.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 2.56 minutes

Epoch #5
Saving the network weights to: ../models/sec_models/only_kill_death/model-4.pth
Results:
  total_reward: -27.0, step_mean: -0.017419354838709676
  total_deaths: 10.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 3.20 minutes

Epoch #6
  1%|          | 6/800 [03:50<8:28:39, 38.44s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-5.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 12.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 3.84 minutes

Epoch #7
Saving the network weights to: ../models/sec_models/only_kill_death/model-6.pth
  1%|          | 7/800 [04:28<8:26:31, 38.32s/it]Results:
  total_reward: -30.0, step_mean: -0.01935483870967742
  total_deaths: 15.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 4.48 minutes

Epoch #8
Saving the network weights to: ../models/sec_models/only_kill_death/model-7.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 16.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 5.12 minutes

Epoch #9
  1%|          | 9/800 [05:46<8:30:42, 38.74s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-8.pth
Results:
  total_reward: -24.0, step_mean: -0.01540436456996149
  total_deaths: 18.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 5.78 minutes

Epoch #10
  1%|▏         | 10/800 [06:25<8:31:06, 38.82s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-9.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 19.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 6.43 minutes

Epoch #11
Saving the network weights to: ../models/sec_models/only_kill_death/model-10.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 20.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 7.09 minutes

Epoch #12
  2%|▏         | 12/800 [07:43<8:27:53, 38.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-11.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 22.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 7.72 minutes

Epoch #13
Saving the network weights to: ../models/sec_models/only_kill_death/model-12.pth
Results:
  total_reward: -11.0, step_mean: -0.0070242656449553
  total_deaths: 23.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 8.36 minutes

Epoch #14
  2%|▏         | 14/800 [08:58<8:20:37, 38.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-13.pth
Results:
  total_reward: -26.0, step_mean: -0.016698779704560053
  total_deaths: 25.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 8.98 minutes

Epoch #15
Saving the network weights to: ../models/sec_models/only_kill_death/model-14.pth
Results:
  total_reward: -41.0, step_mean: -0.026623376623376622
  total_deaths: 29.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 9.60 minutes

Epoch #16
  2%|▏         | 16/800 [10:14<8:16:45, 38.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-15.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 31.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 10.24 minutes

Epoch #17
Saving the network weights to: ../models/sec_models/only_kill_death/model-16.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 33.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 10.89 minutes

Epoch #18
  2%|▏         | 18/800 [11:33<8:25:49, 38.81s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-17.pth
Results:
  total_reward: -7.0, step_mean: -0.004469987228607918
  total_deaths: 34.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 11.55 minutes

Epoch #19
Saving the network weights to: ../models/sec_models/only_kill_death/model-18.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 35.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 12.23 minutes

Epoch #20
  2%|▎         | 20/800 [12:53<8:32:21, 39.41s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-19.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 37.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 12.89 minutes

Epoch #21
Saving the network weights to: ../models/sec_models/only_kill_death/model-20.pth
Results:
  total_reward: -25.0, step_mean: -0.016129032258064516
  total_deaths: 40.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 13.55 minutes

Epoch #22
  3%|▎         | 22/800 [14:13<8:36:22, 39.82s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-21.pth
Results:
  total_reward: -25.0, step_mean: -0.016129032258064516
  total_deaths: 43.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 14.23 minutes

Epoch #23
Saving the network weights to: ../models/sec_models/only_kill_death/model-22.pth
Results:
  total_reward: -11.0, step_mean: -0.0070242656449553
  total_deaths: 44.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 14.91 minutes

Epoch #24
  3%|▎         | 24/800 [15:35<8:41:18, 40.31s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-23.pth
Results:
  total_reward: -17.0, step_mean: -0.010911424903722721
  total_deaths: 46.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 15.59 minutes

Epoch #25
Saving the network weights to: ../models/sec_models/only_kill_death/model-24.pth
Results:
  total_reward: -29.0, step_mean: -0.01872175597159458
  total_deaths: 49.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 16.26 minutes

Epoch #26
  3%|▎         | 26/800 [16:57<8:44:45, 40.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-25.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 50.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 16.95 minutes

Epoch #27
Saving the network weights to: ../models/sec_models/only_kill_death/model-26.pth
Results:
  total_reward: -22.0, step_mean: -0.014193548387096775
  total_deaths: 53.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 17.63 minutes

Epoch #28
  4%|▎         | 28/800 [18:19<8:46:03, 40.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-27.pth
Results:
  total_reward: -14.0, step_mean: -0.008985879332477536
  total_deaths: 55.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 18.32 minutes

Epoch #29
Saving the network weights to: ../models/sec_models/only_kill_death/model-28.pth
Results:
  total_reward: -24.0, step_mean: -0.015483870967741935
  total_deaths: 58.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 18.99 minutes

Epoch #30
  4%|▍         | 30/800 [19:40<8:45:26, 40.94s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-29.pth
Results:
  total_reward: -15.0, step_mean: -0.009627727856225931
  total_deaths: 60.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 19.68 minutes

Epoch #31
Saving the network weights to: ../models/sec_models/only_kill_death/model-30.pth
Results:
  total_reward: -34.0, step_mean: -0.021836865767501604
  total_deaths: 62.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 20.37 minutes

Epoch #32
  4%|▍         | 32/800 [21:02<8:42:52, 40.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-31.pth
Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 64.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 21.04 minutes

Epoch #33
Saving the network weights to: ../models/sec_models/only_kill_death/model-32.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 66.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 21.73 minutes

Epoch #34
  4%|▍         | 34/800 [22:24<8:43:43, 41.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-33.pth
Results:
  total_reward: -25.0, step_mean: -0.016129032258064516
  total_deaths: 69.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 22.42 minutes

Epoch #35
  4%|▍         | 35/800 [23:06<8:46:16, 41.28s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-34.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 70.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 23.11 minutes

Epoch #36
Saving the network weights to: ../models/sec_models/only_kill_death/model-35.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 71.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 23.82 minutes

Epoch #37
  5%|▍         | 37/800 [24:30<8:49:27, 41.63s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-36.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 72.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 24.51 minutes

Epoch #38
Saving the network weights to: ../models/sec_models/only_kill_death/model-37.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 74.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 25.20 minutes

Epoch #39
  5%|▍         | 39/800 [25:53<8:47:12, 41.57s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-38.pth
Results:
  total_reward: -16.0, step_mean: -0.010269576379974325
  total_deaths: 76.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 25.89 minutes

Epoch #40
  5%|▌         | 40/800 [26:35<8:48:28, 41.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-39.pth
Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 78.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 26.60 minutes

Epoch #41
  5%|▌         | 41/800 [27:19<8:53:53, 42.20s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-40.pth
Results:
  total_reward: -42.0, step_mean: -0.027096774193548386
  total_deaths: 81.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 27.32 minutes

Epoch #42
  5%|▌         | 42/800 [28:02<8:58:50, 42.65s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-41.pth
Results:
  total_reward: -12.0, step_mean: -0.007662835249042145
  total_deaths: 82.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 28.05 minutes

Epoch #43
Saving the network weights to: ../models/sec_models/only_kill_death/model-42.pth
Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 84.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 28.76 minutes

Epoch #44
  6%|▌         | 44/800 [29:27<8:53:45, 42.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-43.pth
Results:
  total_reward: -42.0, step_mean: -0.027237354085603113
  total_deaths: 88.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 29.45 minutes

Epoch #45
Saving the network weights to: ../models/sec_models/only_kill_death/model-44.pth
Results:
  total_reward: -35.0, step_mean: -0.022464698331193838
  total_deaths: 90.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 30.16 minutes

Epoch #46
  6%|▌         | 46/800 [30:51<8:50:41, 42.23s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-45.pth
Results:
  total_reward: -41.0, step_mean: -0.026606099935107073
  total_deaths: 94.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 30.86 minutes

Epoch #47
  6%|▌         | 47/800 [31:33<8:49:30, 42.19s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-46.pth
Results:
  total_reward: -31.0, step_mean: -0.01989730423620026
  total_deaths: 96.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 31.56 minutes

Epoch #48
Saving the network weights to: ../models/sec_models/only_kill_death/model-47.pth
Results:
  total_reward: -22.0, step_mean: -0.014120667522464698
  total_deaths: 98.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 32.26 minutes

Epoch #49
  6%|▌         | 49/800 [32:57<8:47:13, 42.12s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-48.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 100.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 32.96 minutes

Epoch #50
  6%|▋         | 50/800 [33:40<8:47:05, 42.17s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-49.pth
Results:
  total_reward: -32.0, step_mean: -0.02053915275994865
  total_deaths: 102.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 33.67 minutes

Epoch #51
Saving the network weights to: ../models/sec_models/only_kill_death/model-50.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 103.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 34.37 minutes

Epoch #52
  6%|▋         | 52/800 [35:03<8:42:47, 41.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-51.pth
Results:
  total_reward: -24.0, step_mean: -0.015483870967741935
  total_deaths: 106.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 35.06 minutes

Epoch #53
Saving the network weights to: ../models/sec_models/only_kill_death/model-52.pth
Results:
  total_reward: -30.0, step_mean: -0.019267822736030827
  total_deaths: 108.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 35.76 minutes

Epoch #54
  7%|▋         | 54/800 [36:27<8:42:21, 42.01s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-53.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 109.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 36.46 minutes

Epoch #55
Saving the network weights to: ../models/sec_models/only_kill_death/model-54.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 110.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 37.14 minutes

Epoch #56
  7%|▋         | 56/800 [37:49<8:34:57, 41.53s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-55.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 112.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 37.83 minutes

Epoch #57
Saving the network weights to: ../models/sec_models/only_kill_death/model-56.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 113.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 38.60 minutes

Epoch #58
  7%|▋         | 58/800 [39:17<8:47:17, 42.64s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-57.pth
Results:
  total_reward: -25.0, step_mean: -0.01605651894669236
  total_deaths: 115.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 39.30 minutes

Epoch #59
Saving the network weights to: ../models/sec_models/only_kill_death/model-58.pth
Results:
  total_reward: -21.0, step_mean: -0.013401403956604978
  total_deaths: 116.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 40.02 minutes

Epoch #60
  8%|▊         | 60/800 [40:43<8:45:18, 42.59s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-59.pth
Results:
  total_reward: -35.0, step_mean: -0.022464698331193838
  total_deaths: 118.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 40.72 minutes

Epoch #61
Saving the network weights to: ../models/sec_models/only_kill_death/model-60.pth
Results:
  total_reward: -25.0, step_mean: -0.01605651894669236
  total_deaths: 120.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 41.42 minutes

Epoch #62
  8%|▊         | 62/800 [42:08<8:46:21, 42.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-61.pth
Results:
  total_reward: -29.0, step_mean: -0.018625561978163133
  total_deaths: 122.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 42.15 minutes

Epoch #63
Saving the network weights to: ../models/sec_models/only_kill_death/model-62.pth
Results:
  total_reward: -52.0, step_mean: -0.033766233766233764
  total_deaths: 126.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 42.85 minutes

Epoch #64
  8%|▊         | 64/800 [43:34<8:44:47, 42.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-63.pth
Results:
  total_reward: -25.0, step_mean: -0.015964240102171137
  total_deaths: 127.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 43.57 minutes

Epoch #65
Saving the network weights to: ../models/sec_models/only_kill_death/model-64.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 129.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 44.28 minutes

Epoch #66
  8%|▊         | 66/800 [44:59<8:41:29, 42.63s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-65.pth
Results:
  total_reward: -28.0, step_mean: -0.01798330122029544
  total_deaths: 131.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 44.99 minutes

Epoch #67
Saving the network weights to: ../models/sec_models/only_kill_death/model-66.pth
Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 133.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 45.70 minutes

Epoch #68
  8%|▊         | 68/800 [46:24<8:38:54, 42.53s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-67.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 135.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 46.40 minutes

Epoch #69
Saving the network weights to: ../models/sec_models/only_kill_death/model-68.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 137.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 47.11 minutes

Epoch #70
  9%|▉         | 70/800 [47:54<8:55:40, 44.03s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-69.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 138.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 47.90 minutes

Epoch #71
Saving the network weights to: ../models/sec_models/only_kill_death/model-70.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 140.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 48.71 minutes

Epoch #72
  9%|▉         | 72/800 [49:33<9:29:48, 46.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-71.pth
Results:
  total_reward: -28.0, step_mean: -0.018076178179470628
  total_deaths: 143.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 49.56 minutes

Epoch #73
Saving the network weights to: ../models/sec_models/only_kill_death/model-72.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 145.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 50.36 minutes

Epoch #74
  9%|▉         | 74/800 [51:11<9:41:48, 48.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-73.pth
Results:
  total_reward: -29.0, step_mean: -0.018625561978163133
  total_deaths: 147.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 51.19 minutes

Epoch #75
Saving the network weights to: ../models/sec_models/only_kill_death/model-74.pth
Results:
  total_reward: -12.0, step_mean: -0.007697241821680564
  total_deaths: 149.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 52.04 minutes

Epoch #76
 10%|▉         | 76/800 [52:53<9:59:59, 49.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-75.pth
Results:
  total_reward: -17.0, step_mean: -0.010911424903722721
  total_deaths: 151.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 52.90 minutes

Epoch #77
Saving the network weights to: ../models/sec_models/only_kill_death/model-76.pth
 10%|▉         | 77/800 [53:41<9:51:00, 49.05s/it]Results:
  total_reward: -44.0, step_mean: -0.028405422853453842
  total_deaths: 154.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 53.69 minutes

Epoch #78
Saving the network weights to: ../models/sec_models/only_kill_death/model-77.pth
Results:
  total_reward: -45.0, step_mean: -0.029051000645577793
  total_deaths: 157.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 54.53 minutes

Epoch #79
 10%|▉         | 79/800 [55:21<9:54:56, 49.51s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-78.pth
Results:
  total_reward: -14.0, step_mean: -0.008939974457215836
  total_deaths: 158.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 55.36 minutes

Epoch #80
Saving the network weights to: ../models/sec_models/only_kill_death/model-79.pth
Results:
  total_reward: -20.0, step_mean: -0.012763241863433313
  total_deaths: 159.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 56.20 minutes

Epoch #81
 10%|█         | 81/800 [57:02<9:58:54, 49.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-80.pth
Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 161.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 57.04 minutes

Epoch #82
Saving the network weights to: ../models/sec_models/only_kill_death/model-81.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 163.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 57.90 minutes

Epoch #83
 10%|█         | 83/800 [58:44<10:02:20, 50.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-82.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 165.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 58.74 minutes

Epoch #84
 10%|█         | 84/800 [59:27<9:35:53, 48.26s/it] Saving the network weights to: ../models/sec_models/only_kill_death/model-83.pth
Results:
  total_reward: -40.0, step_mean: -0.025673940949935817
  total_deaths: 167.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 59.46 minutes

Epoch #85
 11%|█         | 85/800 [1:00:11<9:18:32, 46.87s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-84.pth
Results:
  total_reward: -31.0, step_mean: -0.01989730423620026
  total_deaths: 169.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 60.18 minutes

Epoch #86
Saving the network weights to: ../models/sec_models/only_kill_death/model-85.pth
Results:
  total_reward: -9.0, step_mean: -0.005714285714285714
  total_deaths: 169.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 60.92 minutes

Epoch #87
 11%|█         | 87/800 [1:01:47<9:28:15, 47.82s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-86.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 170.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 61.79 minutes

Epoch #88
Saving the network weights to: ../models/sec_models/only_kill_death/model-87.pth
Results:
  total_reward: -7.0, step_mean: -0.004469987228607918
  total_deaths: 171.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 62.66 minutes

Epoch #89
 11%|█         | 89/800 [1:03:31<9:52:46, 50.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-88.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 173.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 63.52 minutes

Epoch #90
Saving the network weights to: ../models/sec_models/only_kill_death/model-89.pth
Results:
  total_reward: -11.0, step_mean: -0.0070242656449553
  total_deaths: 174.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 64.34 minutes

Epoch #91
 11%|█▏        | 91/800 [1:05:07<9:36:48, 48.81s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-90.pth
Results:
  total_reward: -23.0, step_mean: -0.014771997430956968
  total_deaths: 176.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 65.12 minutes

Epoch #92
Saving the network weights to: ../models/sec_models/only_kill_death/model-91.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 177.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 65.84 minutes

Epoch #93
 12%|█▏        | 93/800 [1:06:33<9:00:55, 45.91s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-92.pth
Results:
  total_reward: -31.0, step_mean: -0.019884541372674792
  total_deaths: 179.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 66.56 minutes

Epoch #94
Saving the network weights to: ../models/sec_models/only_kill_death/model-93.pth
Results:
  total_reward: -20.0, step_mean: -0.012763241863433313
  total_deaths: 180.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 67.26 minutes

Epoch #95
 12%|█▏        | 95/800 [1:07:57<8:35:58, 43.91s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-94.pth
Results:
  total_reward: -23.0, step_mean: -0.014753046824887749
  total_deaths: 182.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 67.96 minutes

Epoch #96
Saving the network weights to: ../models/sec_models/only_kill_death/model-95.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 184.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 68.65 minutes

Epoch #97
 12%|█▏        | 97/800 [1:09:20<8:18:30, 42.55s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-96.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 186.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 69.33 minutes

Epoch #98
Saving the network weights to: ../models/sec_models/only_kill_death/model-97.pth
Results:
  total_reward: -16.0, step_mean: -0.010269576379974325
  total_deaths: 188.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 70.05 minutes

Epoch #99
 12%|█▏        | 99/800 [1:10:45<8:18:36, 42.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-98.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 189.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 70.76 minutes

Epoch #100
Saving the network weights to: ../models/sec_models/only_kill_death/model-99.pth
Results:
  total_reward: -34.0, step_mean: -0.021822849807445442
  total_deaths: 191.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 71.46 minutes

Epoch #101
 13%|█▎        | 101/800 [1:12:08<8:09:55, 42.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-100.pth
Results:
  total_reward: -15.0, step_mean: -0.009621552277100705
  total_deaths: 193.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 72.14 minutes

Epoch #102
 13%|█▎        | 102/800 [1:12:50<8:07:58, 41.95s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-101.pth
Results:
  total_reward: -16.0, step_mean: -0.01021059349074665
  total_deaths: 194.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 72.84 minutes

Epoch #103
Saving the network weights to: ../models/sec_models/only_kill_death/model-102.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 195.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 73.53 minutes

Epoch #104
 13%|█▎        | 104/800 [1:14:13<8:03:18, 41.66s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-103.pth
Results:
  total_reward: -12.0, step_mean: -0.007657945118059987
  total_deaths: 196.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 74.22 minutes

Epoch #105
Saving the network weights to: ../models/sec_models/only_kill_death/model-104.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 197.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 74.91 minutes

Epoch #106
 13%|█▎        | 106/800 [1:15:36<8:01:44, 41.65s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-105.pth
Results:
  total_reward: -21.0, step_mean: -0.013478818998716302
  total_deaths: 199.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 75.61 minutes

Epoch #107
 13%|█▎        | 107/800 [1:16:18<8:02:41, 41.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-106.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 201.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 76.31 minutes

Epoch #108
Saving the network weights to: ../models/sec_models/only_kill_death/model-107.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 203.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 77.02 minutes

Epoch #109
 14%|█▎        | 109/800 [1:17:45<8:11:08, 42.65s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-108.pth
Results:
  total_reward: -32.0, step_mean: -0.02065848934796643
  total_deaths: 206.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 77.75 minutes

Epoch #110
 14%|█▍        | 110/800 [1:18:28<8:14:23, 42.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-109.pth
Results:
  total_reward: -30.0, step_mean: -0.01935483870967742
  total_deaths: 209.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 78.48 minutes

Epoch #111
Saving the network weights to: ../models/sec_models/only_kill_death/model-110.pth
Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 211.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 79.20 minutes

Epoch #112
 14%|█▍        | 112/800 [1:19:55<8:15:48, 43.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-111.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 212.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 79.93 minutes

Epoch #113
Saving the network weights to: ../models/sec_models/only_kill_death/model-112.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 214.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 80.67 minutes

Epoch #114
 14%|█▍        | 114/800 [1:21:21<8:11:47, 43.01s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-113.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 215.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 81.36 minutes

Epoch #115
Saving the network weights to: ../models/sec_models/only_kill_death/model-114.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 217.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 82.05 minutes

Epoch #116
 14%|█▍        | 116/800 [1:22:44<8:00:22, 42.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-115.pth
Results:
  total_reward: -25.0, step_mean: -0.016139444803098774
  total_deaths: 220.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 82.74 minutes

Epoch #117
Saving the network weights to: ../models/sec_models/only_kill_death/model-116.pth
Results:
  total_reward: -14.0, step_mean: -0.008939974457215836
  total_deaths: 221.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 83.45 minutes

Epoch #118
 15%|█▍        | 118/800 [1:24:09<7:59:57, 42.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-117.pth
Results:
  total_reward: -34.0, step_mean: -0.02194964493221433
  total_deaths: 224.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 84.15 minutes

Epoch #119
Saving the network weights to: ../models/sec_models/only_kill_death/model-118.pth
 15%|█▍        | 119/800 [1:24:50<7:56:42, 42.00s/it]Results:
  total_reward: -27.0, step_mean: -0.017341040462427744
  total_deaths: 226.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 84.84 minutes

Epoch #120
Saving the network weights to: ../models/sec_models/only_kill_death/model-119.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 227.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 85.52 minutes

Epoch #121
 15%|█▌        | 121/800 [1:26:12<7:48:38, 41.41s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-120.pth
Results:
  total_reward: -33.0, step_mean: -0.021181001283697046
  total_deaths: 229.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 86.20 minutes

Epoch #122
Saving the network weights to: ../models/sec_models/only_kill_death/model-121.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 230.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 86.90 minutes

Epoch #123
 15%|█▌        | 123/800 [1:27:34<7:46:53, 41.38s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-122.pth
Results:
  total_reward: -32.0, step_mean: -0.02052597819114817
  total_deaths: 232.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 87.58 minutes

Epoch #124
 16%|█▌        | 124/800 [1:28:16<7:46:48, 41.43s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-123.pth
Results:
  total_reward: -27.0, step_mean: -0.017430600387346677
  total_deaths: 235.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 88.28 minutes

Epoch #125
 16%|█▌        | 125/800 [1:28:57<7:44:47, 41.32s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-124.pth
Results:
  total_reward: -13.0, step_mean: -0.00834403080872914
  total_deaths: 237.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 88.96 minutes

Epoch #126
Saving the network weights to: ../models/sec_models/only_kill_death/model-125.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 238.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 89.66 minutes

Epoch #127
 16%|█▌        | 127/800 [1:30:21<7:46:43, 41.61s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-126.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 239.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 90.36 minutes

Epoch #128
Saving the network weights to: ../models/sec_models/only_kill_death/model-127.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 241.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 91.04 minutes

Epoch #129
 16%|█▌        | 129/800 [1:31:45<7:48:53, 41.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-128.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 242.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 91.76 minutes

Epoch #130
Saving the network weights to: ../models/sec_models/only_kill_death/model-129.pth
Results:
  total_reward: -24.0, step_mean: -0.01540436456996149
  total_deaths: 244.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 92.46 minutes

Epoch #131
 16%|█▋        | 131/800 [1:33:10<7:50:57, 42.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-130.pth
Results:
  total_reward: -18.0, step_mean: -0.01148691767708998
  total_deaths: 245.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 93.18 minutes

Epoch #132
Saving the network weights to: ../models/sec_models/only_kill_death/model-131.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 246.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 93.89 minutes

Epoch #133
 17%|█▋        | 133/800 [1:34:36<7:53:13, 42.57s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-132.pth
Results:
  total_reward: -9.0, step_mean: -0.005714285714285714
  total_deaths: 246.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 94.60 minutes

Epoch #134
Saving the network weights to: ../models/sec_models/only_kill_death/model-133.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 247.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 95.31 minutes

Epoch #135
 17%|█▋        | 135/800 [1:36:01<7:53:34, 42.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-134.pth
Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 249.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 96.03 minutes

Epoch #136
Saving the network weights to: ../models/sec_models/only_kill_death/model-135.pth
 17%|█▋        | 136/800 [1:36:44<7:50:40, 42.53s/it]Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 251.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 96.73 minutes

Epoch #137
Saving the network weights to: ../models/sec_models/only_kill_death/model-136.pth
Results:
  total_reward: -32.0, step_mean: -0.02053915275994865
  total_deaths: 253.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 97.44 minutes

Epoch #138
 17%|█▋        | 138/800 [1:38:07<7:43:07, 41.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-137.pth
Results:
  total_reward: -39.0, step_mean: -0.02529182879377432
  total_deaths: 257.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 98.12 minutes

Epoch #139
Saving the network weights to: ../models/sec_models/only_kill_death/model-138.pth
Results:
  total_reward: -21.0, step_mean: -0.013409961685823755
  total_deaths: 258.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 98.81 minutes

Epoch #140
 18%|█▊        | 140/800 [1:39:30<7:39:04, 41.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-139.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 260.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 99.50 minutes

Epoch #141
 18%|█▊        | 141/800 [1:40:11<7:36:31, 41.56s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-140.pth
Results:
  total_reward: -30.0, step_mean: -0.01924310455420141
  total_deaths: 262.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 100.19 minutes

Epoch #142
Saving the network weights to: ../models/sec_models/only_kill_death/model-141.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 264.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 100.88 minutes

Epoch #143
 18%|█▊        | 143/800 [1:41:35<7:39:22, 41.95s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-142.pth
Results:
  total_reward: -18.0, step_mean: -0.01148691767708998
  total_deaths: 265.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 101.60 minutes

Epoch #144
 18%|█▊        | 144/800 [1:42:18<7:39:55, 42.07s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-143.pth
Results:
  total_reward: -30.0, step_mean: -0.01935483870967742
  total_deaths: 268.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 102.30 minutes

Epoch #145
Saving the network weights to: ../models/sec_models/only_kill_death/model-144.pth
Results:
  total_reward: -16.0, step_mean: -0.010269576379974325
  total_deaths: 270.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 102.99 minutes

Epoch #146
 18%|█▊        | 146/800 [1:43:40<7:34:05, 41.66s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-145.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 272.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 103.68 minutes

Epoch #147
Saving the network weights to: ../models/sec_models/only_kill_death/model-146.pth
Results:
  total_reward: -23.0, step_mean: -0.014687100893997445
  total_deaths: 273.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 104.37 minutes

Epoch #148
 18%|█▊        | 148/800 [1:45:03<7:29:54, 41.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-147.pth
Results:
  total_reward: -48.0, step_mean: -0.030987734021949646
  total_deaths: 276.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 105.05 minutes

Epoch #149
Saving the network weights to: ../models/sec_models/only_kill_death/model-148.pth
Results:
  total_reward: -35.0, step_mean: -0.022464698331193838
  total_deaths: 278.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 105.73 minutes

Epoch #150
 19%|█▉        | 150/800 [1:46:24<7:24:14, 41.01s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-149.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 280.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 106.40 minutes

Epoch #151
Saving the network weights to: ../models/sec_models/only_kill_death/model-150.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 281.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 107.09 minutes

Epoch #152
 19%|█▉        | 152/800 [1:47:45<7:21:53, 40.92s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-151.pth
Results:
  total_reward: -21.0, step_mean: -0.013470173187940988
  total_deaths: 283.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 107.77 minutes

Epoch #153
Saving the network weights to: ../models/sec_models/only_kill_death/model-152.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 284.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 108.44 minutes

Epoch #154
 19%|█▉        | 154/800 [1:49:06<7:18:00, 40.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-153.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 286.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 109.11 minutes

Epoch #155
Saving the network weights to: ../models/sec_models/only_kill_death/model-154.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 288.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 109.80 minutes

Epoch #156
 20%|█▉        | 156/800 [1:50:29<7:20:05, 41.00s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-155.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 290.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 110.49 minutes

Epoch #157
Saving the network weights to: ../models/sec_models/only_kill_death/model-156.pth
Results:
  total_reward: -38.0, step_mean: -0.024531956100710135
  total_deaths: 293.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 111.17 minutes

Epoch #158
 20%|█▉        | 158/800 [1:51:51<7:18:36, 40.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-157.pth
Results:
  total_reward: -32.0, step_mean: -0.02053915275994865
  total_deaths: 295.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 111.85 minutes

Epoch #159
Saving the network weights to: ../models/sec_models/only_kill_death/model-158.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 296.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 112.53 minutes

Epoch #160
 20%|██        | 160/800 [1:53:12<7:15:06, 40.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-159.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 298.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 113.21 minutes

Epoch #161
Saving the network weights to: ../models/sec_models/only_kill_death/model-160.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 300.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 113.89 minutes

Epoch #162
 20%|██        | 162/800 [1:54:33<7:12:29, 40.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-161.pth
Results:
  total_reward: -30.0, step_mean: -0.01935483870967742
  total_deaths: 303.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 114.56 minutes

Epoch #163
 20%|██        | 163/800 [1:55:14<7:12:03, 40.70s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-162.pth
Results:
  total_reward: -11.0, step_mean: -0.007019783024888321
  total_deaths: 304.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 115.24 minutes

Epoch #164
Saving the network weights to: ../models/sec_models/only_kill_death/model-163.pth
Results:
  total_reward: -33.0, step_mean: -0.02119460500963391
  total_deaths: 306.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 115.92 minutes

Epoch #165
 21%|██        | 165/800 [1:56:36<7:11:47, 40.80s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-164.pth
Results:
  total_reward: -34.0, step_mean: -0.021822849807445442
  total_deaths: 308.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 116.60 minutes

Epoch #166
Saving the network weights to: ../models/sec_models/only_kill_death/model-165.pth
Results:
  total_reward: -31.0, step_mean: -0.019884541372674792
  total_deaths: 310.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 117.29 minutes

Epoch #167
 21%|██        | 167/800 [1:57:58<7:13:32, 41.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-166.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 311.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 117.98 minutes

Epoch #168
Saving the network weights to: ../models/sec_models/only_kill_death/model-167.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 313.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 118.67 minutes

Epoch #169
 21%|██        | 169/800 [1:59:20<7:10:51, 40.97s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-168.pth
Results:
  total_reward: -44.0, step_mean: -0.028405422853453842
  total_deaths: 316.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 119.35 minutes

Epoch #170
 21%|██▏       | 170/800 [2:00:01<7:10:02, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-169.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 318.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 120.03 minutes

Epoch #171
Saving the network weights to: ../models/sec_models/only_kill_death/model-170.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 320.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 120.70 minutes

Epoch #172
 22%|██▏       | 172/800 [2:01:22<7:06:36, 40.76s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-171.pth
Results:
  total_reward: -24.0, step_mean: -0.01532567049808429
  total_deaths: 321.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 121.38 minutes

Epoch #173
Saving the network weights to: ../models/sec_models/only_kill_death/model-172.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 323.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 122.06 minutes

Epoch #174
 22%|██▏       | 174/800 [2:02:44<7:04:36, 40.70s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-173.pth
Results:
  total_reward: -27.0, step_mean: -0.017419354838709676
  total_deaths: 326.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 122.74 minutes

Epoch #175
Saving the network weights to: ../models/sec_models/only_kill_death/model-174.pth
Results:
  total_reward: -27.0, step_mean: -0.01727447216890595
  total_deaths: 328.0
  frag: 0.0
  death: 2.0
  global_step: 1563
Total elapsed time: 123.42 minutes

Epoch #176
 22%|██▏       | 176/800 [2:04:06<7:04:08, 40.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-175.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 330.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 124.10 minutes

Epoch #177
Saving the network weights to: ../models/sec_models/only_kill_death/model-176.pth
Results:
  total_reward: -38.0, step_mean: -0.02454780361757106
  total_deaths: 333.0
  frag: 0.0
  death: 3.0
  global_step: 1548
Total elapsed time: 124.77 minutes

Epoch #178
 22%|██▏       | 178/800 [2:05:28<7:06:37, 41.15s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-177.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 334.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 125.48 minutes

Epoch #179
Saving the network weights to: ../models/sec_models/only_kill_death/model-178.pth
Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 336.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 126.18 minutes

Epoch #180
 22%|██▎       | 180/800 [2:06:50<7:04:36, 41.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-179.pth
Results:
  total_reward: -21.0, step_mean: -0.013548387096774193
  total_deaths: 339.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 126.85 minutes

Epoch #181
Saving the network weights to: ../models/sec_models/only_kill_death/model-180.pth
Results:
  total_reward: -12.0, step_mean: -0.007643312101910828
  total_deaths: 340.0
  frag: 0.0
  death: 1.0
  global_step: 1570
Total elapsed time: 127.54 minutes

Epoch #182
 23%|██▎       | 182/800 [2:08:13<7:03:01, 41.07s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-181.pth
Results:
  total_reward: 14.0, step_mean: 0.008939974457215836
  total_deaths: 341.0
  frag: 2.0
  death: 1.0
  global_step: 1566
Total elapsed time: 128.22 minutes

Epoch #183
Saving the network weights to: ../models/sec_models/only_kill_death/model-182.pth
Results:
  total_reward: -11.0, step_mean: -0.0070242656449553
  total_deaths: 342.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 128.92 minutes

Epoch #184
 23%|██▎       | 184/800 [2:09:36<7:04:50, 41.38s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-183.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 344.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 129.61 minutes

Epoch #185
Saving the network weights to: ../models/sec_models/only_kill_death/model-184.pth
Results:
  total_reward: -23.0, step_mean: -0.014771997430956968
  total_deaths: 346.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 130.30 minutes

Epoch #186
 23%|██▎       | 186/800 [2:10:58<7:01:46, 41.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-185.pth
Results:
  total_reward: -51.0, step_mean: -0.033116883116883114
  total_deaths: 350.0
  frag: 0.0
  death: 4.0
  global_step: 1540
Total elapsed time: 130.98 minutes

Epoch #187
 23%|██▎       | 187/800 [2:11:40<7:02:32, 41.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-186.pth
Results:
  total_reward: -10.0, step_mean: -0.006418485237483954
  total_deaths: 352.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 131.67 minutes

Epoch #188
Saving the network weights to: ../models/sec_models/only_kill_death/model-187.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 353.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 132.37 minutes

Epoch #189
 24%|██▎       | 189/800 [2:13:02<6:59:37, 41.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-188.pth
Results:
  total_reward: -22.0, step_mean: -0.014120667522464698
  total_deaths: 355.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 133.05 minutes

Epoch #190
Saving the network weights to: ../models/sec_models/only_kill_death/model-189.pth
Results:
  total_reward: -21.0, step_mean: -0.01348747591522158
  total_deaths: 357.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 133.74 minutes

Epoch #191
 24%|██▍       | 191/800 [2:14:25<6:58:13, 41.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-190.pth
Results:
  total_reward: -33.0, step_mean: -0.021181001283697046
  total_deaths: 359.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 134.42 minutes

Epoch #192
Saving the network weights to: ../models/sec_models/only_kill_death/model-191.pth
Results:
  total_reward: -20.0, step_mean: -0.012828736369467608
  total_deaths: 361.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 135.10 minutes

Epoch #193
 24%|██▍       | 193/800 [2:15:47<6:57:16, 41.25s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-192.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 362.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 135.80 minutes

Epoch #194
 24%|██▍       | 194/800 [2:16:28<6:56:31, 41.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-193.pth
Results:
  total_reward: -16.0, step_mean: -0.01021059349074665
  total_deaths: 363.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 136.48 minutes

Epoch #195
 24%|██▍       | 195/800 [2:17:09<6:55:10, 41.17s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-194.pth
Results:
  total_reward: -3.0, step_mean: -0.001924310455420141
  total_deaths: 365.0
  frag: 1.0
  death: 2.0
  global_step: 1559
Total elapsed time: 137.17 minutes

Epoch #196
 24%|██▍       | 196/800 [2:17:53<7:01:44, 41.90s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-195.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 367.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 137.89 minutes

Epoch #197
Saving the network weights to: ../models/sec_models/only_kill_death/model-196.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 368.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 138.66 minutes

Epoch #198
 25%|██▍       | 198/800 [2:19:24<7:18:51, 43.74s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-197.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 369.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 139.41 minutes

Epoch #199
Saving the network weights to: ../models/sec_models/only_kill_death/model-198.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 370.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 140.15 minutes

Epoch #200
 25%|██▌       | 200/800 [2:20:51<7:13:34, 43.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-199.pth
Results:
  total_reward: -7.0, step_mean: -0.004467134652201659
  total_deaths: 371.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 140.85 minutes

Epoch #201
Saving the network weights to: ../models/sec_models/only_kill_death/model-200.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 372.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 141.57 minutes

Epoch #202
 25%|██▌       | 202/800 [2:22:16<7:06:52, 42.83s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-201.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 374.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 142.27 minutes

Epoch #203
Saving the network weights to: ../models/sec_models/only_kill_death/model-202.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 375.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 142.96 minutes

Epoch #204
 26%|██▌       | 204/800 [2:23:40<7:02:45, 42.56s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-203.pth
Results:
  total_reward: -21.0, step_mean: -0.01348747591522158
  total_deaths: 377.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 143.67 minutes

Epoch #205
Saving the network weights to: ../models/sec_models/only_kill_death/model-204.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 379.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 144.39 minutes

Epoch #206
 26%|██▌       | 206/800 [2:25:10<7:16:36, 44.10s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-205.pth
Results:
  total_reward: -23.0, step_mean: -0.014677728142948309
  total_deaths: 380.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 145.18 minutes

Epoch #207
Saving the network weights to: ../models/sec_models/only_kill_death/model-206.pth
Results:
  total_reward: -29.0, step_mean: -0.018625561978163133
  total_deaths: 382.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 146.11 minutes

Epoch #208
 26%|██▌       | 208/800 [2:27:03<8:17:52, 50.46s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-207.pth
Results:
  total_reward: -21.0, step_mean: -0.013409961685823755
  total_deaths: 383.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 147.06 minutes

Epoch #209
 26%|██▌       | 209/800 [2:27:55<8:19:56, 50.76s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-208.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 384.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 147.92 minutes

Epoch #210
Saving the network weights to: ../models/sec_models/only_kill_death/model-209.pth
Results:
  total_reward: -31.0, step_mean: -0.01991008349389852
  total_deaths: 386.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 148.69 minutes

Epoch #211
 26%|██▋       | 211/800 [2:29:25<7:48:51, 47.76s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-210.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 387.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 149.42 minutes

Epoch #212
Saving the network weights to: ../models/sec_models/only_kill_death/model-211.pth
Results:
  total_reward: -28.0, step_mean: -0.018076178179470628
  total_deaths: 390.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 150.14 minutes

Epoch #213
 27%|██▋       | 213/800 [2:30:50<7:20:46, 45.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-212.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 392.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 150.84 minutes

Epoch #214
Saving the network weights to: ../models/sec_models/only_kill_death/model-213.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 394.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 151.54 minutes

Epoch #215
 27%|██▋       | 215/800 [2:32:14<7:03:28, 43.43s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-214.pth
Results:
  total_reward: -22.0, step_mean: -0.014039566049776643
  total_deaths: 395.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 152.24 minutes

Epoch #216
Saving the network weights to: ../models/sec_models/only_kill_death/model-215.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 396.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 152.96 minutes

Epoch #217
 27%|██▋       | 217/800 [2:33:39<6:56:36, 42.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-216.pth
Results:
  total_reward: -13.0, step_mean: -0.00834403080872914
  total_deaths: 398.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 153.65 minutes

Epoch #218
Saving the network weights to: ../models/sec_models/only_kill_death/model-217.pth
Results:
  total_reward: -7.0, step_mean: -0.0044444444444444444
  total_deaths: 398.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 154.35 minutes

Epoch #219
 27%|██▋       | 219/800 [2:35:03<6:50:55, 42.44s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-218.pth
Results:
  total_reward: -17.0, step_mean: -0.010911424903722721
  total_deaths: 400.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 155.05 minutes

Epoch #220
Saving the network weights to: ../models/sec_models/only_kill_death/model-219.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 402.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 155.76 minutes

Epoch #221
 28%|██▊       | 221/800 [2:36:26<6:45:28, 42.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-220.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 404.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 156.44 minutes

Epoch #222
Saving the network weights to: ../models/sec_models/only_kill_death/model-221.pth
Results:
  total_reward: -18.0, step_mean: -0.01148691767708998
  total_deaths: 405.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 157.13 minutes

Epoch #223
 28%|██▊       | 223/800 [2:37:50<6:45:40, 42.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-222.pth
Results:
  total_reward: -33.0, step_mean: -0.02130406714009038
  total_deaths: 408.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 157.85 minutes

Epoch #224
Saving the network weights to: ../models/sec_models/only_kill_death/model-223.pth
Results:
  total_reward: -27.0, step_mean: -0.01731879409878127
  total_deaths: 410.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 158.54 minutes

Epoch #225
 28%|██▊       | 225/800 [2:39:13<6:39:50, 41.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-224.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 412.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 159.22 minutes

Epoch #226
Saving the network weights to: ../models/sec_models/only_kill_death/model-225.pth
 28%|██▊       | 226/800 [2:39:54<6:38:17, 41.63s/it]Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 413.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 159.92 minutes

Epoch #227
 28%|██▊       | 227/800 [2:40:35<6:35:17, 41.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-226.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 415.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 160.60 minutes

Epoch #228
Saving the network weights to: ../models/sec_models/only_kill_death/model-227.pth
Results:
  total_reward: -9.0, step_mean: -0.005747126436781609
  total_deaths: 416.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 161.29 minutes

Epoch #229
 29%|██▊       | 229/800 [2:41:58<6:33:26, 41.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-228.pth
Results:
  total_reward: -13.0, step_mean: -0.00834403080872914
  total_deaths: 418.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 161.97 minutes

Epoch #230
Saving the network weights to: ../models/sec_models/only_kill_death/model-229.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 419.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 162.66 minutes

Epoch #231
 29%|██▉       | 231/800 [2:43:21<6:32:21, 41.37s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-230.pth
Results:
  total_reward: -21.0, step_mean: -0.013401403956604978
  total_deaths: 420.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 163.35 minutes

Epoch #232
Saving the network weights to: ../models/sec_models/only_kill_death/model-231.pth
Results:
  total_reward: -27.0, step_mean: -0.017430600387346677
  total_deaths: 423.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 164.03 minutes

Epoch #233
 29%|██▉       | 233/800 [2:44:43<6:29:59, 41.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-232.pth
Results:
  total_reward: -11.0, step_mean: -0.007019783024888321
  total_deaths: 424.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 164.72 minutes

Epoch #234
 29%|██▉       | 234/800 [2:45:24<6:28:46, 41.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-233.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 425.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 165.41 minutes

Epoch #235
Saving the network weights to: ../models/sec_models/only_kill_death/model-234.pth
Results:
  total_reward: -6.0, step_mean: -0.0038095238095238095
  total_deaths: 425.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 166.10 minutes

Epoch #236
 30%|██▉       | 236/800 [2:46:46<6:26:33, 41.12s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-235.pth
Results:
  total_reward: -28.0, step_mean: -0.01798330122029544
  total_deaths: 427.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 166.78 minutes

Epoch #237
Saving the network weights to: ../models/sec_models/only_kill_death/model-236.pth
Results:
  total_reward: -20.0, step_mean: -0.012828736369467608
  total_deaths: 429.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 167.47 minutes

Epoch #238
 30%|██▉       | 238/800 [2:48:10<6:28:16, 41.45s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-237.pth
Results:
  total_reward: -25.0, step_mean: -0.01605651894669236
  total_deaths: 431.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 168.17 minutes

Epoch #239
Saving the network weights to: ../models/sec_models/only_kill_death/model-238.pth
Results:
  total_reward: -25.0, step_mean: -0.015964240102171137
  total_deaths: 432.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 168.88 minutes

Epoch #240
 30%|███       | 240/800 [2:49:33<6:28:17, 41.60s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-239.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 434.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 169.56 minutes

Epoch #241
Saving the network weights to: ../models/sec_models/only_kill_death/model-240.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 435.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 170.25 minutes

Epoch #242
 30%|███       | 242/800 [2:50:58<6:31:34, 42.10s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-241.pth
Results:
  total_reward: -34.0, step_mean: -0.021822849807445442
  total_deaths: 437.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 170.98 minutes

Epoch #243
Saving the network weights to: ../models/sec_models/only_kill_death/model-242.pth
Results:
  total_reward: -17.0, step_mean: -0.010911424903722721
  total_deaths: 439.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 171.71 minutes

Epoch #244
 30%|███       | 244/800 [2:52:25<6:34:52, 42.61s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-243.pth
Results:
  total_reward: -23.0, step_mean: -0.014838709677419355
  total_deaths: 442.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 172.42 minutes

Epoch #245
Saving the network weights to: ../models/sec_models/only_kill_death/model-244.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 443.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 173.12 minutes

Epoch #246
 31%|███       | 246/800 [2:53:48<6:29:15, 42.16s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-245.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 445.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 173.81 minutes

Epoch #247
Saving the network weights to: ../models/sec_models/only_kill_death/model-246.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 446.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 174.50 minutes

Epoch #248
 31%|███       | 248/800 [2:55:11<6:24:29, 41.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-247.pth
Results:
  total_reward: -45.0, step_mean: -0.029201817001946788
  total_deaths: 450.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 175.19 minutes

Epoch #249
Saving the network weights to: ../models/sec_models/only_kill_death/model-248.pth
Results:
  total_reward: -20.0, step_mean: -0.012763241863433313
  total_deaths: 451.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 175.88 minutes

Epoch #250
 31%|███▏      | 250/800 [2:56:34<6:20:12, 41.48s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-249.pth
Results:
  total_reward: -12.0, step_mean: -0.007702182284980745
  total_deaths: 453.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 176.57 minutes

Epoch #251
Saving the network weights to: ../models/sec_models/only_kill_death/model-250.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 455.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 177.25 minutes

Epoch #252
 32%|███▏      | 252/800 [2:57:56<6:16:30, 41.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-251.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 457.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 177.93 minutes

Epoch #253
Saving the network weights to: ../models/sec_models/only_kill_death/model-252.pth
Results:
  total_reward: -16.0, step_mean: -0.010329244673983214
  total_deaths: 460.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 178.82 minutes

Epoch #254
 32%|███▏      | 254/800 [2:59:33<6:47:11, 44.75s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-253.pth
Results:
  total_reward: -12.0, step_mean: -0.007702182284980745
  total_deaths: 462.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 179.56 minutes

Epoch #255
Saving the network weights to: ../models/sec_models/only_kill_death/model-254.pth
Results:
  total_reward: -19.0, step_mean: -0.012258064516129033
  total_deaths: 465.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 180.30 minutes

Epoch #256
 32%|███▏      | 256/800 [3:01:08<7:00:10, 46.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-255.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 466.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 181.14 minutes

Epoch #257
Saving the network weights to: ../models/sec_models/only_kill_death/model-256.pth
Results:
  total_reward: -18.0, step_mean: -0.01148691767708998
  total_deaths: 467.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 181.87 minutes

Epoch #258
 32%|███▏      | 258/800 [3:02:39<6:57:25, 46.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-257.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 469.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 182.66 minutes

Epoch #259
 32%|███▏      | 259/800 [3:03:28<7:02:25, 46.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-258.pth
Results:
  total_reward: -38.0, step_mean: -0.024531956100710135
  total_deaths: 472.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 183.47 minutes

Epoch #260
Saving the network weights to: ../models/sec_models/only_kill_death/model-259.pth
Results:
  total_reward: -28.0, step_mean: -0.01806451612903226
  total_deaths: 475.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 184.24 minutes

Epoch #261
 33%|███▎      | 261/800 [3:04:59<6:55:26, 46.25s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-260.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 477.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 184.99 minutes

Epoch #262
Saving the network weights to: ../models/sec_models/only_kill_death/model-261.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 479.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 185.72 minutes

Epoch #263
 33%|███▎      | 263/800 [3:06:26<6:42:08, 44.93s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-262.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 481.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 186.45 minutes

Epoch #264
Saving the network weights to: ../models/sec_models/only_kill_death/model-263.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 482.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 187.20 minutes

Epoch #265
 33%|███▎      | 265/800 [3:07:53<6:31:50, 43.95s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-264.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 483.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 187.89 minutes

Epoch #266
Saving the network weights to: ../models/sec_models/only_kill_death/model-265.pth
Results:
  total_reward: -17.0, step_mean: -0.010911424903722721
  total_deaths: 485.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 188.58 minutes

Epoch #267
 33%|███▎      | 267/800 [3:09:16<6:19:34, 42.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-266.pth
Results:
  total_reward: -26.0, step_mean: -0.016774193548387096
  total_deaths: 488.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 189.28 minutes

Epoch #268
 34%|███▎      | 268/800 [3:09:58<6:17:03, 42.52s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-267.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 490.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 189.98 minutes

Epoch #269
Saving the network weights to: ../models/sec_models/only_kill_death/model-268.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 492.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 190.67 minutes

Epoch #270
 34%|███▍      | 270/800 [3:11:22<6:12:43, 42.19s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-269.pth
Results:
  total_reward: -22.0, step_mean: -0.014120667522464698
  total_deaths: 494.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 191.37 minutes

Epoch #271
Saving the network weights to: ../models/sec_models/only_kill_death/model-270.pth
Results:
  total_reward: -7.0, step_mean: -0.0044444444444444444
  total_deaths: 494.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 192.09 minutes

Epoch #272
 34%|███▍      | 272/800 [3:12:47<6:11:58, 42.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-271.pth
Results:
  total_reward: -19.0, step_mean: -0.012218649517684888
  total_deaths: 497.0
  frag: 0.0
  death: 3.0
  global_step: 1555
Total elapsed time: 192.79 minutes

Epoch #273
Saving the network weights to: ../models/sec_models/only_kill_death/model-272.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 498.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 193.49 minutes

Epoch #274
 34%|███▍      | 274/800 [3:14:11<6:08:57, 42.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-273.pth
Results:
  total_reward: -22.0, step_mean: -0.014120667522464698
  total_deaths: 500.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 194.18 minutes

Epoch #275
 34%|███▍      | 275/800 [3:14:53<6:09:34, 42.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-274.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 502.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 194.89 minutes

Epoch #276
Saving the network weights to: ../models/sec_models/only_kill_death/model-275.pth
 34%|███▍      | 276/800 [3:15:36<6:10:14, 42.39s/it]Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 504.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 195.61 minutes

Epoch #277
Saving the network weights to: ../models/sec_models/only_kill_death/model-276.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 505.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 196.31 minutes

Epoch #278
 35%|███▍      | 278/800 [3:17:01<6:08:38, 42.37s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-277.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 506.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 197.02 minutes

Epoch #279
Saving the network weights to: ../models/sec_models/only_kill_death/model-278.pth
Results:
  total_reward: -7.0, step_mean: -0.004469987228607918
  total_deaths: 507.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 197.73 minutes

Epoch #280
 35%|███▌      | 280/800 [3:18:25<6:07:22, 42.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-279.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 509.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 198.43 minutes

Epoch #281
 35%|███▌      | 281/800 [3:19:08<6:07:33, 42.49s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-280.pth
Results:
  total_reward: -11.0, step_mean: -0.007060333761232349
  total_deaths: 511.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 199.14 minutes

Epoch #282
Saving the network weights to: ../models/sec_models/only_kill_death/model-281.pth
Results:
  total_reward: -10.0, step_mean: -0.006385696040868455
  total_deaths: 512.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 199.82 minutes

Epoch #283
 35%|███▌      | 283/800 [3:20:29<5:56:51, 41.41s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-282.pth
Results:
  total_reward: -11.0, step_mean: -0.007060333761232349
  total_deaths: 514.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 200.49 minutes

Epoch #284
Saving the network weights to: ../models/sec_models/only_kill_death/model-283.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 515.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 201.17 minutes

Epoch #285
 36%|███▌      | 285/800 [3:21:50<5:51:00, 40.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-284.pth
Results:
  total_reward: -17.0, step_mean: -0.010911424903722721
  total_deaths: 517.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 201.84 minutes

Epoch #286
Saving the network weights to: ../models/sec_models/only_kill_death/model-285.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 518.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 202.51 minutes

Epoch #287
 36%|███▌      | 287/800 [3:23:10<5:46:56, 40.58s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-286.pth
Results:
  total_reward: -6.0, step_mean: -0.0038289725590299937
  total_deaths: 519.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 203.18 minutes

Epoch #288
Saving the network weights to: ../models/sec_models/only_kill_death/model-287.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 520.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 203.86 minutes

Epoch #289
 36%|███▌      | 289/800 [3:24:31<5:45:05, 40.52s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-288.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 522.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 204.53 minutes

Epoch #290
Saving the network weights to: ../models/sec_models/only_kill_death/model-289.pth
Results:
  total_reward: -18.0, step_mean: -0.01148691767708998
  total_deaths: 523.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 205.22 minutes

Epoch #291
 36%|███▋      | 291/800 [3:25:54<5:46:06, 40.80s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-290.pth
Results:
  total_reward: -21.0, step_mean: -0.013401403956604978
  total_deaths: 524.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 205.90 minutes

Epoch #292
 36%|███▋      | 292/800 [3:26:34<5:44:24, 40.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-291.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 526.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 206.58 minutes

Epoch #293
 37%|███▋      | 293/800 [3:27:15<5:43:27, 40.65s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-292.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 528.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 207.25 minutes

Epoch #294
Saving the network weights to: ../models/sec_models/only_kill_death/model-293.pth
Results:
  total_reward: -22.0, step_mean: -0.014039566049776643
  total_deaths: 529.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 207.93 minutes

Epoch #295
 37%|███▋      | 295/800 [3:28:35<5:40:34, 40.47s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-294.pth
Results:
  total_reward: -31.0, step_mean: -0.020012911555842477
  total_deaths: 532.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 208.60 minutes

Epoch #296
 37%|███▋      | 296/800 [3:29:16<5:39:40, 40.44s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-295.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 533.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 209.27 minutes

Epoch #297
Saving the network weights to: ../models/sec_models/only_kill_death/model-296.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 534.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 209.97 minutes

Epoch #298
 37%|███▋      | 298/800 [3:30:38<5:40:59, 40.76s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-297.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 536.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 210.64 minutes

Epoch #299
Saving the network weights to: ../models/sec_models/only_kill_death/model-298.pth
 37%|███▋      | 299/800 [3:31:18<5:39:09, 40.62s/it]Results:
  total_reward: -28.0, step_mean: -0.018076178179470628
  total_deaths: 539.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 211.31 minutes

Epoch #300
Saving the network weights to: ../models/sec_models/only_kill_death/model-299.pth
Results:
  total_reward: -31.0, step_mean: -0.020012911555842477
  total_deaths: 542.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 211.99 minutes

Epoch #301
 38%|███▊      | 301/800 [3:32:40<5:37:34, 40.59s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-300.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 543.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 212.67 minutes

Epoch #302
Saving the network weights to: ../models/sec_models/only_kill_death/model-301.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 544.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 213.37 minutes

Epoch #303
 38%|███▊      | 303/800 [3:34:01<5:36:18, 40.60s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-302.pth
Results:
  total_reward: -11.0, step_mean: -0.0070242656449553
  total_deaths: 545.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 214.03 minutes

Epoch #304
Saving the network weights to: ../models/sec_models/only_kill_death/model-303.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 546.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 214.69 minutes

Epoch #305
 38%|███▊      | 305/800 [3:35:21<5:32:15, 40.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-304.pth
Results:
  total_reward: -24.0, step_mean: -0.015414258188824663
  total_deaths: 548.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 215.36 minutes

Epoch #306
Saving the network weights to: ../models/sec_models/only_kill_death/model-305.pth
 38%|███▊      | 306/800 [3:36:02<5:33:05, 40.46s/it]Results:
  total_reward: -24.0, step_mean: -0.01540436456996149
  total_deaths: 550.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 216.04 minutes

Epoch #307
 38%|███▊      | 307/800 [3:36:42<5:31:48, 40.38s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-306.pth
Results:
  total_reward: -20.0, step_mean: -0.012763241863433313
  total_deaths: 551.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 216.71 minutes

Epoch #308
 38%|███▊      | 308/800 [3:37:22<5:29:48, 40.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-307.pth
Results:
  total_reward: -30.0, step_mean: -0.01924310455420141
  total_deaths: 553.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 217.37 minutes

Epoch #309
Saving the network weights to: ../models/sec_models/only_kill_death/model-308.pth
Results:
  total_reward: -42.0, step_mean: -0.027237354085603113
  total_deaths: 557.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 218.03 minutes

Epoch #310
 39%|███▉      | 310/800 [3:38:42<5:27:24, 40.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-309.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 559.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 218.70 minutes

Epoch #311
Saving the network weights to: ../models/sec_models/only_kill_death/model-310.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 561.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 219.37 minutes

Epoch #312
 39%|███▉      | 312/800 [3:40:02<5:25:35, 40.03s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-311.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 563.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 220.04 minutes

Epoch #313
Saving the network weights to: ../models/sec_models/only_kill_death/model-312.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 565.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 220.70 minutes

Epoch #314
 39%|███▉      | 314/800 [3:41:22<5:24:08, 40.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-313.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 567.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 221.37 minutes

Epoch #315
Saving the network weights to: ../models/sec_models/only_kill_death/model-314.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 569.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 222.04 minutes

Epoch #316
 40%|███▉      | 316/800 [3:42:42<5:22:48, 40.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-315.pth
Results:
  total_reward: -16.0, step_mean: -0.010269576379974325
  total_deaths: 571.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 222.71 minutes

Epoch #317
 40%|███▉      | 317/800 [3:43:21<5:21:06, 39.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-316.pth
Results:
  total_reward: -52.0, step_mean: -0.03374432186891629
  total_deaths: 575.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 223.37 minutes

Epoch #318
 40%|███▉      | 318/800 [3:44:02<5:21:19, 40.00s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-317.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 576.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 224.04 minutes

Epoch #319
Saving the network weights to: ../models/sec_models/only_kill_death/model-318.pth
Results:
  total_reward: -9.0, step_mean: -0.005747126436781609
  total_deaths: 577.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 224.71 minutes

Epoch #320
 40%|████      | 320/800 [3:45:22<5:19:57, 39.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-319.pth
Results:
  total_reward: -27.0, step_mean: -0.017419354838709676
  total_deaths: 580.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 225.37 minutes

Epoch #321
Saving the network weights to: ../models/sec_models/only_kill_death/model-320.pth
Results:
  total_reward: -22.0, step_mean: -0.014120667522464698
  total_deaths: 582.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 226.03 minutes

Epoch #322
 40%|████      | 322/800 [3:46:41<5:18:19, 39.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-321.pth
Results:
  total_reward: -11.0, step_mean: -0.007019783024888321
  total_deaths: 583.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 226.70 minutes

Epoch #323
 40%|████      | 323/800 [3:47:22<5:18:52, 40.11s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-322.pth
Results:
  total_reward: -30.0, step_mean: -0.019267822736030827
  total_deaths: 585.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 227.37 minutes

Epoch #324
Saving the network weights to: ../models/sec_models/only_kill_death/model-323.pth
Results:
  total_reward: -9.0, step_mean: -0.005806451612903226
  total_deaths: 588.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 228.04 minutes

Epoch #325
 41%|████      | 325/800 [3:48:43<5:18:29, 40.23s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-324.pth
Results:
  total_reward: -4.0, step_mean: -0.0025673940949935813
  total_deaths: 590.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 228.72 minutes

Epoch #326
 41%|████      | 326/800 [3:49:23<5:17:28, 40.19s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-325.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 591.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 229.39 minutes

Epoch #327
Saving the network weights to: ../models/sec_models/only_kill_death/model-326.pth
Results:
  total_reward: -4.0, step_mean: -0.0025396825396825397
  total_deaths: 591.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 230.07 minutes

Epoch #328
 41%|████      | 328/800 [3:50:44<5:17:42, 40.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-327.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 592.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 230.74 minutes

Epoch #329
 41%|████      | 329/800 [3:51:23<5:15:04, 40.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-328.pth
Results:
  total_reward: -26.0, step_mean: -0.016785022595222725
  total_deaths: 595.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 231.40 minutes

Epoch #330
Saving the network weights to: ../models/sec_models/only_kill_death/model-329.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 597.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 232.06 minutes

Epoch #331
 41%|████▏     | 331/800 [3:52:43<5:12:58, 40.04s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-330.pth
Results:
  total_reward: -37.0, step_mean: -0.023886378308586184
  total_deaths: 600.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 232.73 minutes

Epoch #332
Saving the network weights to: ../models/sec_models/only_kill_death/model-331.pth
Results:
  total_reward: -14.0, step_mean: -0.008980115458627326
  total_deaths: 602.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 233.41 minutes

Epoch #333
 42%|████▏     | 333/800 [3:54:04<5:13:15, 40.25s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-332.pth
Results:
  total_reward: -24.0, step_mean: -0.015483870967741935
  total_deaths: 605.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 234.08 minutes

Epoch #334
Saving the network weights to: ../models/sec_models/only_kill_death/model-333.pth
Results:
  total_reward: -22.0, step_mean: -0.014120667522464698
  total_deaths: 607.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 234.74 minutes

Epoch #335
 42%|████▏     | 335/800 [3:55:24<5:10:27, 40.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-334.pth
Results:
  total_reward: -11.0, step_mean: -0.0070242656449553
  total_deaths: 608.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 235.41 minutes

Epoch #336
Saving the network weights to: ../models/sec_models/only_kill_death/model-335.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 609.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 236.08 minutes

Epoch #337
 42%|████▏     | 337/800 [3:56:44<5:09:38, 40.13s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-336.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 610.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 236.75 minutes

Epoch #338
Saving the network weights to: ../models/sec_models/only_kill_death/model-337.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 611.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 237.44 minutes

Epoch #339
 42%|████▏     | 339/800 [3:58:06<5:10:41, 40.44s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-338.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 613.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 238.11 minutes

Epoch #340
Saving the network weights to: ../models/sec_models/only_kill_death/model-339.pth
Results:
  total_reward: -14.0, step_mean: -0.008985879332477536
  total_deaths: 615.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 238.78 minutes

Epoch #341
 43%|████▎     | 341/800 [3:59:26<5:08:21, 40.31s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-340.pth
Results:
  total_reward: -4.0, step_mean: -0.0025526483726866626
  total_deaths: 616.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 239.45 minutes

Epoch #342
 43%|████▎     | 342/800 [4:00:07<5:09:34, 40.56s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-341.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 618.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 240.13 minutes

Epoch #343
 43%|████▎     | 343/800 [4:00:48<5:07:41, 40.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-342.pth
Results:
  total_reward: -39.0, step_mean: -0.025161290322580646
  total_deaths: 621.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 240.80 minutes

Epoch #344
Saving the network weights to: ../models/sec_models/only_kill_death/model-343.pth
Results:
  total_reward: -11.0, step_mean: -0.007060333761232349
  total_deaths: 623.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 241.48 minutes

Epoch #345
 43%|████▎     | 345/800 [4:02:10<5:09:26, 40.81s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-344.pth
Results:
  total_reward: -9.0, step_mean: -0.005714285714285714
  total_deaths: 623.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 242.17 minutes

Epoch #346
 43%|████▎     | 346/800 [4:02:51<5:10:23, 41.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-345.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 624.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 242.86 minutes

Epoch #347
Saving the network weights to: ../models/sec_models/only_kill_death/model-346.pth
Results:
  total_reward: -43.0, step_mean: -0.02775984506132989
  total_deaths: 627.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 243.55 minutes

Epoch #348
 44%|████▎     | 348/800 [4:04:13<5:07:55, 40.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-347.pth
Results:
  total_reward: -28.0, step_mean: -0.01796023091725465
  total_deaths: 629.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 244.22 minutes

Epoch #349
 44%|████▎     | 349/800 [4:04:55<5:09:13, 41.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-348.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 630.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 244.92 minutes

Epoch #350
Saving the network weights to: ../models/sec_models/only_kill_death/model-349.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 631.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 245.61 minutes

Epoch #351
 44%|████▍     | 351/800 [4:06:17<5:08:52, 41.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-350.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 632.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 246.30 minutes

Epoch #352
Saving the network weights to: ../models/sec_models/only_kill_death/model-351.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 633.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 246.98 minutes

Epoch #353
 44%|████▍     | 353/800 [4:07:40<5:07:36, 41.29s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-352.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 634.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 247.67 minutes

Epoch #354
Saving the network weights to: ../models/sec_models/only_kill_death/model-353.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 635.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 248.36 minutes

Epoch #355
 44%|████▍     | 355/800 [4:09:03<5:06:52, 41.38s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-354.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 636.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 249.05 minutes

Epoch #356
Saving the network weights to: ../models/sec_models/only_kill_death/model-355.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 638.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 249.73 minutes

Epoch #357
 45%|████▍     | 357/800 [4:10:25<5:05:35, 41.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-356.pth
Results:
  total_reward: -45.0, step_mean: -0.029051000645577793
  total_deaths: 641.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 250.43 minutes

Epoch #358
Saving the network weights to: ../models/sec_models/only_kill_death/model-357.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 643.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 251.10 minutes

Epoch #359
 45%|████▍     | 359/800 [4:11:45<4:58:24, 40.60s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-358.pth
Results:
  total_reward: -8.0, step_mean: -0.005131494547787043
  total_deaths: 645.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 251.76 minutes

Epoch #360
Saving the network weights to: ../models/sec_models/only_kill_death/model-359.pth
Results:
  total_reward: 9.0, step_mean: 0.00574345883854499
  total_deaths: 646.0
  frag: 2.0
  death: 1.0
  global_step: 1567
Total elapsed time: 252.41 minutes

Epoch #361
 45%|████▌     | 361/800 [4:13:04<4:52:33, 39.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-360.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 647.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 253.07 minutes

Epoch #362
 45%|████▌     | 362/800 [4:13:43<4:50:36, 39.81s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-361.pth
Results:
  total_reward: -28.0, step_mean: -0.018076178179470628
  total_deaths: 650.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 253.73 minutes

Epoch #363
Saving the network weights to: ../models/sec_models/only_kill_death/model-362.pth
Results:
  total_reward: -29.0, step_mean: -0.01870967741935484
  total_deaths: 653.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 254.38 minutes

Epoch #364
 46%|████▌     | 364/800 [4:15:03<4:49:57, 39.90s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-363.pth
Results:
  total_reward: -4.0, step_mean: -0.002554278416347382
  total_deaths: 654.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 255.06 minutes

Epoch #365
Saving the network weights to: ../models/sec_models/only_kill_death/model-364.pth
 46%|████▌     | 365/800 [4:15:44<4:51:59, 40.27s/it]Results:
  total_reward: -5.0, step_mean: -0.003190810465858328
  total_deaths: 655.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 255.74 minutes

Epoch #366
Saving the network weights to: ../models/sec_models/only_kill_death/model-365.pth
Results:
  total_reward: -21.0, step_mean: -0.013409961685823755
  total_deaths: 656.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 256.43 minutes

Epoch #367
 46%|████▌     | 367/800 [4:17:06<4:53:58, 40.74s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-366.pth
Results:
  total_reward: -20.0, step_mean: -0.012763241863433313
  total_deaths: 657.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 257.12 minutes

Epoch #368
Saving the network weights to: ../models/sec_models/only_kill_death/model-367.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 659.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 257.82 minutes

Epoch #369
 46%|████▌     | 369/800 [4:18:30<4:56:45, 41.31s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-368.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 660.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 258.51 minutes

Epoch #370
Saving the network weights to: ../models/sec_models/only_kill_death/model-369.pth
Results:
  total_reward: -16.0, step_mean: -0.01021059349074665
  total_deaths: 661.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 259.22 minutes

Epoch #371
 46%|████▋     | 371/800 [4:19:53<4:55:27, 41.32s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-370.pth
Results:
  total_reward: -41.0, step_mean: -0.026451612903225806
  total_deaths: 664.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 259.90 minutes

Epoch #372
Saving the network weights to: ../models/sec_models/only_kill_death/model-371.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 665.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 260.58 minutes

Epoch #373
 47%|████▋     | 373/800 [4:21:16<4:53:42, 41.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-372.pth
Results:
  total_reward: -32.0, step_mean: -0.0206052801030264
  total_deaths: 668.0
  frag: 0.0
  death: 3.0
  global_step: 1553
Total elapsed time: 261.27 minutes

Epoch #374
Saving the network weights to: ../models/sec_models/only_kill_death/model-373.pth
Results:
  total_reward: -10.0, step_mean: -0.006418485237483954
  total_deaths: 670.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 261.96 minutes

Epoch #375
 47%|████▋     | 375/800 [4:22:39<4:53:22, 41.42s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-374.pth
Results:
  total_reward: -4.0, step_mean: -0.0025396825396825397
  total_deaths: 670.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 262.65 minutes

Epoch #376
Saving the network weights to: ../models/sec_models/only_kill_death/model-375.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 671.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 263.34 minutes

Epoch #377
 47%|████▋     | 377/800 [4:24:01<4:50:11, 41.16s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-376.pth
Results:
  total_reward: -14.0, step_mean: -0.008939974457215836
  total_deaths: 672.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 264.02 minutes

Epoch #378
Saving the network weights to: ../models/sec_models/only_kill_death/model-377.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 673.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 264.70 minutes

Epoch #379
 47%|████▋     | 379/800 [4:25:22<4:46:42, 40.86s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-378.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 674.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 265.37 minutes

Epoch #380
Saving the network weights to: ../models/sec_models/only_kill_death/model-379.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 676.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 266.05 minutes

Epoch #381
 48%|████▊     | 381/800 [4:26:41<4:40:53, 40.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-380.pth
Results:
  total_reward: -30.0, step_mean: -0.019267822736030827
  total_deaths: 678.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 266.70 minutes

Epoch #382
Saving the network weights to: ../models/sec_models/only_kill_death/model-381.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 679.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 267.35 minutes

Epoch #383
 48%|████▊     | 383/800 [4:28:00<4:35:36, 39.66s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-382.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 681.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 268.00 minutes

Epoch #384
Saving the network weights to: ../models/sec_models/only_kill_death/model-383.pth
Results:
  total_reward: -26.0, step_mean: -0.016785022595222725
  total_deaths: 684.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 268.65 minutes

Epoch #385
 48%|████▊     | 385/800 [4:29:17<4:31:29, 39.25s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-384.pth
Results:
  total_reward: -6.0, step_mean: -0.0038289725590299937
  total_deaths: 685.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 269.30 minutes

Epoch #386
Saving the network weights to: ../models/sec_models/only_kill_death/model-385.pth
Results:
  total_reward: -27.0, step_mean: -0.017419354838709676
  total_deaths: 688.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 269.94 minutes

Epoch #387
 48%|████▊     | 387/800 [4:30:36<4:29:56, 39.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-386.pth
Results:
  total_reward: -10.0, step_mean: -0.006381620931716656
  total_deaths: 689.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 270.60 minutes

Epoch #388
Saving the network weights to: ../models/sec_models/only_kill_death/model-387.pth
Results:
  total_reward: -37.0, step_mean: -0.023886378308586184
  total_deaths: 692.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 271.25 minutes

Epoch #389
 49%|████▊     | 389/800 [4:31:54<4:28:58, 39.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-388.pth
Results:
  total_reward: -9.0, step_mean: -0.005714285714285714
  total_deaths: 692.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 271.91 minutes

Epoch #390
Saving the network weights to: ../models/sec_models/only_kill_death/model-389.pth
Results:
  total_reward: -30.0, step_mean: -0.019367333763718526
  total_deaths: 695.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 272.57 minutes

Epoch #391
 49%|████▉     | 391/800 [4:33:14<4:30:24, 39.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-390.pth
Results:
  total_reward: -22.0, step_mean: -0.014039566049776643
  total_deaths: 696.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 273.24 minutes

Epoch #392
Saving the network weights to: ../models/sec_models/only_kill_death/model-391.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 698.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 273.91 minutes

Epoch #393
 49%|████▉     | 393/800 [4:34:34<4:31:10, 39.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-392.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 699.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 274.58 minutes

Epoch #394
 49%|████▉     | 394/800 [4:35:14<4:30:28, 39.97s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-393.pth
Results:
  total_reward: -25.0, step_mean: -0.016139444803098774
  total_deaths: 702.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 275.25 minutes

Epoch #395
Saving the network weights to: ../models/sec_models/only_kill_death/model-394.pth
Results:
  total_reward: -8.0, step_mean: -0.005105296745373325
  total_deaths: 703.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 275.92 minutes

Epoch #396
 50%|████▉     | 396/800 [4:36:35<4:29:51, 40.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-395.pth
Results:
  total_reward: -14.0, step_mean: -0.008939974457215836
  total_deaths: 704.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 276.59 minutes

Epoch #397
Saving the network weights to: ../models/sec_models/only_kill_death/model-396.pth
Results:
  total_reward: -35.0, step_mean: -0.0224791265253693
  total_deaths: 706.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 277.26 minutes

Epoch #398
 50%|████▉     | 398/800 [4:37:56<4:30:44, 40.41s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-397.pth
Results:
  total_reward: -32.0, step_mean: -0.02053915275994865
  total_deaths: 708.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 277.94 minutes

Epoch #399
 50%|████▉     | 399/800 [4:38:36<4:29:54, 40.38s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-398.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 710.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 278.61 minutes

Epoch #400
 50%|█████     | 400/800 [4:39:17<4:29:14, 40.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-399.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 711.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 279.29 minutes

Epoch #401
Saving the network weights to: ../models/sec_models/only_kill_death/model-400.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 713.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 279.96 minutes

Epoch #402
 50%|█████     | 402/800 [4:40:40<4:32:46, 41.12s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-401.pth
Results:
  total_reward: -32.0, step_mean: -0.02064516129032258
  total_deaths: 716.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 280.67 minutes

Epoch #403
 50%|█████     | 403/800 [4:41:22<4:34:13, 41.45s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-402.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 717.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 281.38 minutes

Epoch #404
Saving the network weights to: ../models/sec_models/only_kill_death/model-403.pth
Results:
  total_reward: -26.0, step_mean: -0.016698779704560053
  total_deaths: 719.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 282.06 minutes

Epoch #405
 51%|█████     | 405/800 [4:42:45<4:33:05, 41.48s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-404.pth
Results:
  total_reward: -11.0, step_mean: -0.006984126984126984
  total_deaths: 719.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 282.76 minutes

Epoch #406
 51%|█████     | 406/800 [4:43:26<4:31:42, 41.38s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-405.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 721.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 283.45 minutes

Epoch #407
Saving the network weights to: ../models/sec_models/only_kill_death/model-406.pth
Results:
  total_reward: -16.0, step_mean: -0.01021059349074665
  total_deaths: 722.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 284.14 minutes

Epoch #408
 51%|█████     | 408/800 [4:44:49<4:29:28, 41.25s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-407.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 723.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 284.82 minutes

Epoch #409
Saving the network weights to: ../models/sec_models/only_kill_death/model-408.pth
Results:
  total_reward: -23.0, step_mean: -0.014677728142948309
  total_deaths: 724.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 285.52 minutes

Epoch #410
 51%|█████▏    | 410/800 [4:46:13<4:31:20, 41.75s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-409.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 725.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 286.22 minutes

Epoch #411
Saving the network weights to: ../models/sec_models/only_kill_death/model-410.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 726.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 286.93 minutes

Epoch #412
 52%|█████▏    | 412/800 [4:47:37<4:31:28, 41.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-411.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 728.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 287.63 minutes

Epoch #413
 52%|█████▏    | 413/800 [4:48:20<4:31:58, 42.17s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-412.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 729.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 288.34 minutes

Epoch #414
 52%|█████▏    | 414/800 [4:49:02<4:30:20, 42.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-413.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 730.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 289.04 minutes

Epoch #415
Saving the network weights to: ../models/sec_models/only_kill_death/model-414.pth
Results:
  total_reward: -22.0, step_mean: -0.014111610006414367
  total_deaths: 732.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 289.74 minutes

Epoch #416
 52%|█████▏    | 416/800 [4:50:26<4:29:24, 42.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-415.pth
Results:
  total_reward: -30.0, step_mean: -0.019367333763718526
  total_deaths: 735.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 290.44 minutes

Epoch #417
 52%|█████▏    | 417/800 [4:51:08<4:28:37, 42.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-416.pth
Results:
  total_reward: -11.0, step_mean: -0.0070242656449553
  total_deaths: 736.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 291.14 minutes

Epoch #418
Saving the network weights to: ../models/sec_models/only_kill_death/model-417.pth
Results:
  total_reward: -45.0, step_mean: -0.029051000645577793
  total_deaths: 739.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 291.84 minutes

Epoch #419
 52%|█████▏    | 419/800 [4:52:32<4:27:45, 42.17s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-418.pth
Results:
  total_reward: -9.0, step_mean: -0.00574345883854499
  total_deaths: 740.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 292.55 minutes

Epoch #420
 52%|█████▎    | 420/800 [4:53:15<4:27:01, 42.16s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-419.pth
Results:
  total_reward: -17.0, step_mean: -0.010911424903722721
  total_deaths: 742.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 293.25 minutes

Epoch #421
 53%|█████▎    | 421/800 [4:53:56<4:25:46, 42.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-420.pth
Results:
  total_reward: -9.0, step_mean: -0.005776636713735558
  total_deaths: 744.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 293.95 minutes

Epoch #422
 53%|█████▎    | 422/800 [4:54:39<4:26:26, 42.29s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-421.pth
Results:
  total_reward: -18.0, step_mean: -0.011553273427471117
  total_deaths: 746.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 294.66 minutes

Epoch #423
Saving the network weights to: ../models/sec_models/only_kill_death/model-422.pth
Results:
  total_reward: -10.0, step_mean: -0.006418485237483954
  total_deaths: 748.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 295.37 minutes

Epoch #424
 53%|█████▎    | 424/800 [4:56:02<4:22:13, 41.84s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-423.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 750.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 296.05 minutes

Epoch #425
 53%|█████▎    | 425/800 [4:56:43<4:18:44, 41.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-424.pth
Results:
  total_reward: -38.0, step_mean: -0.024531956100710135
  total_deaths: 753.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 296.72 minutes

Epoch #426
Saving the network weights to: ../models/sec_models/only_kill_death/model-425.pth
Results:
  total_reward: -10.0, step_mean: -0.006349206349206349
  total_deaths: 753.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 297.41 minutes

Epoch #427
 53%|█████▎    | 427/800 [4:58:06<4:17:28, 41.42s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-426.pth
Results:
  total_reward: -5.0, step_mean: -0.0031746031746031746
  total_deaths: 753.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 298.10 minutes

Epoch #428
Saving the network weights to: ../models/sec_models/only_kill_death/model-427.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 754.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 298.78 minutes

Epoch #429
 54%|█████▎    | 429/800 [4:59:27<4:13:36, 41.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-428.pth
Results:
  total_reward: -26.0, step_mean: -0.016698779704560053
  total_deaths: 756.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 299.46 minutes

Epoch #430
Saving the network weights to: ../models/sec_models/only_kill_death/model-429.pth
Results:
  total_reward: -4.0, step_mean: -0.0025396825396825397
  total_deaths: 756.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 300.14 minutes

Epoch #431
 54%|█████▍    | 431/800 [5:00:48<4:11:20, 40.87s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-430.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 758.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 300.82 minutes

Epoch #432
Saving the network weights to: ../models/sec_models/only_kill_death/model-431.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 760.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 301.53 minutes

Epoch #433
 54%|█████▍    | 433/800 [5:02:14<4:15:34, 41.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-432.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 761.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 302.24 minutes

Epoch #434
Saving the network weights to: ../models/sec_models/only_kill_death/model-433.pth
Results:
  total_reward: -20.0, step_mean: -0.012763241863433313
  total_deaths: 762.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 302.95 minutes

Epoch #435
 54%|█████▍    | 435/800 [5:03:39<4:17:25, 42.32s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-434.pth
Results:
  total_reward: -10.0, step_mean: -0.006385696040868455
  total_deaths: 763.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 303.67 minutes

Epoch #436
Saving the network weights to: ../models/sec_models/only_kill_death/model-435.pth
Results:
  total_reward: -20.0, step_mean: -0.012763241863433313
  total_deaths: 764.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 304.37 minutes

Epoch #437
 55%|█████▍    | 437/800 [5:05:03<4:13:48, 41.95s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-436.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 765.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 305.06 minutes

Epoch #438
Saving the network weights to: ../models/sec_models/only_kill_death/model-437.pth
Results:
  total_reward: -40.0, step_mean: -0.025823111684958037
  total_deaths: 768.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 305.74 minutes

Epoch #439
 55%|█████▍    | 439/800 [5:06:25<4:09:45, 41.51s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-438.pth
Results:
  total_reward: -39.0, step_mean: -0.025161290322580646
  total_deaths: 771.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 306.42 minutes

Epoch #440
Saving the network weights to: ../models/sec_models/only_kill_death/model-439.pth
Results:
  total_reward: -20.0, step_mean: -0.012763241863433313
  total_deaths: 772.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 307.11 minutes

Epoch #441
 55%|█████▌    | 441/800 [5:07:47<4:07:47, 41.41s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-440.pth
Results:
  total_reward: -12.0, step_mean: -0.007657945118059987
  total_deaths: 773.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 307.80 minutes

Epoch #442
Saving the network weights to: ../models/sec_models/only_kill_death/model-441.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 775.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 308.49 minutes

Epoch #443
 55%|█████▌    | 443/800 [5:09:10<4:06:40, 41.46s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-442.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 777.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 309.18 minutes

Epoch #444
 56%|█████▌    | 444/800 [5:09:51<4:04:59, 41.29s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-443.pth
Results:
  total_reward: -17.0, step_mean: -0.010911424903722721
  total_deaths: 779.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 309.86 minutes

Epoch #445
Saving the network weights to: ../models/sec_models/only_kill_death/model-444.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 781.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 310.54 minutes

Epoch #446
 56%|█████▌    | 446/800 [5:11:13<4:02:56, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-445.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 782.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 311.23 minutes

Epoch #447
Saving the network weights to: ../models/sec_models/only_kill_death/model-446.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 783.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 311.91 minutes

Epoch #448
 56%|█████▌    | 448/800 [5:12:35<4:01:04, 41.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-447.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 785.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 312.60 minutes

Epoch #449
 56%|█████▌    | 449/800 [5:13:16<3:59:45, 40.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-448.pth
Results:
  total_reward: -12.0, step_mean: -0.007702182284980745
  total_deaths: 787.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 313.28 minutes

Epoch #450
 56%|█████▋    | 450/800 [5:13:57<3:59:14, 41.01s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-449.pth
Results:
  total_reward: -15.0, step_mean: -0.00967741935483871
  total_deaths: 790.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 313.96 minutes

Epoch #451
Saving the network weights to: ../models/sec_models/only_kill_death/model-450.pth
Results:
  total_reward: -3.0, step_mean: -0.0019047619047619048
  total_deaths: 790.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 314.66 minutes

Epoch #452
 56%|█████▋    | 452/800 [5:15:20<3:58:33, 41.13s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-451.pth
Results:
  total_reward: -13.0, step_mean: -0.008338678640153944
  total_deaths: 792.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 315.34 minutes

Epoch #453
 57%|█████▋    | 453/800 [5:16:00<3:55:47, 40.77s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-452.pth
Results:
  total_reward: -26.0, step_mean: -0.016785022595222725
  total_deaths: 795.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 316.01 minutes

Epoch #454
Saving the network weights to: ../models/sec_models/only_kill_death/model-453.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 796.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 316.68 minutes

Epoch #455
 57%|█████▋    | 455/800 [5:17:20<3:52:19, 40.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-454.pth
Results:
  total_reward: -21.0, step_mean: -0.013478818998716302
  total_deaths: 798.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 317.34 minutes

Epoch #456
 57%|█████▋    | 456/800 [5:18:00<3:50:47, 40.25s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-455.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 800.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 318.01 minutes

Epoch #457
 57%|█████▋    | 457/800 [5:18:40<3:49:09, 40.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-456.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 801.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 318.67 minutes

Epoch #458
Saving the network weights to: ../models/sec_models/only_kill_death/model-457.pth
Results:
  total_reward: -14.0, step_mean: -0.008939974457215836
  total_deaths: 802.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 319.32 minutes

Epoch #459
 57%|█████▋    | 459/800 [5:19:58<3:44:50, 39.56s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-458.pth
Results:
  total_reward: -36.0, step_mean: -0.023225806451612905
  total_deaths: 805.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 319.97 minutes

Epoch #460
Saving the network weights to: ../models/sec_models/only_kill_death/model-459.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 806.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 320.62 minutes

Epoch #461
 58%|█████▊    | 461/800 [5:21:16<3:42:00, 39.29s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-460.pth
Results:
  total_reward: -12.0, step_mean: -0.007702182284980745
  total_deaths: 808.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 321.27 minutes

Epoch #462
 58%|█████▊    | 462/800 [5:21:55<3:41:13, 39.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-461.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 809.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 321.93 minutes

Epoch #463
 58%|█████▊    | 463/800 [5:22:34<3:40:38, 39.28s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-462.pth
Results:
  total_reward: -16.0, step_mean: -0.01021059349074665
  total_deaths: 810.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 322.58 minutes

Epoch #464
 58%|█████▊    | 464/800 [5:23:14<3:40:12, 39.32s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-463.pth
Results:
  total_reward: -32.0, step_mean: -0.02064516129032258
  total_deaths: 813.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 323.24 minutes

Epoch #465
Saving the network weights to: ../models/sec_models/only_kill_death/model-464.pth
 58%|█████▊    | 465/800 [5:23:54<3:40:56, 39.57s/it]Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 814.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 323.91 minutes

Epoch #466
Saving the network weights to: ../models/sec_models/only_kill_death/model-465.pth
Results:
  total_reward: -22.0, step_mean: -0.014039566049776643
  total_deaths: 815.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 324.58 minutes

Epoch #467
 58%|█████▊    | 467/800 [5:25:14<3:40:11, 39.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-466.pth
Results:
  total_reward: -14.0, step_mean: -0.008939974457215836
  total_deaths: 816.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 325.23 minutes

Epoch #468
Saving the network weights to: ../models/sec_models/only_kill_death/model-467.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 818.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 325.90 minutes

Epoch #469
 59%|█████▊    | 469/800 [5:26:33<3:38:26, 39.60s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-468.pth
Results:
  total_reward: -35.0, step_mean: -0.0227125243348475
  total_deaths: 822.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 326.55 minutes

Epoch #470
Saving the network weights to: ../models/sec_models/only_kill_death/model-469.pth
Results:
  total_reward: -21.0, step_mean: -0.013470173187940988
  total_deaths: 824.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 327.22 minutes

Epoch #471
 59%|█████▉    | 471/800 [5:27:52<3:37:31, 39.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-470.pth
Results:
  total_reward: -24.0, step_mean: -0.015493867010974823
  total_deaths: 827.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 327.88 minutes

Epoch #472
Saving the network weights to: ../models/sec_models/only_kill_death/model-471.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 828.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 328.55 minutes

Epoch #473
 59%|█████▉    | 473/800 [5:29:15<3:41:41, 40.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-472.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 829.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 329.26 minutes

Epoch #474
 59%|█████▉    | 474/800 [5:29:59<3:46:04, 41.61s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-473.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 831.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 329.99 minutes

Epoch #475
Saving the network weights to: ../models/sec_models/only_kill_death/model-474.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 832.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 330.69 minutes

Epoch #476
 60%|█████▉    | 476/800 [5:31:24<3:48:03, 42.23s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-475.pth
Results:
  total_reward: -10.0, step_mean: -0.006381620931716656
  total_deaths: 833.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 331.42 minutes

Epoch #477
Saving the network weights to: ../models/sec_models/only_kill_death/model-476.pth
Results:
  total_reward: -27.0, step_mean: -0.017419354838709676
  total_deaths: 836.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 332.13 minutes

Epoch #478
 60%|█████▉    | 478/800 [5:32:51<3:49:02, 42.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-477.pth
Results:
  total_reward: 4.0, step_mean: 0.0025526483726866626
  total_deaths: 837.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 332.85 minutes

Epoch #479
Saving the network weights to: ../models/sec_models/only_kill_death/model-478.pth
Results:
  total_reward: -2.0, step_mean: -0.0012763241863433313
  total_deaths: 838.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 333.55 minutes

Epoch #480
 60%|██████    | 480/800 [5:34:15<3:46:01, 42.38s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-479.pth
Results:
  total_reward: -16.0, step_mean: -0.010276172125883108
  total_deaths: 840.0
  frag: 1.0
  death: 2.0
  global_step: 1557
Total elapsed time: 334.25 minutes

Epoch #481
Saving the network weights to: ../models/sec_models/only_kill_death/model-480.pth
Results:
  total_reward: -31.0, step_mean: -0.01989730423620026
  total_deaths: 842.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 334.96 minutes

Epoch #482
 60%|██████    | 482/800 [5:35:39<3:44:01, 42.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-481.pth
Results:
  total_reward: -4.0, step_mean: -0.002554278416347382
  total_deaths: 843.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 335.66 minutes

Epoch #483
Saving the network weights to: ../models/sec_models/only_kill_death/model-482.pth
Results:
  total_reward: -8.0, step_mean: -0.005105296745373325
  total_deaths: 844.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 336.36 minutes

Epoch #484
 60%|██████    | 484/800 [5:37:05<3:45:19, 42.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-483.pth
Results:
  total_reward: -15.0, step_mean: -0.009683666881859263
  total_deaths: 847.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 337.10 minutes

Epoch #485
 61%|██████    | 485/800 [5:37:49<3:45:31, 42.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-484.pth
Results:
  total_reward: -20.0, step_mean: -0.012845215157353885
  total_deaths: 849.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 337.82 minutes

Epoch #486
Saving the network weights to: ../models/sec_models/only_kill_death/model-485.pth
Results:
  total_reward: -9.0, step_mean: -0.005776636713735558
  total_deaths: 851.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 338.53 minutes

Epoch #487
 61%|██████    | 487/800 [5:39:13<3:41:58, 42.55s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-486.pth
Results:
  total_reward: -5.0, step_mean: -0.003190810465858328
  total_deaths: 852.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 339.23 minutes

Epoch #488
Saving the network weights to: ../models/sec_models/only_kill_death/model-487.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 853.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 339.92 minutes

Epoch #489
 61%|██████    | 489/800 [5:40:36<3:38:11, 42.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-488.pth
Results:
  total_reward: -23.0, step_mean: -0.014771997430956968
  total_deaths: 855.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 340.61 minutes

Epoch #490
Saving the network weights to: ../models/sec_models/only_kill_death/model-489.pth
Results:
  total_reward: -12.0, step_mean: -0.007702182284980745
  total_deaths: 857.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 341.31 minutes

Epoch #491
 61%|██████▏   | 491/800 [5:42:01<3:36:55, 42.12s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-490.pth
Results:
  total_reward: -1.0, step_mean: -0.0006381620931716656
  total_deaths: 858.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 342.02 minutes

Epoch #492
Saving the network weights to: ../models/sec_models/only_kill_death/model-491.pth
Results:
  total_reward: -12.0, step_mean: -0.007702182284980745
  total_deaths: 860.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 342.71 minutes

Epoch #493
 62%|██████▏   | 493/800 [5:43:24<3:33:57, 41.82s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-492.pth
Results:
  total_reward: -24.0, step_mean: -0.01540436456996149
  total_deaths: 862.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 343.40 minutes

Epoch #494
Saving the network weights to: ../models/sec_models/only_kill_death/model-493.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 863.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 344.10 minutes

Epoch #495
 62%|██████▏   | 495/800 [5:44:48<3:32:53, 41.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-494.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 864.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 344.80 minutes

Epoch #496
Saving the network weights to: ../models/sec_models/only_kill_death/model-495.pth
Results:
  total_reward: -22.0, step_mean: -0.014039566049776643
  total_deaths: 865.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 345.51 minutes

Epoch #497
 62%|██████▏   | 497/800 [5:46:12<3:32:09, 42.01s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-496.pth
Results:
  total_reward: -10.0, step_mean: -0.006381620931716656
  total_deaths: 866.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 346.21 minutes

Epoch #498
 62%|██████▏   | 498/800 [5:46:56<3:34:13, 42.56s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-497.pth
Results:
  total_reward: -33.0, step_mean: -0.02130406714009038
  total_deaths: 869.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 346.94 minutes

Epoch #499
Saving the network weights to: ../models/sec_models/only_kill_death/model-498.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 871.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 347.64 minutes

Epoch #500
 62%|██████▎   | 500/800 [5:48:21<3:32:41, 42.54s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-499.pth
Results:
  total_reward: -46.0, step_mean: -0.02967741935483871
  total_deaths: 874.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 348.35 minutes

Epoch #501
 63%|██████▎   | 501/800 [5:49:04<3:33:46, 42.90s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-500.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 875.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 349.08 minutes

Epoch #502
 63%|██████▎   | 502/800 [5:49:49<3:36:00, 43.49s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-501.pth
Results:
  total_reward: -21.0, step_mean: -0.013401403956604978
  total_deaths: 876.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 349.83 minutes

Epoch #503
Saving the network weights to: ../models/sec_models/only_kill_death/model-502.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 877.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 350.58 minutes

Epoch #504
 63%|██████▎   | 504/800 [5:51:19<3:38:45, 44.34s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-503.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 878.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 351.33 minutes

Epoch #505
Saving the network weights to: ../models/sec_models/only_kill_death/model-504.pth
Results:
  total_reward: -25.0, step_mean: -0.016139444803098774
  total_deaths: 881.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 352.06 minutes

Epoch #506
 63%|██████▎   | 506/800 [5:52:48<3:38:05, 44.51s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-505.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 882.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 352.82 minutes

Epoch #507
Saving the network weights to: ../models/sec_models/only_kill_death/model-506.pth
Results:
  total_reward: -24.0, step_mean: -0.015315890236119975
  total_deaths: 883.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 353.56 minutes

Epoch #508
 64%|██████▎   | 508/800 [5:54:16<3:34:46, 44.13s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-507.pth
Results:
  total_reward: -27.0, step_mean: -0.017419354838709676
  total_deaths: 886.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 354.28 minutes

Epoch #509
Saving the network weights to: ../models/sec_models/only_kill_death/model-508.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 887.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 354.99 minutes

Epoch #510
 64%|██████▍   | 510/800 [5:55:43<3:31:39, 43.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-509.pth
Results:
  total_reward: -10.0, step_mean: -0.006349206349206349
  total_deaths: 887.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 355.72 minutes

Epoch #511
Saving the network weights to: ../models/sec_models/only_kill_death/model-510.pth
Results:
  total_reward: -16.0, step_mean: -0.01021059349074665
  total_deaths: 888.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 356.45 minutes

Epoch #512
 64%|██████▍   | 512/800 [5:57:10<3:30:15, 43.80s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-511.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 889.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 357.18 minutes

Epoch #513
Saving the network weights to: ../models/sec_models/only_kill_death/model-512.pth
Results:
  total_reward: -31.0, step_mean: -0.020012911555842477
  total_deaths: 892.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 357.89 minutes

Epoch #514
 64%|██████▍   | 514/800 [5:58:35<3:24:52, 42.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-513.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 893.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 358.59 minutes

Epoch #515
Saving the network weights to: ../models/sec_models/only_kill_death/model-514.pth
Results:
  total_reward: -29.0, step_mean: -0.01872175597159458
  total_deaths: 896.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 359.29 minutes

Epoch #516
 64%|██████▍   | 516/800 [5:59:58<3:19:51, 42.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-515.pth
Results:
  total_reward: -47.0, step_mean: -0.030342156229825695
  total_deaths: 899.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 359.97 minutes

Epoch #517
Saving the network weights to: ../models/sec_models/only_kill_death/model-516.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 901.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 360.67 minutes

Epoch #518
 65%|██████▍   | 518/800 [6:01:23<3:19:15, 42.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-517.pth
Results:
  total_reward: -31.0, step_mean: -0.01991008349389852
  total_deaths: 903.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 361.39 minutes

Epoch #519
Saving the network weights to: ../models/sec_models/only_kill_death/model-518.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 905.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 362.08 minutes

Epoch #520
 65%|██████▌   | 520/800 [6:02:48<3:19:08, 42.67s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-519.pth
Results:
  total_reward: -8.0, step_mean: -0.005079365079365079
  total_deaths: 905.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 362.81 minutes

Epoch #521
Saving the network weights to: ../models/sec_models/only_kill_death/model-520.pth
Results:
  total_reward: -22.0, step_mean: -0.014039566049776643
  total_deaths: 906.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 363.50 minutes

Epoch #522
 65%|██████▌   | 522/800 [6:04:10<3:13:19, 41.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-521.pth
Results:
  total_reward: -17.0, step_mean: -0.010911424903722721
  total_deaths: 908.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 364.18 minutes

Epoch #523
 65%|██████▌   | 523/800 [6:04:51<3:11:16, 41.43s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-522.pth
Results:
  total_reward: -21.0, step_mean: -0.013401403956604978
  total_deaths: 909.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 364.86 minutes

Epoch #524
Saving the network weights to: ../models/sec_models/only_kill_death/model-523.pth
Results:
  total_reward: -32.0, step_mean: -0.02065848934796643
  total_deaths: 912.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 365.53 minutes

Epoch #525
 66%|██████▌   | 525/800 [6:06:12<3:07:55, 41.00s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-524.pth
Results:
  total_reward: -30.0, step_mean: -0.019255455712451863
  total_deaths: 914.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 366.21 minutes

Epoch #526
Saving the network weights to: ../models/sec_models/only_kill_death/model-525.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 915.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 366.88 minutes

Epoch #527
 66%|██████▌   | 527/800 [6:07:33<3:05:57, 40.87s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-526.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 917.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 367.56 minutes

Epoch #528
Saving the network weights to: ../models/sec_models/only_kill_death/model-527.pth
Results:
  total_reward: -12.0, step_mean: -0.007702182284980745
  total_deaths: 919.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 368.24 minutes

Epoch #529
 66%|██████▌   | 529/800 [6:08:54<3:03:30, 40.63s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-528.pth
Results:
  total_reward: -17.0, step_mean: -0.010904425914047467
  total_deaths: 921.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 368.91 minutes

Epoch #530
Saving the network weights to: ../models/sec_models/only_kill_death/model-529.pth
Results:
  total_reward: -31.0, step_mean: -0.02
  total_deaths: 924.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 369.58 minutes

Epoch #531
 66%|██████▋   | 531/800 [6:10:14<3:00:55, 40.35s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-530.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 926.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 370.25 minutes

Epoch #532
 66%|██████▋   | 532/800 [6:10:55<3:00:50, 40.49s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-531.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 927.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 370.93 minutes

Epoch #533
Saving the network weights to: ../models/sec_models/only_kill_death/model-532.pth
Results:
  total_reward: -18.0, step_mean: -0.01148691767708998
  total_deaths: 928.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 371.61 minutes

Epoch #534
 67%|██████▋   | 534/800 [6:12:17<3:00:38, 40.75s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-533.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 929.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 372.29 minutes

Epoch #535
 67%|██████▋   | 535/800 [6:12:57<2:58:43, 40.47s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-534.pth
Results:
  total_reward: -21.0, step_mean: -0.013548387096774193
  total_deaths: 932.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 372.96 minutes

Epoch #536
 67%|██████▋   | 536/800 [6:13:38<2:58:18, 40.52s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-535.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 933.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 373.63 minutes

Epoch #537
Saving the network weights to: ../models/sec_models/only_kill_death/model-536.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 934.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 374.31 minutes

Epoch #538
 67%|██████▋   | 538/800 [6:14:59<2:57:06, 40.56s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-537.pth
Results:
  total_reward: -15.0, step_mean: -0.009627727856225931
  total_deaths: 936.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 374.99 minutes

Epoch #539
Saving the network weights to: ../models/sec_models/only_kill_death/model-538.pth
Results:
  total_reward: -14.0, step_mean: -0.008939974457215836
  total_deaths: 937.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 375.67 minutes

Epoch #540
 68%|██████▊   | 540/800 [6:16:21<2:57:09, 40.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-539.pth
Results:
  total_reward: -27.0, step_mean: -0.017341040462427744
  total_deaths: 939.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 376.36 minutes

Epoch #541
Saving the network weights to: ../models/sec_models/only_kill_death/model-540.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 940.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 377.05 minutes

Epoch #542
 68%|██████▊   | 542/800 [6:17:44<2:56:43, 41.10s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-541.pth
Results:
  total_reward: -22.0, step_mean: -0.014120667522464698
  total_deaths: 942.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 377.74 minutes

Epoch #543
Saving the network weights to: ../models/sec_models/only_kill_death/model-542.pth
Results:
  total_reward: -31.0, step_mean: -0.01989730423620026
  total_deaths: 944.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 378.39 minutes

Epoch #544
 68%|██████▊   | 544/800 [6:19:02<2:50:55, 40.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-543.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 945.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 379.04 minutes

Epoch #545
Saving the network weights to: ../models/sec_models/only_kill_death/model-544.pth
Results:
  total_reward: -8.0, step_mean: -0.005105296745373325
  total_deaths: 946.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 379.69 minutes

Epoch #546
 68%|██████▊   | 546/800 [6:20:20<2:47:33, 39.58s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-545.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 948.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 380.35 minutes

Epoch #547
Saving the network weights to: ../models/sec_models/only_kill_death/model-546.pth
Results:
  total_reward: -9.0, step_mean: -0.005747126436781609
  total_deaths: 949.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 380.99 minutes

Epoch #548
 68%|██████▊   | 548/800 [6:21:38<2:45:03, 39.30s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-547.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 950.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 381.65 minutes

Epoch #549
Saving the network weights to: ../models/sec_models/only_kill_death/model-548.pth
Results:
  total_reward: -32.0, step_mean: -0.02053915275994865
  total_deaths: 952.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 382.30 minutes

Epoch #550
 69%|██████▉   | 550/800 [6:22:56<2:43:14, 39.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-549.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 954.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 382.95 minutes

Epoch #551
Saving the network weights to: ../models/sec_models/only_kill_death/model-550.pth
Results:
  total_reward: -12.0, step_mean: -0.007702182284980745
  total_deaths: 956.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 383.60 minutes

Epoch #552
 69%|██████▉   | 552/800 [6:24:15<2:42:05, 39.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-551.pth
Results:
  total_reward: -21.0, step_mean: -0.013401403956604978
  total_deaths: 957.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 384.26 minutes

Epoch #553
 69%|██████▉   | 553/800 [6:24:53<2:40:36, 39.01s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-552.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 959.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 384.90 minutes

Epoch #554
Saving the network weights to: ../models/sec_models/only_kill_death/model-553.pth
Results:
  total_reward: -32.0, step_mean: -0.020552344251766216
  total_deaths: 961.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 385.55 minutes

Epoch #555
 69%|██████▉   | 555/800 [6:26:12<2:39:34, 39.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-554.pth
Results:
  total_reward: -13.0, step_mean: -0.00834403080872914
  total_deaths: 963.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 386.20 minutes

Epoch #556
 70%|██████▉   | 556/800 [6:26:51<2:39:12, 39.15s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-555.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 964.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 386.86 minutes

Epoch #557
Saving the network weights to: ../models/sec_models/only_kill_death/model-556.pth
Results:
  total_reward: -1.0, step_mean: -0.0006349206349206349
  total_deaths: 964.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 387.52 minutes

Epoch #558
 70%|██████▉   | 558/800 [6:28:10<2:38:34, 39.32s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-557.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 965.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 388.17 minutes

Epoch #559
Saving the network weights to: ../models/sec_models/only_kill_death/model-558.pth
Results:
  total_reward: -34.0, step_mean: -0.02194964493221433
  total_deaths: 968.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 388.82 minutes

Epoch #560
 70%|███████   | 560/800 [6:29:28<2:36:12, 39.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-559.pth
Results:
  total_reward: -4.0, step_mean: -0.0025673940949935813
  total_deaths: 970.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 389.47 minutes

Epoch #561
Saving the network weights to: ../models/sec_models/only_kill_death/model-560.pth
Results:
  total_reward: -43.0, step_mean: -0.02775984506132989
  total_deaths: 973.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 390.11 minutes

Epoch #562
 70%|███████   | 562/800 [6:30:45<2:34:37, 38.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-561.pth
Results:
  total_reward: -35.0, step_mean: -0.022464698331193838
  total_deaths: 975.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 390.76 minutes

Epoch #563
Saving the network weights to: ../models/sec_models/only_kill_death/model-562.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 977.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 391.42 minutes

Epoch #564
 70%|███████   | 564/800 [6:32:04<2:33:50, 39.11s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-563.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 978.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 392.07 minutes

Epoch #565
Saving the network weights to: ../models/sec_models/only_kill_death/model-564.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 979.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 392.73 minutes

Epoch #566
 71%|███████   | 566/800 [6:33:23<2:33:27, 39.35s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-565.pth
Results:
  total_reward: -29.0, step_mean: -0.01860166773572803
  total_deaths: 981.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 393.39 minutes

Epoch #567
Saving the network weights to: ../models/sec_models/only_kill_death/model-566.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 982.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 394.06 minutes

Epoch #568
 71%|███████   | 568/800 [6:34:43<2:33:50, 39.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-567.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 983.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 394.73 minutes

Epoch #569
Saving the network weights to: ../models/sec_models/only_kill_death/model-568.pth
Results:
  total_reward: -11.0, step_mean: -0.007019783024888321
  total_deaths: 984.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 395.40 minutes

Epoch #570
 71%|███████▏  | 570/800 [6:36:04<2:33:26, 40.03s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-569.pth
Results:
  total_reward: -12.0, step_mean: -0.007657945118059987
  total_deaths: 985.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 396.07 minutes

Epoch #571
Saving the network weights to: ../models/sec_models/only_kill_death/model-570.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 987.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 396.73 minutes

Epoch #572
 72%|███████▏  | 572/800 [6:37:23<2:31:12, 39.79s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-571.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 988.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 397.39 minutes

Epoch #573
Saving the network weights to: ../models/sec_models/only_kill_death/model-572.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 989.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 398.06 minutes

Epoch #574
 72%|███████▏  | 574/800 [6:38:43<2:30:35, 39.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-573.pth
Results:
  total_reward: -33.0, step_mean: -0.021181001283697046
  total_deaths: 991.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 398.73 minutes

Epoch #575
Saving the network weights to: ../models/sec_models/only_kill_death/model-574.pth
Results:
  total_reward: -21.0, step_mean: -0.013409961685823755
  total_deaths: 992.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 399.40 minutes

Epoch #576
 72%|███████▏  | 576/800 [6:40:03<2:29:20, 40.00s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-575.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 994.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 400.06 minutes

Epoch #577
Saving the network weights to: ../models/sec_models/only_kill_death/model-576.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 995.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 400.73 minutes

Epoch #578
 72%|███████▏  | 578/800 [6:41:23<2:27:53, 39.97s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-577.pth
Results:
  total_reward: -4.0, step_mean: -0.0025526483726866626
  total_deaths: 996.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 401.40 minutes

Epoch #579
 72%|███████▏  | 579/800 [6:42:04<2:27:33, 40.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-578.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 998.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 402.07 minutes

Epoch #580
Saving the network weights to: ../models/sec_models/only_kill_death/model-579.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 999.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 402.73 minutes

Epoch #581
 73%|███████▎  | 581/800 [6:43:23<2:25:34, 39.88s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-580.pth
Results:
  total_reward: -10.0, step_mean: -0.006385696040868455
  total_deaths: 1000.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 403.39 minutes

Epoch #582
 73%|███████▎  | 582/800 [6:44:03<2:25:18, 39.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-581.pth
Results:
  total_reward: -32.0, step_mean: -0.02053915275994865
  total_deaths: 1002.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 404.06 minutes

Epoch #583
Saving the network weights to: ../models/sec_models/only_kill_death/model-582.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 1004.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 404.73 minutes

Epoch #584
 73%|███████▎  | 584/800 [6:45:23<2:23:46, 39.94s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-583.pth
Results:
  total_reward: -34.0, step_mean: -0.021836865767501604
  total_deaths: 1006.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 405.39 minutes

Epoch #585
Saving the network weights to: ../models/sec_models/only_kill_death/model-584.pth
Results:
  total_reward: -12.0, step_mean: -0.007702182284980745
  total_deaths: 1008.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 406.08 minutes

Epoch #586
 73%|███████▎  | 586/800 [6:46:49<2:28:23, 41.61s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-585.pth
Results:
  total_reward: -26.0, step_mean: -0.01667735728030789
  total_deaths: 1010.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 406.82 minutes

Epoch #587
Saving the network weights to: ../models/sec_models/only_kill_death/model-586.pth
Results:
  total_reward: -28.0, step_mean: -0.018076178179470628
  total_deaths: 1013.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 407.52 minutes

Epoch #588
 74%|███████▎  | 588/800 [6:48:14<2:28:32, 42.04s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-587.pth
Results:
  total_reward: -23.0, step_mean: -0.014677728142948309
  total_deaths: 1014.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 408.23 minutes

Epoch #589
 74%|███████▎  | 589/800 [6:48:55<2:26:53, 41.77s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-588.pth
Results:
  total_reward: -32.0, step_mean: -0.02065848934796643
  total_deaths: 1017.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 408.92 minutes

Epoch #590
Saving the network weights to: ../models/sec_models/only_kill_death/model-589.pth
Results:
  total_reward: -25.0, step_mean: -0.016129032258064516
  total_deaths: 1020.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 409.60 minutes

Epoch #591
 74%|███████▍  | 591/800 [6:50:17<2:24:52, 41.59s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-590.pth
Results:
  total_reward: -7.0, step_mean: -0.0044444444444444444
  total_deaths: 1020.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 410.30 minutes

Epoch #592
Saving the network weights to: ../models/sec_models/only_kill_death/model-591.pth
Results:
  total_reward: -25.0, step_mean: -0.016139444803098774
  total_deaths: 1023.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 410.99 minutes

Epoch #593
 74%|███████▍  | 593/800 [6:51:43<2:25:37, 42.21s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-592.pth
Results:
  total_reward: -37.0, step_mean: -0.023886378308586184
  total_deaths: 1026.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 411.72 minutes

Epoch #594
Saving the network weights to: ../models/sec_models/only_kill_death/model-593.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 1027.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 412.41 minutes

Epoch #595
 74%|███████▍  | 595/800 [6:53:06<2:22:57, 41.84s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-594.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 1028.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 413.10 minutes

Epoch #596
Saving the network weights to: ../models/sec_models/only_kill_death/model-595.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 1030.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 413.79 minutes

Epoch #597
 75%|███████▍  | 597/800 [6:54:28<2:20:21, 41.49s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-596.pth
Results:
  total_reward: -32.0, step_mean: -0.02053915275994865
  total_deaths: 1032.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 414.47 minutes

Epoch #598
Saving the network weights to: ../models/sec_models/only_kill_death/model-597.pth
Results:
  total_reward: -15.0, step_mean: -0.009627727856225931
  total_deaths: 1034.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 415.15 minutes

Epoch #599
 75%|███████▍  | 599/800 [6:55:51<2:18:56, 41.48s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-598.pth
Results:
  total_reward: -29.0, step_mean: -0.018625561978163133
  total_deaths: 1036.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 415.85 minutes

Epoch #600
Saving the network weights to: ../models/sec_models/only_kill_death/model-599.pth
Results:
  total_reward: -16.0, step_mean: -0.010269576379974325
  total_deaths: 1038.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 416.55 minutes

Epoch #601
 75%|███████▌  | 601/800 [6:57:18<2:21:41, 42.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-600.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 1039.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 417.31 minutes

Epoch #602
 75%|███████▌  | 602/800 [6:58:00<2:20:34, 42.60s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-601.pth
Results:
  total_reward: -31.0, step_mean: -0.020012911555842477
  total_deaths: 1042.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 418.01 minutes

Epoch #603
 75%|███████▌  | 603/800 [6:58:42<2:18:42, 42.25s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-602.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 1043.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 418.70 minutes

Epoch #604
Saving the network weights to: ../models/sec_models/only_kill_death/model-603.pth
Results:
  total_reward: -37.0, step_mean: -0.023886378308586184
  total_deaths: 1046.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 419.38 minutes

Epoch #605
 76%|███████▌  | 605/800 [7:00:03<2:14:50, 41.49s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-604.pth
Results:
  total_reward: -24.0, step_mean: -0.015394483643361129
  total_deaths: 1048.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 420.06 minutes

Epoch #606
Saving the network weights to: ../models/sec_models/only_kill_death/model-605.pth
Results:
  total_reward: -5.0, step_mean: -0.0031746031746031746
  total_deaths: 1048.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 420.74 minutes

Epoch #607
 76%|███████▌  | 607/800 [7:01:25<2:12:47, 41.28s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-606.pth
Results:
  total_reward: -30.0, step_mean: -0.01924310455420141
  total_deaths: 1050.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 421.43 minutes

Epoch #608
 76%|███████▌  | 608/800 [7:02:07<2:12:38, 41.45s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-607.pth
Results:
  total_reward: -29.0, step_mean: -0.018625561978163133
  total_deaths: 1053.0
  frag: 0.0
  death: 3.0
  global_step: 1557
Total elapsed time: 422.13 minutes

Epoch #609
Saving the network weights to: ../models/sec_models/only_kill_death/model-608.pth
Results:
  total_reward: -27.0, step_mean: -0.017430600387346677
  total_deaths: 1056.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 422.82 minutes

Epoch #610
 76%|███████▋  | 610/800 [7:03:31<2:12:08, 41.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-609.pth
Results:
  total_reward: -18.0, step_mean: -0.01148691767708998
  total_deaths: 1057.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 423.52 minutes

Epoch #611
Saving the network weights to: ../models/sec_models/only_kill_death/model-610.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 1059.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 424.22 minutes

Epoch #612
 76%|███████▋  | 612/800 [7:04:54<2:10:21, 41.60s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-611.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 1061.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 424.91 minutes

Epoch #613
 77%|███████▋  | 613/800 [7:05:36<2:09:45, 41.63s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-612.pth
Results:
  total_reward: -24.0, step_mean: -0.01532567049808429
  total_deaths: 1062.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 425.60 minutes

Epoch #614
Saving the network weights to: ../models/sec_models/only_kill_death/model-613.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 1063.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 426.30 minutes

Epoch #615
 77%|███████▋  | 615/800 [7:06:59<2:08:34, 41.70s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-614.pth
Results:
  total_reward: -28.0, step_mean: -0.01797175866495507
  total_deaths: 1065.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 427.00 minutes

Epoch #616
Saving the network weights to: ../models/sec_models/only_kill_death/model-615.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 1066.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 427.71 minutes

Epoch #617
 77%|███████▋  | 617/800 [7:08:24<2:08:05, 42.00s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-616.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 1068.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 428.41 minutes

Epoch #618
Saving the network weights to: ../models/sec_models/only_kill_death/model-617.pth
 77%|███████▋  | 618/800 [7:09:05<2:06:07, 41.58s/it]Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 1070.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 429.09 minutes

Epoch #619
 77%|███████▋  | 619/800 [7:09:45<2:04:27, 41.26s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-618.pth
Results:
  total_reward: -25.0, step_mean: -0.01603592046183451
  total_deaths: 1072.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 429.76 minutes

Epoch #620
Saving the network weights to: ../models/sec_models/only_kill_death/model-619.pth
Results:
  total_reward: -14.0, step_mean: -0.008939974457215836
  total_deaths: 1073.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 430.44 minutes

Epoch #621
 78%|███████▊  | 621/800 [7:11:06<2:01:44, 40.81s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-620.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 1074.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 431.11 minutes

Epoch #622
Saving the network weights to: ../models/sec_models/only_kill_death/model-621.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 1076.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 431.78 minutes

Epoch #623
 78%|███████▊  | 623/800 [7:12:27<1:59:41, 40.58s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-622.pth
Results:
  total_reward: -10.0, step_mean: -0.006385696040868455
  total_deaths: 1077.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 432.45 minutes

Epoch #624
Saving the network weights to: ../models/sec_models/only_kill_death/model-623.pth
Results:
  total_reward: -16.0, step_mean: -0.01021059349074665
  total_deaths: 1078.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 433.12 minutes

Epoch #625
 78%|███████▊  | 625/800 [7:13:48<1:58:32, 40.64s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-624.pth
Results:
  total_reward: -24.0, step_mean: -0.01540436456996149
  total_deaths: 1080.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 433.81 minutes

Epoch #626
Saving the network weights to: ../models/sec_models/only_kill_death/model-625.pth
Results:
  total_reward: -33.0, step_mean: -0.02130406714009038
  total_deaths: 1083.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 434.46 minutes

Epoch #627
 78%|███████▊  | 627/800 [7:15:07<1:55:53, 40.20s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-626.pth
Results:
  total_reward: -15.0, step_mean: -0.009578544061302681
  total_deaths: 1084.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 435.13 minutes

Epoch #628
 78%|███████▊  | 628/800 [7:15:47<1:55:07, 40.16s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-627.pth
Results:
  total_reward: -15.0, step_mean: -0.009627727856225931
  total_deaths: 1086.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 435.80 minutes

Epoch #629
Saving the network weights to: ../models/sec_models/only_kill_death/model-628.pth
Results:
  total_reward: -31.0, step_mean: -0.01989730423620026
  total_deaths: 1088.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 436.47 minutes

Epoch #630
 79%|███████▉  | 630/800 [7:17:08<1:53:52, 40.19s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-629.pth
Results:
  total_reward: -14.0, step_mean: -0.008985879332477536
  total_deaths: 1090.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 437.14 minutes

Epoch #631
 79%|███████▉  | 631/800 [7:17:49<1:53:48, 40.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-630.pth
Results:
  total_reward: -23.0, step_mean: -0.014687100893997445
  total_deaths: 1091.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 437.82 minutes

Epoch #632
Saving the network weights to: ../models/sec_models/only_kill_death/model-631.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 1092.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 438.53 minutes

Epoch #633
 79%|███████▉  | 633/800 [7:19:12<1:54:00, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-632.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 1094.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 439.21 minutes

Epoch #634
Saving the network weights to: ../models/sec_models/only_kill_death/model-633.pth
Results:
  total_reward: -34.0, step_mean: -0.021822849807445442
  total_deaths: 1096.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 439.88 minutes

Epoch #635
 79%|███████▉  | 635/800 [7:20:33<1:52:16, 40.83s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-634.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 1097.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 440.56 minutes

Epoch #636
Saving the network weights to: ../models/sec_models/only_kill_death/model-635.pth
Results:
  total_reward: -6.0, step_mean: -0.0038289725590299937
  total_deaths: 1098.0
  frag: 1.0
  death: 1.0
  global_step: 1567
Total elapsed time: 441.24 minutes

Epoch #637
 80%|███████▉  | 637/800 [7:21:55<1:50:38, 40.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-636.pth
Results:
  total_reward: -9.0, step_mean: -0.00574345883854499
  total_deaths: 1099.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 441.92 minutes

Epoch #638
Saving the network weights to: ../models/sec_models/only_kill_death/model-637.pth
Results:
  total_reward: -30.0, step_mean: -0.019267822736030827
  total_deaths: 1101.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 442.59 minutes

Epoch #639
 80%|███████▉  | 639/800 [7:23:16<1:49:16, 40.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-638.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 1102.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 443.27 minutes

Epoch #640
Saving the network weights to: ../models/sec_models/only_kill_death/model-639.pth
Results:
  total_reward: -15.0, step_mean: -0.009627727856225931
  total_deaths: 1104.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 443.96 minutes

Epoch #641
 80%|████████  | 641/800 [7:24:38<1:48:03, 40.77s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-640.pth
Results:
  total_reward: -37.0, step_mean: -0.023886378308586184
  total_deaths: 1107.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 444.64 minutes

Epoch #642
Saving the network weights to: ../models/sec_models/only_kill_death/model-641.pth
Results:
  total_reward: -14.0, step_mean: -0.00899165061014772
  total_deaths: 1109.0
  frag: 1.0
  death: 2.0
  global_step: 1557
Total elapsed time: 445.32 minutes

Epoch #643
 80%|████████  | 643/800 [7:26:00<1:47:19, 41.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-642.pth
Results:
  total_reward: -35.0, step_mean: -0.022595222724338282
  total_deaths: 1112.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 446.01 minutes

Epoch #644
 80%|████████  | 644/800 [7:26:41<1:46:46, 41.07s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-643.pth
Results:
  total_reward: 0.0, step_mean: 0.0
  total_deaths: 1114.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 446.70 minutes

Epoch #645
Saving the network weights to: ../models/sec_models/only_kill_death/model-644.pth
Results:
  total_reward: -10.0, step_mean: -0.006381620931716656
  total_deaths: 1115.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 447.38 minutes

Epoch #646
 81%|████████  | 646/800 [7:28:02<1:44:38, 40.77s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-645.pth
Results:
  total_reward: -9.0, step_mean: -0.005810200129115558
  total_deaths: 1118.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 448.05 minutes

Epoch #647
Saving the network weights to: ../models/sec_models/only_kill_death/model-646.pth
Results:
  total_reward: -12.0, step_mean: -0.007746933505487412
  total_deaths: 1121.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 448.73 minutes

Epoch #648
 81%|████████  | 648/800 [7:29:25<1:43:55, 41.02s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-647.pth
Results:
  total_reward: -37.0, step_mean: -0.023870967741935485
  total_deaths: 1124.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 449.42 minutes

Epoch #649
Saving the network weights to: ../models/sec_models/only_kill_death/model-648.pth
Results:
  total_reward: -21.0, step_mean: -0.013548387096774193
  total_deaths: 1127.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 450.08 minutes

Epoch #650
 81%|████████▏ | 650/800 [7:30:44<1:40:53, 40.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-649.pth
Results:
  total_reward: -12.0, step_mean: -0.007662835249042145
  total_deaths: 1128.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 450.75 minutes

Epoch #651
Saving the network weights to: ../models/sec_models/only_kill_death/model-650.pth
Results:
  total_reward: -7.0, step_mean: -0.004469987228607918
  total_deaths: 1129.0
  frag: 1.0
  death: 1.0
  global_step: 1566
Total elapsed time: 451.43 minutes

Epoch #652
 82%|████████▏ | 652/800 [7:32:07<1:40:56, 40.92s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-651.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 1131.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 452.13 minutes

Epoch #653
Saving the network weights to: ../models/sec_models/only_kill_death/model-652.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 1132.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 452.82 minutes

Epoch #654
 82%|████████▏ | 654/800 [7:33:30<1:39:58, 41.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-653.pth
Results:
  total_reward: -21.0, step_mean: -0.01348747591522158
  total_deaths: 1134.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 453.50 minutes

Epoch #655
Saving the network weights to: ../models/sec_models/only_kill_death/model-654.pth
Results:
  total_reward: -21.0, step_mean: -0.013478818998716302
  total_deaths: 1136.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 454.18 minutes

Epoch #656
 82%|████████▏ | 656/800 [7:34:52<1:38:30, 41.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-655.pth
Results:
  total_reward: -21.0, step_mean: -0.013478818998716302
  total_deaths: 1138.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 454.87 minutes

Epoch #657
Saving the network weights to: ../models/sec_models/only_kill_death/model-656.pth
Results:
  total_reward: -27.0, step_mean: -0.017419354838709676
  total_deaths: 1141.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 455.56 minutes

Epoch #658
 82%|████████▏ | 658/800 [7:36:15<1:37:48, 41.33s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-657.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 1142.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 456.25 minutes

Epoch #659
Saving the network weights to: ../models/sec_models/only_kill_death/model-658.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 1143.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 456.91 minutes

Epoch #660
 82%|████████▎ | 660/800 [7:37:33<1:33:45, 40.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-659.pth
Results:
  total_reward: -33.0, step_mean: -0.02129032258064516
  total_deaths: 1146.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 457.56 minutes

Epoch #661
Saving the network weights to: ../models/sec_models/only_kill_death/model-660.pth
Results:
  total_reward: -31.0, step_mean: -0.01989730423620026
  total_deaths: 1148.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 458.24 minutes

Epoch #662
 83%|████████▎ | 662/800 [7:38:54<1:32:37, 40.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-661.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 1150.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 458.91 minutes

Epoch #663
 83%|████████▎ | 663/800 [7:39:33<1:31:29, 40.07s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-662.pth
Results:
  total_reward: -38.0, step_mean: -0.024531956100710135
  total_deaths: 1153.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 459.57 minutes

Epoch #664
 83%|████████▎ | 664/800 [7:40:14<1:30:48, 40.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-663.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 1155.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 460.23 minutes

Epoch #665
Saving the network weights to: ../models/sec_models/only_kill_death/model-664.pth
Results:
  total_reward: -11.0, step_mean: -0.007019783024888321
  total_deaths: 1156.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 460.90 minutes

Epoch #666
 83%|████████▎ | 666/800 [7:41:34<1:29:25, 40.04s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-665.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 1157.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 461.57 minutes

Epoch #667
Saving the network weights to: ../models/sec_models/only_kill_death/model-666.pth
Results:
  total_reward: -38.0, step_mean: -0.024531956100710135
  total_deaths: 1160.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 462.22 minutes

Epoch #668
 84%|████████▎ | 668/800 [7:42:53<1:27:40, 39.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-667.pth
Results:
  total_reward: -12.0, step_mean: -0.007662835249042145
  total_deaths: 1161.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 462.89 minutes

Epoch #669
Saving the network weights to: ../models/sec_models/only_kill_death/model-668.pth
Results:
  total_reward: -4.0, step_mean: -0.0025526483726866626
  total_deaths: 1162.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 463.57 minutes

Epoch #670
 84%|████████▍ | 670/800 [7:44:14<1:27:03, 40.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-669.pth
Results:
  total_reward: -22.0, step_mean: -0.014120667522464698
  total_deaths: 1164.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 464.24 minutes

Epoch #671
Saving the network weights to: ../models/sec_models/only_kill_death/model-670.pth
Results:
  total_reward: -17.0, step_mean: -0.010855683269476373
  total_deaths: 1165.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 464.91 minutes

Epoch #672
 84%|████████▍ | 672/800 [7:45:35<1:26:11, 40.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-671.pth
Results:
  total_reward: -24.0, step_mean: -0.015394483643361129
  total_deaths: 1167.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 465.59 minutes

Epoch #673
Saving the network weights to: ../models/sec_models/only_kill_death/model-672.pth
Results:
  total_reward: -27.0, step_mean: -0.01752109020116807
  total_deaths: 1171.0
  frag: 1.0
  death: 4.0
  global_step: 1541
Total elapsed time: 466.26 minutes

Epoch #674
 84%|████████▍ | 674/800 [7:46:56<1:24:57, 40.45s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-673.pth
Results:
  total_reward: -34.0, step_mean: -0.021822849807445442
  total_deaths: 1173.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 466.94 minutes

Epoch #675
Saving the network weights to: ../models/sec_models/only_kill_death/model-674.pth
Results:
  total_reward: -24.0, step_mean: -0.015414258188824663
  total_deaths: 1175.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 467.62 minutes

Epoch #676
 84%|████████▍ | 676/800 [7:48:18<1:24:16, 40.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-675.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 1176.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 468.31 minutes

Epoch #677
 85%|████████▍ | 677/800 [7:48:59<1:23:28, 40.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-676.pth
Results:
  total_reward: -9.0, step_mean: -0.005714285714285714
  total_deaths: 1176.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 468.99 minutes

Epoch #678
Saving the network weights to: ../models/sec_models/only_kill_death/model-677.pth
Results:
  total_reward: -29.0, step_mean: -0.01872175597159458
  total_deaths: 1179.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 469.66 minutes

Epoch #679
 85%|████████▍ | 679/800 [7:50:19<1:21:37, 40.48s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-678.pth
Results:
  total_reward: -6.0, step_mean: -0.0038095238095238095
  total_deaths: 1179.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 470.33 minutes

Epoch #680
 85%|████████▌ | 680/800 [7:50:59<1:20:26, 40.22s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-679.pth
Results:
  total_reward: -21.0, step_mean: -0.013478818998716302
  total_deaths: 1181.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 470.99 minutes

Epoch #681
 85%|████████▌ | 681/800 [7:51:38<1:19:10, 39.92s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-680.pth
Results:
  total_reward: -31.0, step_mean: -0.01991008349389852
  total_deaths: 1183.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 471.64 minutes

Epoch #682
 85%|████████▌ | 682/800 [7:52:17<1:18:12, 39.77s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-681.pth
Results:
  total_reward: -29.0, step_mean: -0.018625561978163133
  total_deaths: 1185.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 472.30 minutes

Epoch #683
Saving the network weights to: ../models/sec_models/only_kill_death/model-682.pth
Results:
  total_reward: -16.0, step_mean: -0.010262989095574085
  total_deaths: 1187.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 472.96 minutes

Epoch #684
 86%|████████▌ | 684/800 [7:53:37<1:16:45, 39.70s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-683.pth
Results:
  total_reward: -10.0, step_mean: -0.006418485237483954
  total_deaths: 1189.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 473.62 minutes

Epoch #685
Saving the network weights to: ../models/sec_models/only_kill_death/model-684.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 1190.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 474.29 minutes

Epoch #686
 86%|████████▌ | 686/800 [7:54:57<1:15:58, 39.99s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-685.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 1191.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 474.96 minutes

Epoch #687
Saving the network weights to: ../models/sec_models/only_kill_death/model-686.pth
Results:
  total_reward: -19.0, step_mean: -0.012187299550994226
  total_deaths: 1193.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 475.67 minutes

Epoch #688
 86%|████████▌ | 688/800 [7:56:21<1:16:14, 40.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-687.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 1194.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 476.36 minutes

Epoch #689
Saving the network weights to: ../models/sec_models/only_kill_death/model-688.pth
Results:
  total_reward: -18.0, step_mean: -0.01148691767708998
  total_deaths: 1195.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 477.03 minutes

Epoch #690
 86%|████████▋ | 690/800 [7:57:43<1:15:05, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-689.pth
Results:
  total_reward: -1.0, step_mean: -0.0006349206349206349
  total_deaths: 1195.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 477.72 minutes

Epoch #691
Saving the network weights to: ../models/sec_models/only_kill_death/model-690.pth
Results:
  total_reward: -42.0, step_mean: -0.02711426726920594
  total_deaths: 1198.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 478.39 minutes

Epoch #692
 86%|████████▋ | 692/800 [7:59:03<1:13:10, 40.65s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-691.pth
Results:
  total_reward: -31.0, step_mean: -0.01989730423620026
  total_deaths: 1200.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 479.06 minutes

Epoch #693
Saving the network weights to: ../models/sec_models/only_kill_death/model-692.pth
Results:
  total_reward: -30.0, step_mean: -0.01924310455420141
  total_deaths: 1202.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 479.74 minutes

Epoch #694
 87%|████████▋ | 694/800 [8:00:24<1:11:22, 40.40s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-693.pth
Results:
  total_reward: -12.0, step_mean: -0.007657945118059987
  total_deaths: 1203.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 480.40 minutes

Epoch #695
Saving the network weights to: ../models/sec_models/only_kill_death/model-694.pth
Results:
  total_reward: -3.0, step_mean: -0.0019047619047619048
  total_deaths: 1203.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 481.07 minutes

Epoch #696
 87%|████████▋ | 696/800 [8:01:44<1:09:37, 40.16s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-695.pth
Results:
  total_reward: -14.0, step_mean: -0.008985879332477536
  total_deaths: 1205.0
  frag: 1.0
  death: 2.0
  global_step: 1558
Total elapsed time: 481.74 minutes

Epoch #697
 87%|████████▋ | 697/800 [8:02:23<1:08:45, 40.05s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-696.pth
Results:
  total_reward: -19.0, step_mean: -0.012265978050355068
  total_deaths: 1208.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 482.40 minutes

Epoch #698
Saving the network weights to: ../models/sec_models/only_kill_death/model-697.pth
Results:
  total_reward: -21.0, step_mean: -0.013409961685823755
  total_deaths: 1209.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 483.07 minutes

Epoch #699
 87%|████████▋ | 699/800 [8:03:43<1:07:23, 40.03s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-698.pth
Results:
  total_reward: -32.0, step_mean: -0.02053915275994865
  total_deaths: 1211.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 483.73 minutes

Epoch #700
 88%|████████▊ | 700/800 [8:04:24<1:07:03, 40.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-699.pth
Results:
  total_reward: -27.0, step_mean: -0.017329910141206675
  total_deaths: 1213.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 484.41 minutes

Epoch #701
Saving the network weights to: ../models/sec_models/only_kill_death/model-700.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 1214.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 485.09 minutes

Epoch #702
 88%|████████▊ | 702/800 [8:05:45<1:05:37, 40.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-701.pth
Results:
  total_reward: -27.0, step_mean: -0.017430600387346677
  total_deaths: 1217.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 485.75 minutes

Epoch #703
Saving the network weights to: ../models/sec_models/only_kill_death/model-702.pth
Results:
  total_reward: -43.0, step_mean: -0.02775984506132989
  total_deaths: 1220.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 486.43 minutes

Epoch #704
 88%|████████▊ | 704/800 [8:07:06<1:04:56, 40.59s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-703.pth
Results:
  total_reward: -16.0, step_mean: -0.01021059349074665
  total_deaths: 1221.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 487.11 minutes

Epoch #705
Saving the network weights to: ../models/sec_models/only_kill_death/model-704.pth
Results:
  total_reward: -10.0, step_mean: -0.006418485237483954
  total_deaths: 1223.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 487.81 minutes

Epoch #706
 88%|████████▊ | 706/800 [8:08:30<1:04:21, 41.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-705.pth
Results:
  total_reward: -11.0, step_mean: -0.007019783024888321
  total_deaths: 1224.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 488.50 minutes

Epoch #707
 88%|████████▊ | 707/800 [8:09:10<1:03:27, 40.94s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-706.pth
Results:
  total_reward: -17.0, step_mean: -0.010904425914047467
  total_deaths: 1226.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 489.18 minutes

Epoch #708
Saving the network weights to: ../models/sec_models/only_kill_death/model-707.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 1227.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 489.86 minutes

Epoch #709
 89%|████████▊ | 709/800 [8:10:33<1:02:43, 41.36s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-708.pth
Results:
  total_reward: -25.0, step_mean: -0.016129032258064516
  total_deaths: 1230.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 490.57 minutes

Epoch #710
Saving the network weights to: ../models/sec_models/only_kill_death/model-709.pth
Results:
  total_reward: -14.0, step_mean: -0.008985879332477536
  total_deaths: 1232.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 491.24 minutes

Epoch #711
 89%|████████▉ | 711/800 [8:11:55<1:00:45, 40.96s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-710.pth
Results:
  total_reward: -44.0, step_mean: -0.028405422853453842
  total_deaths: 1235.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 491.92 minutes

Epoch #712
Saving the network weights to: ../models/sec_models/only_kill_death/model-711.pth
Results:
  total_reward: -37.0, step_mean: -0.023870967741935485
  total_deaths: 1238.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 492.61 minutes

Epoch #713
 89%|████████▉ | 713/800 [8:13:17<59:33, 41.07s/it]  Saving the network weights to: ../models/sec_models/only_kill_death/model-712.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 1239.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 493.29 minutes

Epoch #714
 89%|████████▉ | 714/800 [8:13:58<58:52, 41.07s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-713.pth
Results:
  total_reward: -23.0, step_mean: -0.014848289218850872
  total_deaths: 1242.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 493.98 minutes

Epoch #715
 89%|████████▉ | 715/800 [8:14:39<58:03, 40.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-714.pth
Results:
  total_reward: -6.0, step_mean: -0.0038289725590299937
  total_deaths: 1243.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 494.65 minutes

Epoch #716
 90%|████████▉ | 716/800 [8:15:19<57:03, 40.76s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-715.pth
Results:
  total_reward: -21.0, step_mean: -0.013401403956604978
  total_deaths: 1244.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 495.33 minutes

Epoch #717
Saving the network weights to: ../models/sec_models/only_kill_death/model-716.pth
Results:
  total_reward: -23.0, step_mean: -0.014687100893997445
  total_deaths: 1245.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 496.01 minutes

Epoch #718
 90%|████████▉ | 718/800 [8:16:41<55:56, 40.94s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-717.pth
Results:
  total_reward: -30.0, step_mean: -0.019267822736030827
  total_deaths: 1247.0
  frag: 0.0
  death: 2.0
  global_step: 1557
Total elapsed time: 496.69 minutes

Epoch #719
Saving the network weights to: ../models/sec_models/only_kill_death/model-718.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 1248.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 497.38 minutes

Epoch #720
 90%|█████████ | 720/800 [8:18:04<54:54, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-719.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 1249.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 498.07 minutes

Epoch #721
Saving the network weights to: ../models/sec_models/only_kill_death/model-720.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 1250.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 498.75 minutes

Epoch #722
 90%|█████████ | 722/800 [8:19:25<53:05, 40.85s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-721.pth
Results:
  total_reward: -24.0, step_mean: -0.015493867010974823
  total_deaths: 1253.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 499.42 minutes

Epoch #723
 90%|█████████ | 723/800 [8:20:06<52:28, 40.89s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-722.pth
Results:
  total_reward: -22.0, step_mean: -0.014120667522464698
  total_deaths: 1255.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 500.11 minutes

Epoch #724
 90%|█████████ | 724/800 [8:20:48<52:10, 41.19s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-723.pth
Results:
  total_reward: -16.0, step_mean: -0.01021059349074665
  total_deaths: 1256.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 500.81 minutes

Epoch #725
Saving the network weights to: ../models/sec_models/only_kill_death/model-724.pth
Results:
  total_reward: -36.0, step_mean: -0.023106546854942234
  total_deaths: 1258.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 501.49 minutes

Epoch #726
 91%|█████████ | 726/800 [8:22:10<50:47, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-725.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 1259.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 502.18 minutes

Epoch #727
Saving the network weights to: ../models/sec_models/only_kill_death/model-726.pth
Results:
  total_reward: -25.0, step_mean: -0.016046213093709884
  total_deaths: 1261.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 502.87 minutes

Epoch #728
 91%|█████████ | 728/800 [8:23:33<49:29, 41.24s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-727.pth
Results:
  total_reward: -26.0, step_mean: -0.016785022595222725
  total_deaths: 1264.0
  frag: 0.0
  death: 3.0
  global_step: 1549
Total elapsed time: 503.55 minutes

Epoch #729
 91%|█████████ | 729/800 [8:24:14<48:41, 41.15s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-728.pth
Results:
  total_reward: -23.0, step_mean: -0.014838709677419355
  total_deaths: 1267.0
  frag: 1.0
  death: 3.0
  global_step: 1550
Total elapsed time: 504.24 minutes

Epoch #730
Saving the network weights to: ../models/sec_models/only_kill_death/model-729.pth
Results:
  total_reward: -33.0, step_mean: -0.021181001283697046
  total_deaths: 1269.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 504.91 minutes

Epoch #731
 91%|█████████▏| 731/800 [8:25:37<47:34, 41.37s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-730.pth
Results:
  total_reward: -14.0, step_mean: -0.008934269304403318
  total_deaths: 1270.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 505.62 minutes

Epoch #732
Saving the network weights to: ../models/sec_models/only_kill_death/model-731.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 1271.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 506.31 minutes

Epoch #733
 92%|█████████▏| 733/800 [8:26:58<45:54, 41.11s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-732.pth
Results:
  total_reward: -48.0, step_mean: -0.031148604802076575
  total_deaths: 1275.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 506.98 minutes

Epoch #734
 92%|█████████▏| 734/800 [8:27:41<45:42, 41.55s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-733.pth
Results:
  total_reward: -30.0, step_mean: -0.01924310455420141
  total_deaths: 1277.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 507.69 minutes

Epoch #735
 92%|█████████▏| 735/800 [8:28:23<45:10, 41.70s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-734.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 1278.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 508.39 minutes

Epoch #736
Saving the network weights to: ../models/sec_models/only_kill_death/model-735.pth
Results:
  total_reward: -16.0, step_mean: -0.010269576379974325
  total_deaths: 1280.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 509.11 minutes

Epoch #737
 92%|█████████▏| 737/800 [8:29:48<44:10, 42.06s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-736.pth
Results:
  total_reward: -19.0, step_mean: -0.012187299550994226
  total_deaths: 1282.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 509.81 minutes

Epoch #738
Saving the network weights to: ../models/sec_models/only_kill_death/model-737.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 1283.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 510.50 minutes

Epoch #739
 92%|█████████▏| 739/800 [8:31:11<42:19, 41.64s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-738.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 1284.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 511.19 minutes

Epoch #740
Saving the network weights to: ../models/sec_models/only_kill_death/model-739.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 1285.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 511.88 minutes

Epoch #741
 93%|█████████▎| 741/800 [8:32:35<41:09, 41.86s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-740.pth
Results:
  total_reward: -10.0, step_mean: -0.006381620931716656
  total_deaths: 1286.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 512.59 minutes

Epoch #742
Saving the network weights to: ../models/sec_models/only_kill_death/model-741.pth
Results:
  total_reward: -38.0, step_mean: -0.02465931213497729
  total_deaths: 1290.0
  frag: 0.0
  death: 4.0
  global_step: 1541
Total elapsed time: 513.27 minutes

Epoch #743
 93%|█████████▎| 743/800 [8:33:58<39:39, 41.75s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-742.pth
Results:
  total_reward: -21.0, step_mean: -0.01348747591522158
  total_deaths: 1292.0
  frag: 1.0
  death: 2.0
  global_step: 1557
Total elapsed time: 513.97 minutes

Epoch #744
Saving the network weights to: ../models/sec_models/only_kill_death/model-743.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 1293.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 514.67 minutes

Epoch #745
 93%|█████████▎| 745/800 [8:35:21<38:12, 41.68s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-744.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 1294.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 515.36 minutes

Epoch #746
Saving the network weights to: ../models/sec_models/only_kill_death/model-745.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 1295.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 516.05 minutes

Epoch #747
 93%|█████████▎| 747/800 [8:36:44<36:38, 41.49s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-746.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 1296.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 516.74 minutes

Epoch #748
Saving the network weights to: ../models/sec_models/only_kill_death/model-747.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 1297.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 517.43 minutes

Epoch #749
 94%|█████████▎| 749/800 [8:38:06<35:10, 41.38s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-748.pth
Results:
  total_reward: -16.0, step_mean: -0.010217113665389528
  total_deaths: 1298.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 518.11 minutes

Epoch #750
Saving the network weights to: ../models/sec_models/only_kill_death/model-749.pth
Results:
  total_reward: -20.0, step_mean: -0.012763241863433313
  total_deaths: 1299.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 518.82 minutes

Epoch #751
 94%|█████████▍| 751/800 [8:39:30<33:53, 41.50s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-750.pth
Results:
  total_reward: -14.0, step_mean: -0.008939974457215836
  total_deaths: 1300.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 519.51 minutes

Epoch #752
 94%|█████████▍| 752/800 [8:40:11<33:03, 41.33s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-751.pth
Results:
  total_reward: -17.0, step_mean: -0.010904425914047467
  total_deaths: 1302.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 520.19 minutes

Epoch #753
Saving the network weights to: ../models/sec_models/only_kill_death/model-752.pth
Results:
  total_reward: -29.0, step_mean: -0.01856594110115237
  total_deaths: 1304.0
  frag: 0.0
  death: 2.0
  global_step: 1562
Total elapsed time: 520.87 minutes

Epoch #754
 94%|█████████▍| 754/800 [8:41:34<31:46, 41.45s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-753.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 1305.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 521.57 minutes

Epoch #755
Saving the network weights to: ../models/sec_models/only_kill_death/model-754.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 1306.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 522.27 minutes

Epoch #756
 94%|█████████▍| 756/800 [8:42:56<30:15, 41.27s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-755.pth
Results:
  total_reward: -15.0, step_mean: -0.009621552277100705
  total_deaths: 1308.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 522.94 minutes

Epoch #757
Saving the network weights to: ../models/sec_models/only_kill_death/model-756.pth
Results:
  total_reward: -18.0, step_mean: -0.011494252873563218
  total_deaths: 1309.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 523.63 minutes

Epoch #758
 95%|█████████▍| 758/800 [8:44:19<28:59, 41.42s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-757.pth
Results:
  total_reward: -19.0, step_mean: -0.012132822477650063
  total_deaths: 1310.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 524.33 minutes

Epoch #759
Saving the network weights to: ../models/sec_models/only_kill_death/model-758.pth
Results:
  total_reward: -6.0, step_mean: -0.0038095238095238095
  total_deaths: 1310.0
  frag: 0.0
  death: 0.0
  global_step: 1575
Total elapsed time: 525.02 minutes

Epoch #760
 95%|█████████▌| 760/800 [8:45:42<27:32, 41.32s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-759.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 1311.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 525.70 minutes

Epoch #761
Saving the network weights to: ../models/sec_models/only_kill_death/model-760.pth
Results:
  total_reward: -26.0, step_mean: -0.01667735728030789
  total_deaths: 1313.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 526.41 minutes

Epoch #762
 95%|█████████▌| 762/800 [8:47:06<26:27, 41.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-761.pth
Results:
  total_reward: -33.0, step_mean: -0.021181001283697046
  total_deaths: 1315.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 527.11 minutes

Epoch #763
 95%|█████████▌| 763/800 [8:47:49<25:53, 41.98s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-762.pth
Results:
  total_reward: -9.0, step_mean: -0.005810200129115558
  total_deaths: 1318.0
  frag: 1.0
  death: 3.0
  global_step: 1549
Total elapsed time: 527.82 minutes

Epoch #764
Saving the network weights to: ../models/sec_models/only_kill_death/model-763.pth
Results:
  total_reward: -21.0, step_mean: -0.013478818998716302
  total_deaths: 1320.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 528.50 minutes

Epoch #765
 96%|█████████▌| 765/800 [8:49:09<23:58, 41.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-764.pth
Results:
  total_reward: -41.0, step_mean: -0.026451612903225806
  total_deaths: 1323.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 529.16 minutes

Epoch #766
Saving the network weights to: ../models/sec_models/only_kill_death/model-765.pth
Results:
  total_reward: -46.0, step_mean: -0.029831387808041506
  total_deaths: 1327.0
  frag: 0.0
  death: 4.0
  global_step: 1542
Total elapsed time: 529.83 minutes

Epoch #767
 96%|█████████▌| 767/800 [8:50:29<22:18, 40.55s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-766.pth
Results:
  total_reward: -32.0, step_mean: -0.02053915275994865
  total_deaths: 1329.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 530.50 minutes

Epoch #768
Saving the network weights to: ../models/sec_models/only_kill_death/model-767.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 1330.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 531.17 minutes

Epoch #769
 96%|█████████▌| 769/800 [8:51:50<20:54, 40.45s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-768.pth
Results:
  total_reward: -34.0, step_mean: -0.021822849807445442
  total_deaths: 1332.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 531.84 minutes

Epoch #770
Saving the network weights to: ../models/sec_models/only_kill_death/model-769.pth
Results:
  total_reward: -16.0, step_mean: -0.010262989095574085
  total_deaths: 1334.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 532.51 minutes

Epoch #771
 96%|█████████▋| 771/800 [8:53:10<19:24, 40.16s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-770.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 1336.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 533.17 minutes

Epoch #772
 96%|█████████▋| 772/800 [8:53:50<18:43, 40.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-771.pth
Results:
  total_reward: -22.0, step_mean: -0.014039566049776643
  total_deaths: 1337.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 533.84 minutes

Epoch #773
 97%|█████████▋| 773/800 [8:54:30<18:03, 40.14s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-772.pth
Results:
  total_reward: -35.0, step_mean: -0.022464698331193838
  total_deaths: 1339.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 534.51 minutes

Epoch #774
Saving the network weights to: ../models/sec_models/only_kill_death/model-773.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 1340.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 535.18 minutes

Epoch #775
 97%|█████████▋| 775/800 [8:55:51<16:44, 40.19s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-774.pth
Results:
  total_reward: -16.0, step_mean: -0.010269576379974325
  total_deaths: 1342.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 535.85 minutes

Epoch #776
Saving the network weights to: ../models/sec_models/only_kill_death/model-775.pth
Results:
  total_reward: -21.0, step_mean: -0.013401403956604978
  total_deaths: 1343.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 536.52 minutes

Epoch #777
 97%|█████████▋| 777/800 [8:57:12<15:31, 40.49s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-776.pth
Results:
  total_reward: -20.0, step_mean: -0.01277139208173691
  total_deaths: 1344.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 537.21 minutes

Epoch #778
Saving the network weights to: ../models/sec_models/only_kill_death/model-777.pth
Results:
  total_reward: -17.0, step_mean: -0.010848755583918315
  total_deaths: 1345.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 537.90 minutes

Epoch #779
 97%|█████████▋| 779/800 [8:58:35<14:19, 40.94s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-778.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 1347.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 538.59 minutes

Epoch #780
 98%|█████████▊| 780/800 [8:59:17<13:43, 41.18s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-779.pth
Results:
  total_reward: -20.0, step_mean: -0.012763241863433313
  total_deaths: 1348.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 539.28 minutes

Epoch #781
Saving the network weights to: ../models/sec_models/only_kill_death/model-780.pth
Results:
  total_reward: -21.0, step_mean: -0.013401403956604978
  total_deaths: 1349.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 539.98 minutes

Epoch #782
 98%|█████████▊| 782/800 [9:00:39<12:20, 41.15s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-781.pth
Results:
  total_reward: -8.0, step_mean: -0.005105296745373325
  total_deaths: 1350.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 540.66 minutes

Epoch #783
Saving the network weights to: ../models/sec_models/only_kill_death/model-782.pth
Results:
  total_reward: -34.0, step_mean: -0.02193548387096774
  total_deaths: 1353.0
  frag: 0.0
  death: 3.0
  global_step: 1550
Total elapsed time: 541.33 minutes

Epoch #784
 98%|█████████▊| 784/800 [9:02:00<10:52, 40.78s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-783.pth
Results:
  total_reward: -22.0, step_mean: -0.0140485312899106
  total_deaths: 1354.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 542.00 minutes

Epoch #785
 98%|█████████▊| 785/800 [9:02:41<10:16, 41.09s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-784.pth
Results:
  total_reward: -19.0, step_mean: -0.012125079770261647
  total_deaths: 1355.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 542.70 minutes

Epoch #786
Saving the network weights to: ../models/sec_models/only_kill_death/model-785.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 1357.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 543.38 minutes

Epoch #787
 98%|█████████▊| 787/800 [9:04:03<08:50, 40.80s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-786.pth
Results:
  total_reward: -29.0, step_mean: -0.018613607188703467
  total_deaths: 1359.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 544.05 minutes

Epoch #788
Saving the network weights to: ../models/sec_models/only_kill_death/model-787.pth
Results:
  total_reward: -18.0, step_mean: -0.01148691767708998
  total_deaths: 1360.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 544.71 minutes

Epoch #789
 99%|█████████▊| 789/800 [9:05:21<07:21, 40.11s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-788.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 1361.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 545.37 minutes

Epoch #790
Saving the network weights to: ../models/sec_models/only_kill_death/model-789.pth
Results:
  total_reward: -13.0, step_mean: -0.008296107211231652
  total_deaths: 1362.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 546.02 minutes

Epoch #791
 99%|█████████▉| 791/800 [9:06:40<05:57, 39.72s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-790.pth
Results:
  total_reward: -15.0, step_mean: -0.009572431397574984
  total_deaths: 1363.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 546.68 minutes

Epoch #792
Saving the network weights to: ../models/sec_models/only_kill_death/model-791.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 1365.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 547.34 minutes

Epoch #793
 99%|█████████▉| 793/800 [9:07:59<04:38, 39.73s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-792.pth
Results:
  total_reward: -23.0, step_mean: -0.014762516046213094
  total_deaths: 1367.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 548.00 minutes

Epoch #794
Saving the network weights to: ../models/sec_models/only_kill_death/model-793.pth
Results:
  total_reward: -17.0, step_mean: -0.010904425914047467
  total_deaths: 1369.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 548.65 minutes

Epoch #795
 99%|█████████▉| 795/800 [9:09:18<03:16, 39.39s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-794.pth
Results:
  total_reward: -26.0, step_mean: -0.01668806161745828
  total_deaths: 1371.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 549.30 minutes

Epoch #796
100%|█████████▉| 796/800 [9:09:56<02:36, 39.08s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-795.pth
Results:
  total_reward: -20.0, step_mean: -0.012836970474967908
  total_deaths: 1373.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 549.94 minutes

Epoch #797
Saving the network weights to: ../models/sec_models/only_kill_death/model-796.pth
Results:
  total_reward: -19.0, step_mean: -0.012195121951219513
  total_deaths: 1375.0
  frag: 0.0
  death: 2.0
  global_step: 1558
Total elapsed time: 550.58 minutes

Epoch #798
100%|█████████▉| 798/800 [9:11:13<01:17, 38.69s/it]Saving the network weights to: ../models/sec_models/only_kill_death/model-797.pth
Results:
  total_reward: -7.0, step_mean: -0.004467134652201659
  total_deaths: 1376.0
  frag: 0.0
  death: 1.0
  global_step: 1567
Total elapsed time: 551.22 minutes

Epoch #799
Saving the network weights to: ../models/sec_models/only_kill_death/model-798.pth
Results:
  total_reward: -21.0, step_mean: -0.013470173187940988
  total_deaths: 1378.0
  frag: 0.0
  death: 2.0
  global_step: 1559
Total elapsed time: 551.89 minutes

Epoch #800
Saving the network weights to: ../models/sec_models/only_kill_death/model-799.pth
Results:
  total_reward: -13.0, step_mean: -0.008301404853128991
  total_deaths: 1379.0
  frag: 0.0
  death: 1.0
  global_step: 1566
Total elapsed time: 552.56 minutes
Saving the network weights to: ../models/model-only_kill_death.pth
======================================
Training finished. It's time to watch!
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.01021059349074665, total: -16.0, steps: 1567
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.017419354838709676, total: -27.0, steps: 1550
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.01935483870967742, total: -30.0, steps: 1550
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.01540436456996149, total: -24.0, steps: 1558
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.0070242656449553, total: -11.0, steps: 1566
mean: -0.016698779704560053, total: -26.0, steps: 1557
mean: -0.026623376623376622, total: -41.0, steps: 1540
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.004469987228607918, total: -7.0, steps: 1566
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.016129032258064516, total: -25.0, steps: 1550
mean: -0.016129032258064516, total: -25.0, steps: 1550
mean: -0.0070242656449553, total: -11.0, steps: 1566
mean: -0.010911424903722721, total: -17.0, steps: 1558
mean: -0.01872175597159458, total: -29.0, steps: 1549
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.014193548387096775, total: -22.0, steps: 1550
mean: -0.008985879332477536, total: -14.0, steps: 1558
mean: -0.015483870967741935, total: -24.0, steps: 1550
mean: -0.009627727856225931, total: -15.0, steps: 1558
mean: -0.021836865767501604, total: -34.0, steps: 1557
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.016129032258064516, total: -25.0, steps: 1550
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.010269576379974325, total: -16.0, steps: 1558
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.027096774193548386, total: -42.0, steps: 1550
mean: -0.007662835249042145, total: -12.0, steps: 1566
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.027237354085603113, total: -42.0, steps: 1542
mean: -0.022464698331193838, total: -35.0, steps: 1558
mean: -0.026606099935107073, total: -41.0, steps: 1541
mean: -0.01989730423620026, total: -31.0, steps: 1558
mean: -0.014120667522464698, total: -22.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.02053915275994865, total: -32.0, steps: 1558
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.015483870967741935, total: -24.0, steps: 1550
mean: -0.019267822736030827, total: -30.0, steps: 1557
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.01605651894669236, total: -25.0, steps: 1557
mean: -0.013401403956604978, total: -21.0, steps: 1567
mean: -0.022464698331193838, total: -35.0, steps: 1558
mean: -0.01605651894669236, total: -25.0, steps: 1557
mean: -0.018625561978163133, total: -29.0, steps: 1557
mean: -0.033766233766233764, total: -52.0, steps: 1540
mean: -0.015964240102171137, total: -25.0, steps: 1566
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.01798330122029544, total: -28.0, steps: 1557
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.018076178179470628, total: -28.0, steps: 1549
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.018625561978163133, total: -29.0, steps: 1557
mean: -0.007697241821680564, total: -12.0, steps: 1559
mean: -0.010911424903722721, total: -17.0, steps: 1558
mean: -0.028405422853453842, total: -44.0, steps: 1549
mean: -0.029051000645577793, total: -45.0, steps: 1549
mean: -0.008939974457215836, total: -14.0, steps: 1566
mean: -0.012763241863433313, total: -20.0, steps: 1567
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.025673940949935817, total: -40.0, steps: 1558
mean: -0.01989730423620026, total: -31.0, steps: 1558
mean: -0.005714285714285714, total: -9.0, steps: 1575
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.004469987228607918, total: -7.0, steps: 1566
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.0070242656449553, total: -11.0, steps: 1566
mean: -0.014771997430956968, total: -23.0, steps: 1557
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.019884541372674792, total: -31.0, steps: 1559
mean: -0.012763241863433313, total: -20.0, steps: 1567
mean: -0.014753046824887749, total: -23.0, steps: 1559
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.010269576379974325, total: -16.0, steps: 1558
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.021822849807445442, total: -34.0, steps: 1558
mean: -0.009621552277100705, total: -15.0, steps: 1559
mean: -0.01021059349074665, total: -16.0, steps: 1567
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.007657945118059987, total: -12.0, steps: 1567
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.013478818998716302, total: -21.0, steps: 1558
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.02065848934796643, total: -32.0, steps: 1549
mean: -0.01935483870967742, total: -30.0, steps: 1550
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.016139444803098774, total: -25.0, steps: 1549
mean: -0.008939974457215836, total: -14.0, steps: 1566
mean: -0.02194964493221433, total: -34.0, steps: 1549
mean: -0.017341040462427744, total: -27.0, steps: 1557
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.021181001283697046, total: -33.0, steps: 1558
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.02052597819114817, total: -32.0, steps: 1559
mean: -0.017430600387346677, total: -27.0, steps: 1549
mean: -0.00834403080872914, total: -13.0, steps: 1558
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.01540436456996149, total: -24.0, steps: 1558
mean: -0.01148691767708998, total: -18.0, steps: 1567
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.005714285714285714, total: -9.0, steps: 1575
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.02053915275994865, total: -32.0, steps: 1558
mean: -0.02529182879377432, total: -39.0, steps: 1542
mean: -0.013409961685823755, total: -21.0, steps: 1566
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.01924310455420141, total: -30.0, steps: 1559
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.01148691767708998, total: -18.0, steps: 1567
mean: -0.01935483870967742, total: -30.0, steps: 1550
mean: -0.010269576379974325, total: -16.0, steps: 1558
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.014687100893997445, total: -23.0, steps: 1566
mean: -0.030987734021949646, total: -48.0, steps: 1549
mean: -0.022464698331193838, total: -35.0, steps: 1558
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.013470173187940988, total: -21.0, steps: 1559
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.024531956100710135, total: -38.0, steps: 1549
mean: -0.02053915275994865, total: -32.0, steps: 1558
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.01935483870967742, total: -30.0, steps: 1550
mean: -0.007019783024888321, total: -11.0, steps: 1567
mean: -0.02119460500963391, total: -33.0, steps: 1557
mean: -0.021822849807445442, total: -34.0, steps: 1558
mean: -0.019884541372674792, total: -31.0, steps: 1559
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.028405422853453842, total: -44.0, steps: 1549
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.01532567049808429, total: -24.0, steps: 1566
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.017419354838709676, total: -27.0, steps: 1550
mean: -0.01727447216890595, total: -27.0, steps: 1563
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.02454780361757106, total: -38.0, steps: 1548
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.013548387096774193, total: -21.0, steps: 1550
mean: -0.007643312101910828, total: -12.0, steps: 1570
mean: 0.008939974457215836, total: 14.0, steps: 1566
mean: -0.0070242656449553, total: -11.0, steps: 1566
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.014771997430956968, total: -23.0, steps: 1557
mean: -0.033116883116883114, total: -51.0, steps: 1540
mean: -0.006418485237483954, total: -10.0, steps: 1558
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.014120667522464698, total: -22.0, steps: 1558
mean: -0.01348747591522158, total: -21.0, steps: 1557
mean: -0.021181001283697046, total: -33.0, steps: 1558
mean: -0.012828736369467608, total: -20.0, steps: 1559
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.01021059349074665, total: -16.0, steps: 1567
mean: -0.001924310455420141, total: -3.0, steps: 1559
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.004467134652201659, total: -7.0, steps: 1567
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.01348747591522158, total: -21.0, steps: 1557
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.014677728142948309, total: -23.0, steps: 1567
mean: -0.018625561978163133, total: -29.0, steps: 1557
mean: -0.013409961685823755, total: -21.0, steps: 1566
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.01991008349389852, total: -31.0, steps: 1557
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.018076178179470628, total: -28.0, steps: 1549
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.014039566049776643, total: -22.0, steps: 1567
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.00834403080872914, total: -13.0, steps: 1558
mean: -0.0044444444444444444, total: -7.0, steps: 1575
mean: -0.010911424903722721, total: -17.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.01148691767708998, total: -18.0, steps: 1567
mean: -0.02130406714009038, total: -33.0, steps: 1549
mean: -0.01731879409878127, total: -27.0, steps: 1559
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.005747126436781609, total: -9.0, steps: 1566
mean: -0.00834403080872914, total: -13.0, steps: 1558
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.013401403956604978, total: -21.0, steps: 1567
mean: -0.017430600387346677, total: -27.0, steps: 1549
mean: -0.007019783024888321, total: -11.0, steps: 1567
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.0038095238095238095, total: -6.0, steps: 1575
mean: -0.01798330122029544, total: -28.0, steps: 1557
mean: -0.012828736369467608, total: -20.0, steps: 1559
mean: -0.01605651894669236, total: -25.0, steps: 1557
mean: -0.015964240102171137, total: -25.0, steps: 1566
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.021822849807445442, total: -34.0, steps: 1558
mean: -0.010911424903722721, total: -17.0, steps: 1558
mean: -0.014838709677419355, total: -23.0, steps: 1550
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.029201817001946788, total: -45.0, steps: 1541
mean: -0.012763241863433313, total: -20.0, steps: 1567
mean: -0.007702182284980745, total: -12.0, steps: 1558
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.010329244673983214, total: -16.0, steps: 1549
mean: -0.007702182284980745, total: -12.0, steps: 1558
mean: -0.012258064516129033, total: -19.0, steps: 1550
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.01148691767708998, total: -18.0, steps: 1567
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.024531956100710135, total: -38.0, steps: 1549
mean: -0.01806451612903226, total: -28.0, steps: 1550
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.010911424903722721, total: -17.0, steps: 1558
mean: -0.016774193548387096, total: -26.0, steps: 1550
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.014120667522464698, total: -22.0, steps: 1558
mean: -0.0044444444444444444, total: -7.0, steps: 1575
mean: -0.012218649517684888, total: -19.0, steps: 1555
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.014120667522464698, total: -22.0, steps: 1558
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.004469987228607918, total: -7.0, steps: 1566
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.007060333761232349, total: -11.0, steps: 1558
mean: -0.006385696040868455, total: -10.0, steps: 1566
mean: -0.007060333761232349, total: -11.0, steps: 1558
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.010911424903722721, total: -17.0, steps: 1558
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.0038289725590299937, total: -6.0, steps: 1567
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.01148691767708998, total: -18.0, steps: 1567
mean: -0.013401403956604978, total: -21.0, steps: 1567
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.014039566049776643, total: -22.0, steps: 1567
mean: -0.020012911555842477, total: -31.0, steps: 1549
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.018076178179470628, total: -28.0, steps: 1549
mean: -0.020012911555842477, total: -31.0, steps: 1549
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.0070242656449553, total: -11.0, steps: 1566
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.015414258188824663, total: -24.0, steps: 1557
mean: -0.01540436456996149, total: -24.0, steps: 1558
mean: -0.012763241863433313, total: -20.0, steps: 1567
mean: -0.01924310455420141, total: -30.0, steps: 1559
mean: -0.027237354085603113, total: -42.0, steps: 1542
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.010269576379974325, total: -16.0, steps: 1558
mean: -0.03374432186891629, total: -52.0, steps: 1541
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.005747126436781609, total: -9.0, steps: 1566
mean: -0.017419354838709676, total: -27.0, steps: 1550
mean: -0.014120667522464698, total: -22.0, steps: 1558
mean: -0.007019783024888321, total: -11.0, steps: 1567
mean: -0.019267822736030827, total: -30.0, steps: 1557
mean: -0.005806451612903226, total: -9.0, steps: 1550
mean: -0.0025673940949935813, total: -4.0, steps: 1558
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.0025396825396825397, total: -4.0, steps: 1575
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.016785022595222725, total: -26.0, steps: 1549
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.023886378308586184, total: -37.0, steps: 1549
mean: -0.008980115458627326, total: -14.0, steps: 1559
mean: -0.015483870967741935, total: -24.0, steps: 1550
mean: -0.014120667522464698, total: -22.0, steps: 1558
mean: -0.0070242656449553, total: -11.0, steps: 1566
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.008985879332477536, total: -14.0, steps: 1558
mean: -0.0025526483726866626, total: -4.0, steps: 1567
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.025161290322580646, total: -39.0, steps: 1550
mean: -0.007060333761232349, total: -11.0, steps: 1558
mean: -0.005714285714285714, total: -9.0, steps: 1575
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.02775984506132989, total: -43.0, steps: 1549
mean: -0.01796023091725465, total: -28.0, steps: 1559
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.029051000645577793, total: -45.0, steps: 1549
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.005131494547787043, total: -8.0, steps: 1559
mean: 0.00574345883854499, total: 9.0, steps: 1567
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.018076178179470628, total: -28.0, steps: 1549
mean: -0.01870967741935484, total: -29.0, steps: 1550
mean: -0.002554278416347382, total: -4.0, steps: 1566
mean: -0.003190810465858328, total: -5.0, steps: 1567
mean: -0.013409961685823755, total: -21.0, steps: 1566
mean: -0.012763241863433313, total: -20.0, steps: 1567
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.01021059349074665, total: -16.0, steps: 1567
mean: -0.026451612903225806, total: -41.0, steps: 1550
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.0206052801030264, total: -32.0, steps: 1553
mean: -0.006418485237483954, total: -10.0, steps: 1558
mean: -0.0025396825396825397, total: -4.0, steps: 1575
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.008939974457215836, total: -14.0, steps: 1566
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.019267822736030827, total: -30.0, steps: 1557
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.016785022595222725, total: -26.0, steps: 1549
mean: -0.0038289725590299937, total: -6.0, steps: 1567
mean: -0.017419354838709676, total: -27.0, steps: 1550
mean: -0.006381620931716656, total: -10.0, steps: 1567
mean: -0.023886378308586184, total: -37.0, steps: 1549
mean: -0.005714285714285714, total: -9.0, steps: 1575
mean: -0.019367333763718526, total: -30.0, steps: 1549
mean: -0.014039566049776643, total: -22.0, steps: 1567
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.016139444803098774, total: -25.0, steps: 1549
mean: -0.005105296745373325, total: -8.0, steps: 1567
mean: -0.008939974457215836, total: -14.0, steps: 1566
mean: -0.0224791265253693, total: -35.0, steps: 1557
mean: -0.02053915275994865, total: -32.0, steps: 1558
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.02064516129032258, total: -32.0, steps: 1550
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.016698779704560053, total: -26.0, steps: 1557
mean: -0.006984126984126984, total: -11.0, steps: 1575
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.01021059349074665, total: -16.0, steps: 1567
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.014677728142948309, total: -23.0, steps: 1567
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.014111610006414367, total: -22.0, steps: 1559
mean: -0.019367333763718526, total: -30.0, steps: 1549
mean: -0.0070242656449553, total: -11.0, steps: 1566
mean: -0.029051000645577793, total: -45.0, steps: 1549
mean: -0.00574345883854499, total: -9.0, steps: 1567
mean: -0.010911424903722721, total: -17.0, steps: 1558
mean: -0.005776636713735558, total: -9.0, steps: 1558
mean: -0.011553273427471117, total: -18.0, steps: 1558
mean: -0.006418485237483954, total: -10.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.024531956100710135, total: -38.0, steps: 1549
mean: -0.006349206349206349, total: -10.0, steps: 1575
mean: -0.0031746031746031746, total: -5.0, steps: 1575
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.016698779704560053, total: -26.0, steps: 1557
mean: -0.0025396825396825397, total: -4.0, steps: 1575
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.012763241863433313, total: -20.0, steps: 1567
mean: -0.006385696040868455, total: -10.0, steps: 1566
mean: -0.012763241863433313, total: -20.0, steps: 1567
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.025823111684958037, total: -40.0, steps: 1549
mean: -0.025161290322580646, total: -39.0, steps: 1550
mean: -0.012763241863433313, total: -20.0, steps: 1567
mean: -0.007657945118059987, total: -12.0, steps: 1567
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.010911424903722721, total: -17.0, steps: 1558
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.007702182284980745, total: -12.0, steps: 1558
mean: -0.00967741935483871, total: -15.0, steps: 1550
mean: -0.0019047619047619048, total: -3.0, steps: 1575
mean: -0.008338678640153944, total: -13.0, steps: 1559
mean: -0.016785022595222725, total: -26.0, steps: 1549
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.013478818998716302, total: -21.0, steps: 1558
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.008939974457215836, total: -14.0, steps: 1566
mean: -0.023225806451612905, total: -36.0, steps: 1550
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.007702182284980745, total: -12.0, steps: 1558
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.01021059349074665, total: -16.0, steps: 1567
mean: -0.02064516129032258, total: -32.0, steps: 1550
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.014039566049776643, total: -22.0, steps: 1567
mean: -0.008939974457215836, total: -14.0, steps: 1566
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.0227125243348475, total: -35.0, steps: 1541
mean: -0.013470173187940988, total: -21.0, steps: 1559
mean: -0.015493867010974823, total: -24.0, steps: 1549
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.006381620931716656, total: -10.0, steps: 1567
mean: -0.017419354838709676, total: -27.0, steps: 1550
mean: 0.0025526483726866626, total: 4.0, steps: 1567
mean: -0.0012763241863433313, total: -2.0, steps: 1567
mean: -0.010276172125883108, total: -16.0, steps: 1557
mean: -0.01989730423620026, total: -31.0, steps: 1558
mean: -0.002554278416347382, total: -4.0, steps: 1566
mean: -0.005105296745373325, total: -8.0, steps: 1567
mean: -0.009683666881859263, total: -15.0, steps: 1549
mean: -0.012845215157353885, total: -20.0, steps: 1557
mean: -0.005776636713735558, total: -9.0, steps: 1558
mean: -0.003190810465858328, total: -5.0, steps: 1567
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.014771997430956968, total: -23.0, steps: 1557
mean: -0.007702182284980745, total: -12.0, steps: 1558
mean: -0.0006381620931716656, total: -1.0, steps: 1567
mean: -0.007702182284980745, total: -12.0, steps: 1558
mean: -0.01540436456996149, total: -24.0, steps: 1558
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.014039566049776643, total: -22.0, steps: 1567
mean: -0.006381620931716656, total: -10.0, steps: 1567
mean: -0.02130406714009038, total: -33.0, steps: 1549
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.02967741935483871, total: -46.0, steps: 1550
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.013401403956604978, total: -21.0, steps: 1567
mean: 0.0, total: 0.0, steps: 1567
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.016139444803098774, total: -25.0, steps: 1549
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.015315890236119975, total: -24.0, steps: 1567
mean: -0.017419354838709676, total: -27.0, steps: 1550
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.006349206349206349, total: -10.0, steps: 1575
mean: -0.01021059349074665, total: -16.0, steps: 1567
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.020012911555842477, total: -31.0, steps: 1549
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.01872175597159458, total: -29.0, steps: 1549
mean: -0.030342156229825695, total: -47.0, steps: 1549
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.01991008349389852, total: -31.0, steps: 1557
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.005079365079365079, total: -8.0, steps: 1575
mean: -0.014039566049776643, total: -22.0, steps: 1567
mean: -0.010911424903722721, total: -17.0, steps: 1558
mean: -0.013401403956604978, total: -21.0, steps: 1567
mean: -0.02065848934796643, total: -32.0, steps: 1549
mean: -0.019255455712451863, total: -30.0, steps: 1558
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.007702182284980745, total: -12.0, steps: 1558
mean: -0.010904425914047467, total: -17.0, steps: 1559
mean: -0.02, total: -31.0, steps: 1550
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.01148691767708998, total: -18.0, steps: 1567
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.013548387096774193, total: -21.0, steps: 1550
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.009627727856225931, total: -15.0, steps: 1558
mean: -0.008939974457215836, total: -14.0, steps: 1566
mean: -0.017341040462427744, total: -27.0, steps: 1557
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.014120667522464698, total: -22.0, steps: 1558
mean: -0.01989730423620026, total: -31.0, steps: 1558
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.005105296745373325, total: -8.0, steps: 1567
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.005747126436781609, total: -9.0, steps: 1566
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.02053915275994865, total: -32.0, steps: 1558
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.007702182284980745, total: -12.0, steps: 1558
mean: -0.013401403956604978, total: -21.0, steps: 1567
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.020552344251766216, total: -32.0, steps: 1557
mean: -0.00834403080872914, total: -13.0, steps: 1558
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.0006349206349206349, total: -1.0, steps: 1575
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.02194964493221433, total: -34.0, steps: 1549
mean: -0.0025673940949935813, total: -4.0, steps: 1558
mean: -0.02775984506132989, total: -43.0, steps: 1549
mean: -0.022464698331193838, total: -35.0, steps: 1558
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.01860166773572803, total: -29.0, steps: 1559
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.007019783024888321, total: -11.0, steps: 1567
mean: -0.007657945118059987, total: -12.0, steps: 1567
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.021181001283697046, total: -33.0, steps: 1558
mean: -0.013409961685823755, total: -21.0, steps: 1566
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.0025526483726866626, total: -4.0, steps: 1567
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.006385696040868455, total: -10.0, steps: 1566
mean: -0.02053915275994865, total: -32.0, steps: 1558
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.021836865767501604, total: -34.0, steps: 1557
mean: -0.007702182284980745, total: -12.0, steps: 1558
mean: -0.01667735728030789, total: -26.0, steps: 1559
mean: -0.018076178179470628, total: -28.0, steps: 1549
mean: -0.014677728142948309, total: -23.0, steps: 1567
mean: -0.02065848934796643, total: -32.0, steps: 1549
mean: -0.016129032258064516, total: -25.0, steps: 1550
mean: -0.0044444444444444444, total: -7.0, steps: 1575
mean: -0.016139444803098774, total: -25.0, steps: 1549
mean: -0.023886378308586184, total: -37.0, steps: 1549
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.02053915275994865, total: -32.0, steps: 1558
mean: -0.009627727856225931, total: -15.0, steps: 1558
mean: -0.018625561978163133, total: -29.0, steps: 1557
mean: -0.010269576379974325, total: -16.0, steps: 1558
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.020012911555842477, total: -31.0, steps: 1549
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.023886378308586184, total: -37.0, steps: 1549
mean: -0.015394483643361129, total: -24.0, steps: 1559
mean: -0.0031746031746031746, total: -5.0, steps: 1575
mean: -0.01924310455420141, total: -30.0, steps: 1559
mean: -0.018625561978163133, total: -29.0, steps: 1557
mean: -0.017430600387346677, total: -27.0, steps: 1549
mean: -0.01148691767708998, total: -18.0, steps: 1567
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.01532567049808429, total: -24.0, steps: 1566
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.01797175866495507, total: -28.0, steps: 1558
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.01603592046183451, total: -25.0, steps: 1559
mean: -0.008939974457215836, total: -14.0, steps: 1566
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.006385696040868455, total: -10.0, steps: 1566
mean: -0.01021059349074665, total: -16.0, steps: 1567
mean: -0.01540436456996149, total: -24.0, steps: 1558
mean: -0.02130406714009038, total: -33.0, steps: 1549
mean: -0.009578544061302681, total: -15.0, steps: 1566
mean: -0.009627727856225931, total: -15.0, steps: 1558
mean: -0.01989730423620026, total: -31.0, steps: 1558
mean: -0.008985879332477536, total: -14.0, steps: 1558
mean: -0.014687100893997445, total: -23.0, steps: 1566
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.021822849807445442, total: -34.0, steps: 1558
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.0038289725590299937, total: -6.0, steps: 1567
mean: -0.00574345883854499, total: -9.0, steps: 1567
mean: -0.019267822736030827, total: -30.0, steps: 1557
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.009627727856225931, total: -15.0, steps: 1558
mean: -0.023886378308586184, total: -37.0, steps: 1549
mean: -0.00899165061014772, total: -14.0, steps: 1557
mean: -0.022595222724338282, total: -35.0, steps: 1549
mean: 0.0, total: 0.0, steps: 1558
mean: -0.006381620931716656, total: -10.0, steps: 1567
mean: -0.005810200129115558, total: -9.0, steps: 1549
mean: -0.007746933505487412, total: -12.0, steps: 1549
mean: -0.023870967741935485, total: -37.0, steps: 1550
mean: -0.013548387096774193, total: -21.0, steps: 1550
mean: -0.007662835249042145, total: -12.0, steps: 1566
mean: -0.004469987228607918, total: -7.0, steps: 1566
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.01348747591522158, total: -21.0, steps: 1557
mean: -0.013478818998716302, total: -21.0, steps: 1558
mean: -0.013478818998716302, total: -21.0, steps: 1558
mean: -0.017419354838709676, total: -27.0, steps: 1550
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.02129032258064516, total: -33.0, steps: 1550
mean: -0.01989730423620026, total: -31.0, steps: 1558
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.024531956100710135, total: -38.0, steps: 1549
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.007019783024888321, total: -11.0, steps: 1567
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.024531956100710135, total: -38.0, steps: 1549
mean: -0.007662835249042145, total: -12.0, steps: 1566
mean: -0.0025526483726866626, total: -4.0, steps: 1567
mean: -0.014120667522464698, total: -22.0, steps: 1558
mean: -0.010855683269476373, total: -17.0, steps: 1566
mean: -0.015394483643361129, total: -24.0, steps: 1559
mean: -0.01752109020116807, total: -27.0, steps: 1541
mean: -0.021822849807445442, total: -34.0, steps: 1558
mean: -0.015414258188824663, total: -24.0, steps: 1557
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.005714285714285714, total: -9.0, steps: 1575
mean: -0.01872175597159458, total: -29.0, steps: 1549
mean: -0.0038095238095238095, total: -6.0, steps: 1575
mean: -0.013478818998716302, total: -21.0, steps: 1558
mean: -0.01991008349389852, total: -31.0, steps: 1557
mean: -0.018625561978163133, total: -29.0, steps: 1557
mean: -0.010262989095574085, total: -16.0, steps: 1559
mean: -0.006418485237483954, total: -10.0, steps: 1558
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.012187299550994226, total: -19.0, steps: 1559
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.01148691767708998, total: -18.0, steps: 1567
mean: -0.0006349206349206349, total: -1.0, steps: 1575
mean: -0.02711426726920594, total: -42.0, steps: 1549
mean: -0.01989730423620026, total: -31.0, steps: 1558
mean: -0.01924310455420141, total: -30.0, steps: 1559
mean: -0.007657945118059987, total: -12.0, steps: 1567
mean: -0.0019047619047619048, total: -3.0, steps: 1575
mean: -0.008985879332477536, total: -14.0, steps: 1558
mean: -0.012265978050355068, total: -19.0, steps: 1549
mean: -0.013409961685823755, total: -21.0, steps: 1566
mean: -0.02053915275994865, total: -32.0, steps: 1558
mean: -0.017329910141206675, total: -27.0, steps: 1558
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.017430600387346677, total: -27.0, steps: 1549
mean: -0.02775984506132989, total: -43.0, steps: 1549
mean: -0.01021059349074665, total: -16.0, steps: 1567
mean: -0.006418485237483954, total: -10.0, steps: 1558
mean: -0.007019783024888321, total: -11.0, steps: 1567
mean: -0.010904425914047467, total: -17.0, steps: 1559
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.016129032258064516, total: -25.0, steps: 1550
mean: -0.008985879332477536, total: -14.0, steps: 1558
mean: -0.028405422853453842, total: -44.0, steps: 1549
mean: -0.023870967741935485, total: -37.0, steps: 1550
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.014848289218850872, total: -23.0, steps: 1549
mean: -0.0038289725590299937, total: -6.0, steps: 1567
mean: -0.013401403956604978, total: -21.0, steps: 1567
mean: -0.014687100893997445, total: -23.0, steps: 1566
mean: -0.019267822736030827, total: -30.0, steps: 1557
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.015493867010974823, total: -24.0, steps: 1549
mean: -0.014120667522464698, total: -22.0, steps: 1558
mean: -0.01021059349074665, total: -16.0, steps: 1567
mean: -0.023106546854942234, total: -36.0, steps: 1558
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.016046213093709884, total: -25.0, steps: 1558
mean: -0.016785022595222725, total: -26.0, steps: 1549
mean: -0.014838709677419355, total: -23.0, steps: 1550
mean: -0.021181001283697046, total: -33.0, steps: 1558
mean: -0.008934269304403318, total: -14.0, steps: 1567
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.031148604802076575, total: -48.0, steps: 1541
mean: -0.01924310455420141, total: -30.0, steps: 1559
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.010269576379974325, total: -16.0, steps: 1558
mean: -0.012187299550994226, total: -19.0, steps: 1559
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.006381620931716656, total: -10.0, steps: 1567
mean: -0.02465931213497729, total: -38.0, steps: 1541
mean: -0.01348747591522158, total: -21.0, steps: 1557
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.010217113665389528, total: -16.0, steps: 1566
mean: -0.012763241863433313, total: -20.0, steps: 1567
mean: -0.008939974457215836, total: -14.0, steps: 1566
mean: -0.010904425914047467, total: -17.0, steps: 1559
mean: -0.01856594110115237, total: -29.0, steps: 1562
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.009621552277100705, total: -15.0, steps: 1559
mean: -0.011494252873563218, total: -18.0, steps: 1566
mean: -0.012132822477650063, total: -19.0, steps: 1566
mean: -0.0038095238095238095, total: -6.0, steps: 1575
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.01667735728030789, total: -26.0, steps: 1559
mean: -0.021181001283697046, total: -33.0, steps: 1558
mean: -0.005810200129115558, total: -9.0, steps: 1549
mean: -0.013478818998716302, total: -21.0, steps: 1558
mean: -0.026451612903225806, total: -41.0, steps: 1550
mean: -0.029831387808041506, total: -46.0, steps: 1542
mean: -0.02053915275994865, total: -32.0, steps: 1558
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.021822849807445442, total: -34.0, steps: 1558
mean: -0.010262989095574085, total: -16.0, steps: 1559
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.014039566049776643, total: -22.0, steps: 1567
mean: -0.022464698331193838, total: -35.0, steps: 1558
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.010269576379974325, total: -16.0, steps: 1558
mean: -0.013401403956604978, total: -21.0, steps: 1567
mean: -0.01277139208173691, total: -20.0, steps: 1566
mean: -0.010848755583918315, total: -17.0, steps: 1567
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.012763241863433313, total: -20.0, steps: 1567
mean: -0.013401403956604978, total: -21.0, steps: 1567
mean: -0.005105296745373325, total: -8.0, steps: 1567
mean: -0.02193548387096774, total: -34.0, steps: 1550
mean: -0.0140485312899106, total: -22.0, steps: 1566
mean: -0.012125079770261647, total: -19.0, steps: 1567
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.018613607188703467, total: -29.0, steps: 1558
mean: -0.01148691767708998, total: -18.0, steps: 1567
mean: -0.008301404853128991, total: -13.0, steps: 1566
mean: -0.008296107211231652, total: -13.0, steps: 1567
mean: -0.009572431397574984, total: -15.0, steps: 1567
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.014762516046213094, total: -23.0, steps: 1558
mean: -0.010904425914047467, total: -17.0, steps: 1559
mean: -0.01668806161745828, total: -26.0, steps: 1558
mean: -0.012836970474967908, total: -20.0, steps: 1558
mean: -0.012195121951219513, total: -19.0, steps: 1558
mean: -0.004467134652201659, total: -7.0, steps: 1567
mean: -0.013470173187940988, total: -21.0, steps: 1559
mean: -0.008301404853128991, total: -13.0, steps: 1566
Episode finished.
************************

kills: 0.0,
deaths: 0.0,
kill/death: 0.0
Results: (name: score)
AI: 0

Perfect: 0

Total score: -9.0
************************

Process finished with exit code 0
